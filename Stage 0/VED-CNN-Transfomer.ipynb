{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7b1419-1a2d-4601-a43b-89e245befcb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 03:24:45.928400: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-28 03:24:45.990630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-28 03:24:47.028732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, re, math, random, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390ce10d-cc36-4a6d-99af-c3cbbe32208a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ====== 修改为你的 AudioWAV 路径 ======\n",
    "AUDIO_DIR = \"../AudioWAV\"\n",
    "AUDIO_DIR = Path(AUDIO_DIR)\n",
    "assert AUDIO_DIR.exists(), f\"路径不存在：{AUDIO_DIR}\"\n",
    "\n",
    "# 固定随机种子，结果更可复现\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c549c9ab-c62d-4543-83e2-f4e69cfa338e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>emotion_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AudioWAV/1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AudioWAV/1001_DFA_DIS_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>DIS</td>\n",
       "      <td>XX</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AudioWAV/1001_DFA_FEA_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>FEA</td>\n",
       "      <td>XX</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AudioWAV/1001_DFA_HAP_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>HAP</td>\n",
       "      <td>XX</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AudioWAV/1001_DFA_NEU_XX.wav</td>\n",
       "      <td>1001</td>\n",
       "      <td>DFA</td>\n",
       "      <td>NEU</td>\n",
       "      <td>XX</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  speaker sentence emotion intensity   \n",
       "0  AudioWAV/1001_DFA_ANG_XX.wav     1001      DFA     ANG        XX  \\\n",
       "1  AudioWAV/1001_DFA_DIS_XX.wav     1001      DFA     DIS        XX   \n",
       "2  AudioWAV/1001_DFA_FEA_XX.wav     1001      DFA     FEA        XX   \n",
       "3  AudioWAV/1001_DFA_HAP_XX.wav     1001      DFA     HAP        XX   \n",
       "4  AudioWAV/1001_DFA_NEU_XX.wav     1001      DFA     NEU        XX   \n",
       "\n",
       "  emotion_name  \n",
       "0        Anger  \n",
       "1      Disgust  \n",
       "2         Fear  \n",
       "3        Happy  \n",
       "4      Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREMA-D 文件名格式： <speaker>_<sentence>_<emotion>_<intensity>.wav\n",
    "# 例：1001_DFA_ANG_XX.wav\n",
    "pat = re.compile(r\"(?P<spk>\\d{4})_(?P<sent>[A-Z]{3})_(?P<emo>[A-Z]{3})_(?P<inten>[A-Z]{2})\\.wav$\", re.I)\n",
    "\n",
    "def parse_filename(p: Path):\n",
    "    m = pat.search(p.name)\n",
    "    if not m:\n",
    "        return None\n",
    "    gd = m.groupdict()\n",
    "    return {\n",
    "        \"path\": p,\n",
    "        \"speaker\": int(gd[\"spk\"]),\n",
    "        \"sentence\": gd[\"sent\"].upper(),\n",
    "        \"emotion\": gd[\"emo\"].upper(),\n",
    "        \"intensity\": gd[\"inten\"].upper(),\n",
    "    }\n",
    "\n",
    "files = sorted(AUDIO_DIR.glob(\"*.wav\"))\n",
    "rows = [parse_filename(p) for p in files]\n",
    "meta = pd.DataFrame([r for r in rows if r is not None])\n",
    "\n",
    "# 情绪与强度的映射/可读名\n",
    "EMO_MAP = {\"ANG\":\"Anger\", \"DIS\":\"Disgust\", \"FEA\":\"Fear\", \"HAP\":\"Happy\", \"NEU\":\"Neutral\", \"SAD\":\"Sad\"}\n",
    "INTEN_ORDER = [\"LO\",\"MD\",\"HI\",\"XX\"]  # XX=未知\n",
    "meta[\"emotion_name\"] = meta[\"emotion\"].map(EMO_MAP)\n",
    "meta[\"intensity\"] = pd.Categorical(meta[\"intensity\"], categories=INTEN_ORDER, ordered=True)\n",
    "\n",
    "meta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f9f1af-f962-4a05-813e-2b738b766af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "启用 GPU 显存按需分配\n"
     ]
    }
   ],
   "source": [
    "# 放在 import tensorflow as tf 之后、构建模型之前\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"启用 GPU 显存按需分配\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35140060-708b-4953-9600-6e7607c5aa74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数: 7442\n",
      "emotion_name\n",
      "Anger      1271\n",
      "Disgust    1271\n",
      "Fear       1271\n",
      "Happy      1271\n",
      "Sad        1271\n",
      "Neutral    1087\n",
      "Name: count, dtype: int64\n",
      "情绪标签映射: {'ANG': 0, 'DIS': 1, 'FEA': 2, 'HAP': 3, 'NEU': 4, 'SAD': 5}\n",
      "Train: 4667 Val: 1223 Test: 1552\n",
      "提取 Train 特征...\n",
      "  已处理 500/4667 条音频\n",
      "  已处理 1000/4667 条音频\n",
      "  已处理 1500/4667 条音频\n",
      "  已处理 2000/4667 条音频\n",
      "  已处理 2500/4667 条音频\n",
      "  已处理 3000/4667 条音频\n",
      "  已处理 3500/4667 条音频\n",
      "  已处理 4000/4667 条音频\n",
      "  已处理 4500/4667 条音频\n",
      "提取 Val 特征...\n",
      "  已处理 500/1223 条音频\n",
      "  已处理 1000/1223 条音频\n",
      "提取 Test 特征...\n",
      "  已处理 500/1552 条音频\n",
      "  已处理 1000/1552 条音频\n",
      "  已处理 1500/1552 条音频\n",
      "X_train: (4667, 64, 151, 1) y_train: (4667,)\n",
      "X_val: (1223, 64, 151, 1) X_test: (1552, 64, 151, 1)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 151, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 151, 32)          288       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 64, 151, 32)          128       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 64, 151, 32)          0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 32, 75, 32)           0         ['activation_4[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 32, 75, 32)           0         ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 32, 75, 64)           18432     ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 32, 75, 64)           256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 32, 75, 64)           0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 16, 37, 64)           0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 16, 37, 64)           0         ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 16, 37, 128)          73728     ['dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 16, 37, 128)          512       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 16, 37, 128)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 8, 18, 128)           0         ['activation_6[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 8, 18, 128)           0         ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 8, 18, 256)           294912    ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 8, 18, 256)           1024      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 8, 18, 256)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 4, 9, 256)            0         ['activation_7[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 4, 9, 256)            0         ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " permute_1 (Permute)         (None, 9, 4, 256)            0         ['dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 9, 1024)              0         ['permute_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 9, 256)               262400    ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " positional_embedding_1 (Po  (None, 9, 256)               2304      ['dense_13[0][0]']            \n",
      " sitionalEmbedding)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 9, 256)               263168    ['positional_embedding_1[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'positional_embedding_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)        (None, 9, 256)               0         ['multi_head_attention_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (None, 9, 256)               0         ['positional_embedding_1[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'dropout_18[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 9, 256)               512       ['tf.__operators__.add_8[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 9, 512)               131584    ['layer_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, 9, 512)               0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 9, 256)               131328    ['dropout_19[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (None, 9, 256)               0         ['layer_normalization_8[0][0]'\n",
      " OpLambda)                                                          , 'dense_15[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 9, 256)               512       ['tf.__operators__.add_9[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 9, 256)               263168    ['layer_normalization_9[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 9, 256)               0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (None, 9, 256)               0         ['layer_normalization_9[0][0]'\n",
      " FOpLambda)                                                         , 'dropout_20[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 9, 256)               512       ['tf.__operators__.add_10[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 9, 512)               131584    ['layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 9, 512)               0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 9, 256)               131328    ['dropout_21[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (None, 9, 256)               0         ['layer_normalization_10[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 9, 256)               512       ['tf.__operators__.add_11[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 9, 256)               263168    ['layer_normalization_11[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)        (None, 9, 256)               0         ['multi_head_attention_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, 9, 256)               0         ['layer_normalization_11[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dropout_22[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 9, 256)               512       ['tf.__operators__.add_12[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 9, 512)               131584    ['layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)        (None, 9, 512)               0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 9, 256)               131328    ['dropout_23[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, 9, 256)               0         ['layer_normalization_12[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 9, 256)               512       ['tf.__operators__.add_13[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 9, 256)               263168    ['layer_normalization_13[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)        (None, 9, 256)               0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (None, 9, 256)               0         ['layer_normalization_13[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dropout_24[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 9, 256)               512       ['tf.__operators__.add_14[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 9, 512)               131584    ['layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 9, 512)               0         ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 9, 256)               131328    ['dropout_25[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (None, 9, 256)               0         ['layer_normalization_14[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 9, 256)               512       ['tf.__operators__.add_15[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 9, 1)                 257       ['layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.nn.softmax_1 (TFOpLambd  (None, 9, 1)                 0         ['dense_22[0][0]']            \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 9, 256)               0         ['layer_normalization_15[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.nn.softmax_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOp  (None, 256)                  0         ['tf.math.multiply_1[0][0]']  \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 256)                  65792     ['tf.math.reduce_sum_1[0][0]']\n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)        (None, 256)                  0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 256)                  1024      ['dropout_26[0][0]']          \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 128)                  32896     ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)        (None, 128)                  0         ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 6)                    774       ['dropout_27[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2863143 (10.92 MB)\n",
      "Trainable params: 2861671 (10.92 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 一些全局配置\n",
    "# =========================\n",
    "SR = 16000                # 重采样采样率\n",
    "DURATION = 3.0            # 统一到 3 秒，可按需改成 4.0\n",
    "N_MELS = 64               # 梅尔频带数\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 320          # 约 20ms 帧移\n",
    "FMIN, FMAX = 50, 8000\n",
    "\n",
    "MAX_LEN_SAMPLES = int(SR * DURATION)   # 固定长度的波形点数\n",
    "\n",
    "print(\"样本数:\", len(meta))\n",
    "print(meta[\"emotion_name\"].value_counts())\n",
    "\n",
    "# =========================\n",
    "# Label 编码（情绪 6 类）\n",
    "# =========================\n",
    "le = LabelEncoder()\n",
    "meta[\"emo_idx\"] = le.fit_transform(meta[\"emotion\"])  # 直接用三字母编码\n",
    "num_classes = len(le.classes_)\n",
    "print(\"情绪标签映射:\", dict(zip(le.classes_, range(num_classes))))\n",
    "\n",
    "# =========================\n",
    "# 按 speaker 分组切 train/val/test\n",
    "# =========================\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_val_idx, test_idx = next(gss.split(meta, groups=meta[\"speaker\"]))\n",
    "\n",
    "meta_train_val = meta.iloc[train_val_idx].reset_index(drop=True)\n",
    "meta_test      = meta.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# 再从 train_val 里切出 val\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, val_idx = next(gss2.split(meta_train_val, groups=meta_train_val[\"speaker\"]))\n",
    "\n",
    "meta_train = meta_train_val.iloc[train_idx].reset_index(drop=True)\n",
    "meta_val   = meta_train_val.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Train:\", len(meta_train), \"Val:\", len(meta_val), \"Test:\", len(meta_test))\n",
    "\n",
    "# =========================\n",
    "# 音频 -> 固定长度波形 -> log-mel 特征\n",
    "# =========================\n",
    "def load_and_fix_length(path, sr=SR, max_len=MAX_LEN_SAMPLES):\n",
    "    y, _ = librosa.load(path, sr=sr)\n",
    "    # 实例级 Z-score 标准化，避免响度差异\n",
    "    y = y - np.mean(y)\n",
    "    y_std = np.std(y) + 1e-9\n",
    "    y = y / y_std\n",
    "\n",
    "    if len(y) < max_len:\n",
    "        # 居中 padding\n",
    "        pad_width = max_len - len(y)\n",
    "        left = pad_width // 2\n",
    "        right = pad_width - left\n",
    "        y = np.pad(y, (left, right), mode=\"constant\")\n",
    "    elif len(y) > max_len:\n",
    "        # 居中裁剪\n",
    "        start = (len(y) - max_len) // 2\n",
    "        y = y[start:start+max_len]\n",
    "    return y\n",
    "\n",
    "def waveform_to_logmel(y, sr=SR, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "                       fmin=FMIN, fmax=FMAX):\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=n_fft, hop_length=hop_length,\n",
    "        n_mels=n_mels, fmin=fmin, fmax=fmax, power=2.0\n",
    "    )\n",
    "    logS = librosa.power_to_db(S, ref=np.max)\n",
    "    # 实例级标准化\n",
    "    m = logS.mean()\n",
    "    s = logS.std() + 1e-9\n",
    "    logS = (logS - m) / s\n",
    "    return logS.astype(np.float32)   # shape: (n_mels, time)\n",
    "\n",
    "def extract_features(df):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, row in df.iterrows():\n",
    "        path = row[\"path\"]\n",
    "        emo_idx = row[\"emo_idx\"]\n",
    "        y_wav = load_and_fix_length(path)\n",
    "        logmel = waveform_to_logmel(y_wav)  # (n_mels, time)\n",
    "        X.append(logmel)\n",
    "        y.append(emo_idx)\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f\"  已处理 {i+1}/{len(df)} 条音频\")\n",
    "    X = np.stack(X, axis=0)   # (N, n_mels, time)\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    # 增加一个通道维度 -> (N, n_mels, time, 1)\n",
    "    X = X[..., np.newaxis]\n",
    "    return X, y\n",
    "\n",
    "print(\"提取 Train 特征...\")\n",
    "X_train, y_train = extract_features(meta_train)\n",
    "\n",
    "print(\"提取 Val 特征...\")\n",
    "X_val, y_val = extract_features(meta_val)\n",
    "\n",
    "print(\"提取 Test 特征...\")\n",
    "X_test, y_test = extract_features(meta_test)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape, \"X_test:\", X_test.shape)\n",
    "\n",
    "# =========================\n",
    "# tf.data 数据管线（可选简单增强）\n",
    "# 这里先不上 SpecAugment，后面你可以在此基础上加\n",
    "# =========================\n",
    "\n",
    "def make_dataset(X, y, training=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(X), seed=SEED)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(X_train, y_train, training=True)\n",
    "val_ds   = make_dataset(X_val, y_val, training=False)\n",
    "test_ds  = make_dataset(X_test, y_test, training=False)\n",
    "\n",
    "# =========================\n",
    "# Transformer 相关模块\n",
    "# =========================\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    \"\"\"简单可训练位置编码：对时间轴做 embedding。\"\"\"\n",
    "    def __init__(self, maxlen, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.maxlen = maxlen\n",
    "        self.d_model = d_model\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        # x: (batch, time, d_model)\n",
    "        length = tf.shape(x)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        positions = self.pos_emb(positions)  # (time, d_model)\n",
    "        return x + positions\n",
    "\n",
    "def transformer_encoder(x, head_size, num_heads, ff_dim, dropout=0.1):\n",
    "    \"\"\"标准 Transformer Encoder Block。\"\"\"\n",
    "    # Multi-Head Self Attention\n",
    "    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(x, x)\n",
    "    attn = layers.Dropout(dropout)(attn)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + attn)\n",
    "\n",
    "    # Feed-Forward\n",
    "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    ff = layers.Dense(x.shape[-1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "    return x\n",
    "\n",
    "# =========================\n",
    "# 构建 CNN 前端 + Transformer 编码器 + 判别头 模型\n",
    "# =========================\n",
    "def build_cnn_transformer_model(\n",
    "    input_shape,\n",
    "    num_classes,\n",
    "    cnn_channels=(32, 64, 128),\n",
    "    d_model=256,\n",
    "    num_heads=4,\n",
    "    num_transformer_blocks=4,\n",
    "    ff_dim=512,\n",
    "    dropout_cnn=0.2,\n",
    "    dropout_transformer=0.2,\n",
    "    dropout_head=0.4\n",
    "):\n",
    "    \"\"\"\n",
    "    input_shape: (n_mels, time, 1)\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = inp\n",
    "    # ---- CNN 声学前端：多层 Conv2D + BN + ReLU + MaxPool ----\n",
    "    for ch in cnn_channels:\n",
    "        x = layers.Conv2D(ch, (3, 3), padding=\"same\", use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        # 对频率轴做 pool，尽量保留时间分辨率\n",
    "        x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = layers.Dropout(dropout_cnn)(x)\n",
    "\n",
    "    # x: (batch, mel', time', ch_last)\n",
    "    # 我们想要以“时间”为序列维度，把 (mel', ch) 合并成特征维度\n",
    "    # 先把维度变成 (batch, time', mel', ch)\n",
    "    x = layers.Permute((2, 1, 3))(x)  # (batch, time', mel', ch)\n",
    "    time_steps = tf.shape(x)[1]\n",
    "    feat_dim = x.shape[2] * x.shape[3]  # 静态维度\n",
    "\n",
    "    x = layers.Reshape((-1, feat_dim))(x)  # (batch, time', feat_dim)\n",
    "\n",
    "    # 线性投到 Transformer 的 d_model 维度\n",
    "    x = layers.Dense(d_model)(x)\n",
    "\n",
    "    # 加位置编码\n",
    "    # 这里 maxlen 用 input_shape 的时间轴近似，也可以用 x.shape[1]\n",
    "    maxlen = x.shape[1]\n",
    "    if maxlen is None:\n",
    "        # fallback：给个较大的 maxlen\n",
    "        maxlen = 500\n",
    "    pos_emb = PositionalEmbedding(maxlen=maxlen, d_model=d_model)\n",
    "    x = pos_emb(x)\n",
    "\n",
    "    # ---- 多层 Transformer Encoder ----\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(\n",
    "            x,\n",
    "            head_size=d_model // num_heads,\n",
    "            num_heads=num_heads,\n",
    "            ff_dim=ff_dim,\n",
    "            dropout=dropout_transformer\n",
    "        )\n",
    "\n",
    "    # ---- 判别性分类头：Attention Pooling + Dense ----\n",
    "    # Attention Pooling：让模型自动关注情感强的时刻\n",
    "    attn_scores = layers.Dense(1)(x)               # (batch, time, 1)\n",
    "    attn_scores = tf.nn.softmax(attn_scores, axis=1)\n",
    "    x_pooled = tf.reduce_sum(x * attn_scores, axis=1)  # (batch, d_model)\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(x_pooled)\n",
    "    x = layers.Dropout(dropout_head)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout_head)(x)\n",
    "\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape[1:]  # (n_mels, time, 1)\n",
    "model = build_cnn_transformer_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    cnn_channels=(32, 64, 128, 256),   # 显存够，可以再深一点\n",
    "    d_model=256,\n",
    "    num_heads=4,\n",
    "    num_transformer_blocks=4,\n",
    "    ff_dim=512\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9532361-4ad5-40d2-855b-09f1b0db3407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 03:37:32.176467: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/dropout_14/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 [============================>.] - ETA: 0s - loss: 1.3035 - accuracy: 0.4753 - macro_f1: 0.4593\n",
      "[Epoch 1] current lr: 6.335616e-05\n",
      "37/37 [==============================] - 20s 85ms/step - loss: 1.3040 - accuracy: 0.4748 - macro_f1: 0.4585 - val_loss: 1.5432 - val_accuracy: 0.4113 - val_macro_f1: 0.3525\n",
      "Epoch 2/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2649 - accuracy: 0.5033 - macro_f1: 0.4926\n",
      "[Epoch 2] current lr: 1.267123e-04\n",
      "37/37 [==============================] - 2s 59ms/step - loss: 1.2649 - accuracy: 0.5033 - macro_f1: 0.4926 - val_loss: 1.3994 - val_accuracy: 0.4587 - val_macro_f1: 0.4191\n",
      "Epoch 3/80\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.2464 - accuracy: 0.5139 - macro_f1: 0.5042\n",
      "[Epoch 3] current lr: 1.900685e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2482 - accuracy: 0.5132 - macro_f1: 0.5025 - val_loss: 1.4281 - val_accuracy: 0.4415 - val_macro_f1: 0.3982\n",
      "Epoch 4/80\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.2196 - accuracy: 0.5239 - macro_f1: 0.5157\n",
      "[Epoch 4] current lr: 2.534247e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2196 - accuracy: 0.5239 - macro_f1: 0.5158 - val_loss: 1.4870 - val_accuracy: 0.4072 - val_macro_f1: 0.3447\n",
      "Epoch 5/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2351 - accuracy: 0.5078 - macro_f1: 0.4963\n",
      "[Epoch 5] current lr: 3.167808e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2351 - accuracy: 0.5078 - macro_f1: 0.4963 - val_loss: 1.4784 - val_accuracy: 0.4235 - val_macro_f1: 0.3752\n",
      "Epoch 6/80\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.2298 - accuracy: 0.5217 - macro_f1: 0.5118\n",
      "[Epoch 6] current lr: 3.801370e-04\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 1.2288 - accuracy: 0.5222 - macro_f1: 0.5128 - val_loss: 1.4121 - val_accuracy: 0.4612 - val_macro_f1: 0.4318\n",
      "Epoch 7/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2249 - accuracy: 0.5301 - macro_f1: 0.5166\n",
      "[Epoch 7] current lr: 4.434932e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2249 - accuracy: 0.5301 - macro_f1: 0.5166 - val_loss: 2.7530 - val_accuracy: 0.3442 - val_macro_f1: 0.2912\n",
      "Epoch 8/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2372 - accuracy: 0.5140 - macro_f1: 0.5022\n",
      "[Epoch 8] current lr: 5.068493e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2372 - accuracy: 0.5140 - macro_f1: 0.5022 - val_loss: 1.3879 - val_accuracy: 0.4652 - val_macro_f1: 0.4289\n",
      "Epoch 9/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2226 - accuracy: 0.5282 - macro_f1: 0.5134\n",
      "[Epoch 9] current lr: 5.702055e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2226 - accuracy: 0.5282 - macro_f1: 0.5134 - val_loss: 1.5394 - val_accuracy: 0.4268 - val_macro_f1: 0.3987\n",
      "Epoch 10/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2022 - accuracy: 0.5322 - macro_f1: 0.5209\n",
      "[Epoch 10] current lr: 6.335616e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2022 - accuracy: 0.5322 - macro_f1: 0.5209 - val_loss: 1.9387 - val_accuracy: 0.3851 - val_macro_f1: 0.3328\n",
      "Epoch 11/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.1960 - accuracy: 0.5327 - macro_f1: 0.5240\n",
      "[Epoch 11] current lr: 6.969178e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.1960 - accuracy: 0.5327 - macro_f1: 0.5240 - val_loss: 2.2765 - val_accuracy: 0.3786 - val_macro_f1: 0.3389\n",
      "Epoch 12/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2053 - accuracy: 0.5395 - macro_f1: 0.5271\n",
      "[Epoch 12] current lr: 7.602739e-04\n",
      "37/37 [==============================] - 2s 49ms/step - loss: 1.2053 - accuracy: 0.5395 - macro_f1: 0.5271 - val_loss: 1.8128 - val_accuracy: 0.3745 - val_macro_f1: 0.3399\n",
      "Epoch 13/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2126 - accuracy: 0.5215 - macro_f1: 0.5105\n",
      "[Epoch 13] current lr: 8.236301e-04\n",
      "37/37 [==============================] - 2s 49ms/step - loss: 1.2126 - accuracy: 0.5215 - macro_f1: 0.5105 - val_loss: 1.5184 - val_accuracy: 0.3925 - val_macro_f1: 0.3620\n",
      "Epoch 14/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2366 - accuracy: 0.5192 - macro_f1: 0.5062\n",
      "[Epoch 14] current lr: 8.869863e-04\n",
      "37/37 [==============================] - 2s 49ms/step - loss: 1.2366 - accuracy: 0.5192 - macro_f1: 0.5062 - val_loss: 1.8147 - val_accuracy: 0.3704 - val_macro_f1: 0.3051\n",
      "Epoch 15/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2734 - accuracy: 0.4984 - macro_f1: 0.4853\n",
      "[Epoch 15] current lr: 9.503425e-04\n",
      "37/37 [==============================] - 2s 49ms/step - loss: 1.2734 - accuracy: 0.4984 - macro_f1: 0.4853 - val_loss: 1.4138 - val_accuracy: 0.4751 - val_macro_f1: 0.4312\n",
      "Epoch 16/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2589 - accuracy: 0.5078 - macro_f1: 0.4918\n",
      "[Epoch 16] current lr: 9.999942e-04\n",
      "37/37 [==============================] - 2s 49ms/step - loss: 1.2589 - accuracy: 0.5078 - macro_f1: 0.4918 - val_loss: 1.4701 - val_accuracy: 0.4227 - val_macro_f1: 0.3711\n",
      "Epoch 17/80\n",
      "36/37 [============================>.] - ETA: 0s - loss: 1.2419 - accuracy: 0.5104 - macro_f1: 0.4940\n",
      "[Epoch 17] current lr: 9.998191e-04\n",
      "37/37 [==============================] - 2s 50ms/step - loss: 1.2419 - accuracy: 0.5106 - macro_f1: 0.4928 - val_loss: 1.5648 - val_accuracy: 0.4186 - val_macro_f1: 0.3716\n",
      "Epoch 18/80\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.2359 - accuracy: 0.5192 - macro_f1: 0.5065\n",
      "[Epoch 18] current lr: 9.993996e-04\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 1.2359 - accuracy: 0.5192 - macro_f1: 0.5065 - val_loss: 1.6041 - val_accuracy: 0.3876 - val_macro_f1: 0.3189\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 优化器 & 学习率调度\n",
    "# =========================\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 初始学习率\n",
    "base_lr = 1e-3\n",
    "\n",
    "# Cosine Decay + Warmup 的简单实现（Keras 回调方式）\n",
    "class CosineAnnealingWithWarmup(callbacks.Callback):\n",
    "    def __init__(self, base_lr, total_steps, warmup_steps=0):\n",
    "        super().__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.global_step = 0\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.global_step += 1\n",
    "        if self.global_step < self.warmup_steps:\n",
    "            lr = self.base_lr * self.global_step / float(self.warmup_steps)\n",
    "        else:\n",
    "            progress = (self.global_step - self.warmup_steps) / float(\n",
    "                max(1, self.total_steps - self.warmup_steps)\n",
    "            )\n",
    "            lr = 0.5 * self.base_lr * (1 + math.cos(math.pi * progress))\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        print(f\"\\n[Epoch {epoch+1}] current lr: {lr:.6e}\")\n",
    "\n",
    "steps_per_epoch = math.ceil(len(X_train) / BATCH_SIZE)\n",
    "total_steps = steps_per_epoch * EPOCHS\n",
    "warmup_steps = int(0.1 * total_steps)  # 前 10% step 线性 warmup\n",
    "\n",
    "cosine_cb = CosineAnnealingWithWarmup(\n",
    "    base_lr=base_lr,\n",
    "    total_steps=total_steps,\n",
    "    warmup_steps=warmup_steps\n",
    ")\n",
    "\n",
    "early_stop_cb = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    \"../best_cnn_transformer_ser.h5\",\n",
    "    monitor=\"val_macro_f1\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# 自定义 Macro-F1 指标（tf 里以 batch 内近似，最终评估还是用 sklearn 更准）\n",
    "def macro_f1(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred_labels = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "\n",
    "    # 混淆矩阵: (num_classes, num_classes)\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred_labels,\n",
    "        num_classes=num_classes,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    # per-class precision, recall\n",
    "    tp = tf.linalg.diag_part(cm)\n",
    "    precision = tp / (tf.reduce_sum(cm, axis=0) + 1e-9)\n",
    "    recall = tp / (tf.reduce_sum(cm, axis=1) + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    return tf.reduce_mean(f1)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_lr),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", macro_f1]\n",
    ")\n",
    "\n",
    "# 训练\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[cosine_cb, early_stop_cb, checkpoint_cb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9e2a6-c4a7-4d5c-b0bc-33e8492b9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 在 Test 集上做最终评估\n",
    "# =========================\n",
    "model.load_weights(\"best_cnn_transformer_ser.h5\")  # 载入最优权重\n",
    "\n",
    "test_loss, test_acc, test_macro_f1 = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Acc : {test_acc:.4f}\")\n",
    "print(f\"Test Macro-F1: {test_macro_f1:.4f}\")\n",
    "\n",
    "# 取出预测概率和标签\n",
    "y_prob = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "# 注意：test_ds 是 batch 的，需要把 y_test 对齐一下（这里我们是直接用 X_test/y_test 组成的 test_ds，顺序一致）\n",
    "print(\"classification_report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=[EMO_MAP[c] for c in le.classes_]\n",
    "))\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[EMO_MAP[c] for c in le.classes_],\n",
    "    yticklabels=[EMO_MAP[c] for c in le.classes_]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Normalized Confusion Matrix (Test)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
