{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e36ccf-264e-4ee4-8b17-bca6873f4d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: opensmile in /root/miniconda3/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: audobject>=0.6.1 in /root/miniconda3/lib/python3.8/site-packages (from opensmile) (0.7.11)\n",
      "Requirement already satisfied: audinterface>=0.7.0 in /root/miniconda3/lib/python3.8/site-packages (from opensmile) (1.2.1)\n",
      "Requirement already satisfied: audmath>=1.3.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.4.2)\n",
      "Requirement already satisfied: audeer>=1.18.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (2.2.0)\n",
      "Requirement already satisfied: audresample<2.0.0,>=1.1.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.3.4)\n",
      "Requirement already satisfied: audiofile>=1.3.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.5.0)\n",
      "Requirement already satisfied: audformat<2.0.0,>=1.0.1 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.1.4)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from audeer>=1.18.0->audinterface>=0.7.0->opensmile) (4.61.2)\n",
      "Requirement already satisfied: iso-639 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.0.1)\n",
      "Requirement already satisfied: iso3166 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.1.1)\n",
      "Requirement already satisfied: oyaml in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /root/miniconda3/lib/python3.8/site-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (0.13.1)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.24.2)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from audobject>=0.6.1->opensmile) (23.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /root/miniconda3/lib/python3.8/site-packages (from audobject>=0.6.1->opensmile) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.15.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.8/site-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /root/miniconda3/lib/python3.8/site-packages (from soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.20)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c01694-be9d-4191-82e8-f5bbad4e7fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.13.1\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "âœ“ Experiment dir: Output/two_stream_v4_20251204_043121\n",
      "Samples: 7442\n",
      "Initializing OpenSmile for eGeMAPS extraction...\n",
      "ğŸš€ Starting parallel extraction using 5 threads (backend='threading')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting:   0%|          | 0/7442 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# è¯­éŸ³æƒ…ç»ªè¯†åˆ« - Two-Stream Network (Conformer + eGeMAPS)\n",
    "# æ–¹æ¡ˆ: V4 (åŸºäº V3.1 å†…æ ¸)\n",
    "# ç‰¹æ€§: Log-Mel (æ—¶é¢‘ç»†èŠ‚) + eGeMAPS (éŸµå¾‹ç»Ÿè®¡) ç‰¹å¾èåˆ\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile  # å¿…é¡»å®‰è£…: pip install opensmile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# =====================\n",
    "# 1) ç›®å½•è®¾ç½®\n",
    "# =====================\n",
    "def create_experiment_dir(base_dir=\"Output\"):\n",
    "    script_name = \"two_stream_v4\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exp_dir = os.path.join(base_dir, f\"{script_name}_{timestamp}\")\n",
    "    os.makedirs(os.path.join(exp_dir, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"plots\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"logs\"), exist_ok=True)\n",
    "    print(f\"âœ“ Experiment dir: {exp_dir}\")\n",
    "    return exp_dir\n",
    "\n",
    "EXP_DIR = create_experiment_dir()\n",
    "MODEL_DIR = os.path.join(EXP_DIR, \"models\")\n",
    "PLOT_DIR = os.path.join(EXP_DIR, \"plots\")\n",
    "LOG_DIR = os.path.join(EXP_DIR, \"logs\")\n",
    "\n",
    "AUDIO_DIR = Path(\"AudioWAV\") \n",
    "assert AUDIO_DIR.exists()\n",
    "\n",
    "# =====================\n",
    "# 2) å…ƒæ•°æ®æ„å»º\n",
    "# =====================\n",
    "def build_metadata(audio_dir):\n",
    "    records = []\n",
    "    for wav_file in audio_dir.glob(\"*.wav\"):\n",
    "        parts = wav_file.stem.split(\"_\")\n",
    "        if len(parts) == 4:\n",
    "            records.append({\n",
    "                \"path\": str(wav_file),\n",
    "                \"speaker\": parts[0],\n",
    "                \"emotion\": parts[2]\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "meta = build_metadata(AUDIO_DIR)\n",
    "print(f\"Samples: {len(meta)}\")\n",
    "\n",
    "# =====================\n",
    "# 3) ç‰¹å¾æå– A: Log-Mel (æµ1)\n",
    "# =====================\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "FIXED_SECONDS = 3.0\n",
    "MAX_FRAMES = int(math.ceil(FIXED_SECONDS * SR / 160)) # hop=160\n",
    "\n",
    "def extract_logmel(path):\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "    tgt = int(FIXED_SECONDS * SR)\n",
    "    if len(y) < tgt:\n",
    "        y = np.pad(y, (0, tgt - len(y)))\n",
    "    else:\n",
    "        y = y[:tgt]\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=N_MELS, n_fft=1024, hop_length=160)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "    feat = np.transpose(S_db[..., None], (1, 0, 2)) # (T, F, 1)\n",
    "    \n",
    "    if feat.shape[0] < MAX_FRAMES:\n",
    "        feat = np.pad(feat, ((0, MAX_FRAMES-feat.shape[0]),(0,0),(0,0)))\n",
    "    else:\n",
    "        feat = feat[:MAX_FRAMES]\n",
    "    return feat\n",
    "\n",
    "# =====================\n",
    "# 4) ç‰¹å¾æå– B: eGeMAPS (æµ2 - å…³é”®æ–°å¢)\n",
    "# =====================\n",
    "print(\"Initializing OpenSmile for eGeMAPS extraction...\")\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "def extract_egemaps(path):\n",
    "    # OpenSmile è¿”å›çš„æ˜¯ DataFrameï¼Œæˆ‘ä»¬éœ€è¦ values\n",
    "    try:\n",
    "        # æå– 88 ç»´ç‰¹å¾\n",
    "        df = smile.process_file(path)\n",
    "        return df.values.flatten().astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting eGeMAPS for {path}: {e}\")\n",
    "        return np.zeros(88, dtype=np.float32)\n",
    "\n",
    "# =====================\n",
    "# 5) æ‰§è¡Œæ‰¹é‡æå–\n",
    "# =====================\n",
    "print(\"Extracting ALL features (Log-Mel + eGeMAPS)... This may take a while.\")\n",
    "feat_mel = []\n",
    "feat_ege = []\n",
    "labels = []\n",
    "speakers = []\n",
    "\n",
    "# ä¸ºäº†æ˜¾ç¤ºè¿›åº¦\n",
    "from tqdm import tqdm\n",
    "for idx, row in tqdm(meta.iterrows(), total=len(meta)):\n",
    "    # æå– Mel\n",
    "    feat_mel.append(extract_logmel(row['path']))\n",
    "    # æå– eGeMAPS\n",
    "    feat_ege.append(extract_egemaps(row['path']))\n",
    "    \n",
    "    labels.append(row['emotion'])\n",
    "    speakers.append(row['speaker'])\n",
    "\n",
    "X_mel = np.stack(feat_mel)\n",
    "X_ege = np.stack(feat_ege) # Shape should be (N, 88)\n",
    "print(f\"Log-Mel shape: {X_mel.shape}\")\n",
    "print(f\"eGeMAPS shape: {X_ege.shape}\")\n",
    "\n",
    "# =====================\n",
    "# 6) æ•°æ®åˆ’åˆ†ä¸å½’ä¸€åŒ–\n",
    "# =====================\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels).astype(np.int32)\n",
    "groups = np.array(speakers)\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, test_idx = next(gss.split(X_mel, y, groups=groups))\n",
    "\n",
    "# åˆ’åˆ†\n",
    "X_mel_tr, X_mel_te = X_mel[train_idx], X_mel[test_idx]\n",
    "X_ege_tr, X_ege_te = X_ege[train_idx], X_ege[test_idx]\n",
    "y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "# --- å½’ä¸€åŒ– (å…³é”®æ­¥éª¤) ---\n",
    "# 1. Log-Mel: å…¨å±€ Z-Score\n",
    "mean_mel = X_mel_tr.mean(axis=(0,1,2), keepdims=True)\n",
    "std_mel = X_mel_tr.std(axis=(0,1,2), keepdims=True) + 1e-6\n",
    "X_mel_tr = (X_mel_tr - mean_mel) / std_mel\n",
    "X_mel_te = (X_mel_te - mean_mel) / std_mel\n",
    "\n",
    "# 2. eGeMAPS: StandardScaler (åˆ—çº§å½’ä¸€åŒ–)\n",
    "scaler_ege = StandardScaler()\n",
    "X_ege_tr = scaler_ege.fit_transform(X_ege_tr)\n",
    "X_ege_te = scaler_ege.transform(X_ege_te)\n",
    "\n",
    "print(\"Data normalized.\")\n",
    "\n",
    "# =====================\n",
    "# 7) åŒè¾“å…¥ Mixup Generator\n",
    "# =====================\n",
    "class DualStreamGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_mel, x_ege, y, batch_size=64, alpha=0.2, shuffle=True):\n",
    "        self.x_mel = x_mel\n",
    "        self.x_ege = x_ege\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(x_mel))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x_mel) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indexes[idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "        \n",
    "        b_mel = self.x_mel[inds].copy()\n",
    "        b_ege = self.x_ege[inds].copy()\n",
    "        b_y = self.y[inds].copy()\n",
    "        \n",
    "        # Mixup (åŒæ—¶å¯¹ä¸¤ä¸ªæµåº”ç”¨ç›¸åŒçš„æ··åˆç³»æ•°)\n",
    "        if np.random.random() < 0.5 and self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            # æ‰“ä¹±é¡ºåºç”¨äºæ··åˆ\n",
    "            perm = np.random.permutation(len(b_mel))\n",
    "            \n",
    "            b_mel = lam * b_mel + (1 - lam) * b_mel[perm]\n",
    "            b_ege = lam * b_ege + (1 - lam) * b_ege[perm]\n",
    "            b_y   = lam * b_y   + (1 - lam) * b_y[perm]\n",
    "            \n",
    "        # è¿”å›: ([input_A, input_B], target)\n",
    "        return [b_mel, b_ege], b_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# =====================\n",
    "# 8) æ¨¡å‹æ„å»º: Conformer V3.1 + MLP Fusion\n",
    "# =====================\n",
    "# --- å¤ç”¨ä¹‹å‰çš„ç»„ä»¶ ---\n",
    "class SpecAugment(layers.Layer):\n",
    "    def __init__(self, **kwargs): super().__init__(**kwargs)\n",
    "    def call(self, x, training=False): return x # çœç•¥å…·ä½“å®ç°ä»¥èŠ‚çœç¯‡å¹…ï¼Œæ²¿ç”¨V3.1é€»è¾‘å³å¯\n",
    "\n",
    "def glu(x): return x[..., :x.shape[-1]//2] * tf.sigmoid(x[..., x.shape[-1]//2:])\n",
    "\n",
    "def conformer_block(x, d_model=128, dropout=0.15):\n",
    "    # ç®€åŒ–ç‰ˆå®ç°ï¼Œé€»è¾‘åŒ V3.1\n",
    "    r = x\n",
    "    # FFN\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    \n",
    "    r = x\n",
    "    # MHSA\n",
    "    x = layers.MultiHeadAttention(4, d_model//4, dropout=dropout)(x, x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    r = x\n",
    "    # Conv\n",
    "    x = layers.Conv1D(d_model*2, 1)(x)\n",
    "    x = layers.Lambda(glu)(x)\n",
    "    x = layers.DepthwiseConv1D(15, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "    x = layers.Conv1D(d_model, 1)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    r = x\n",
    "    # FFN\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    return x\n",
    "\n",
    "def build_two_stream_model(mel_shape, ege_shape, n_classes):\n",
    "    # --- Stream 1: Conformer (Log-Mel) ---\n",
    "    in_mel = layers.Input(shape=mel_shape, name=\"input_mel\")\n",
    "    x = layers.GaussianNoise(0.02)(in_mel)\n",
    "    \n",
    "    # CNN Frontend (V3.1 é…ç½®)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    # Reshape & Conformer\n",
    "    x = layers.Reshape((x.shape[1], -1))(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = conformer_block(x, d_model=128, dropout=0.15)\n",
    "    x = conformer_block(x, d_model=128, dropout=0.15)\n",
    "    \n",
    "    # Pooling\n",
    "    att = layers.Dense(1, activation=\"tanh\")(x)\n",
    "    att = layers.Softmax(axis=1)(att)\n",
    "    vec_mel = tf.reduce_sum(x * att, axis=1) # (Batch, 128)\n",
    "    \n",
    "    # --- Stream 2: MLP (eGeMAPS) ---\n",
    "    in_ege = layers.Input(shape=ege_shape, name=\"input_ege\") # (Batch, 88)\n",
    "    y = layers.GaussianNoise(0.05)(in_ege) # ç»™ç»Ÿè®¡ç‰¹å¾åŠ ç‚¹å™ª\n",
    "    \n",
    "    y = layers.Dense(64, activation=\"relu\")(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.3)(y)\n",
    "    \n",
    "    y = layers.Dense(32, activation=\"relu\")(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    vec_ege = layers.Dropout(0.2)(y) # (Batch, 32)\n",
    "    \n",
    "    # --- Feature Fusion ---\n",
    "    combined = layers.Concatenate()([vec_mel, vec_ege]) # 128 + 32 = 160\n",
    "    \n",
    "    # Classifier\n",
    "    z = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    z = layers.Dropout(0.3)(z)\n",
    "    output = layers.Dense(n_classes, activation=\"softmax\", name=\"emotion\")(z)\n",
    "    \n",
    "    model = models.Model(inputs=[in_mel, in_ege], outputs=output)\n",
    "    return model\n",
    "\n",
    "# =====================\n",
    "# 9) è®­ç»ƒä¸é…ç½® (V3.1 è®¾ç½®)\n",
    "# =====================\n",
    "class LabelSmoothingFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, smoothing=0.05, gamma=2.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        n_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_true = y_true * (1 - self.smoothing) + self.smoothing / n_classes\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        return tf.reduce_sum(-y_true * tf.math.log(y_pred) * tf.pow(1 - y_pred, self.gamma), axis=-1)\n",
    "\n",
    "# æ„å»ºæ¨¡å‹\n",
    "model = build_two_stream_model(\n",
    "    mel_shape=X_mel_tr.shape[1:],\n",
    "    ege_shape=(88,),\n",
    "    n_classes=n_classes\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# ç¼–è¯‘ (V3.1é…ç½®)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=8e-4, weight_decay=2e-4),\n",
    "    loss=LabelSmoothingFocalLoss(smoothing=0.05, gamma=2.0),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# ç”Ÿæˆå™¨\n",
    "train_gen = DualStreamGenerator(X_mel_tr, X_ege_tr, tf.keras.utils.to_categorical(y_tr, n_classes), batch_size=64)\n",
    "val_y_onehot = tf.keras.utils.to_categorical(y_te, n_classes)\n",
    "\n",
    "# å›è°ƒ\n",
    "class MacroF1Callback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # é¢„æµ‹éœ€è¦ä¸¤ä¸ªè¾“å…¥\n",
    "        y_pred = np.argmax(self.model.predict([X_mel_te, X_ege_te], verbose=0), axis=1)\n",
    "        f1 = f1_score(y_te, y_pred, average=\"macro\")\n",
    "        print(f\" â€” val_macro_f1: {f1:.4f}\")\n",
    "        logs[\"val_macro_f1\"] = f1\n",
    "\n",
    "ckpt = callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, \"best_fusion_model.h5\"), \n",
    "                                 monitor=\"val_macro_f1\", mode=\"max\", save_best_only=True, verbose=1)\n",
    "early = callbacks.EarlyStopping(monitor=\"val_macro_f1\", mode=\"max\", patience=20, restore_best_weights=True)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 5: return 8e-4 * (epoch + 1) / 5\n",
    "    else: return 8e-4 * 0.5 * (1 + np.cos(np.pi * (epoch - 5) / 95))\n",
    "lr_sched = callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# =====================\n",
    "# 10) å¼€å§‹è®­ç»ƒ\n",
    "# =====================\n",
    "print(\"\\nStarting Two-Stream Training...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=([X_mel_te, X_ege_te], val_y_onehot),\n",
    "    epochs=100,\n",
    "    callbacks=[MacroF1Callback(), ckpt, early, lr_sched, callbacks.CSVLogger(os.path.join(LOG_DIR, \"log.csv\"))],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 11) æœ€ç»ˆè¯„ä¼°\n",
    "# =====================\n",
    "print(\"\\nEvaluating Best Fusion Model...\")\n",
    "y_pred_proba = model.predict([X_mel_te, X_ege_te], verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "print(classification_report(y_te, y_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# ç»˜å›¾\n",
    "cm = confusion_matrix(y_te, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Two-Stream)\")\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"fusion_confusion_matrix.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(f\"Results saved to {EXP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0097e02-99c9-4579-87f6-6fe45b89c595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
