{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb78e637-fe5f-412a-badc-67cd23bb79b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:26:45.274683: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 05:26:45.343803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 05:26:46.472397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files...\n",
      "Extracting features for 7442 files...\n",
      "Processing 0...\n",
      "Processing 500...\n",
      "Processing 1000...\n",
      "Processing 2000...\n",
      "Processing 2500...\n",
      "Processing 3000...\n",
      "Processing 3500...\n",
      "Processing 4000...\n",
      "Processing 4500...\n",
      "Processing 5000...\n",
      "Processing 5500...\n",
      "Processing 6000...\n",
      "Processing 6500...\n",
      "Processing 7000...\n",
      "Train shape: Mel (5890, 300, 64, 1), eGe (5890, 88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:41:03.749161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:03.0, compute capability: 7.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got '<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7fb589f45fa0>' (of type <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>) as input for layer 'max_pooling2d'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 278\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m): np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# 编译\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_cross_fusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_mel_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m88\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    280\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdamW(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8e-4\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-4\u001b[39m),\n\u001b[1;32m    281\u001b[0m     loss\u001b[38;5;241m=\u001b[39mLabelSmoothingFocalLoss(smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m),\n\u001b[1;32m    282\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[1], line 201\u001b[0m, in \u001b[0;36mbuild_cross_fusion_model\u001b[0;34m(mel_shape, ege_shape, n_classes, d_model)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# CNN Front-end\u001b[39;00m\n\u001b[1;32m    200\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_regularizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mregularizers\u001b[38;5;241m.\u001b[39ml2(\u001b[38;5;241m5e-5\u001b[39m))(x)\n\u001b[0;32m--> 201\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization(); x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_regularizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mregularizers\u001b[38;5;241m.\u001b[39ml2(\u001b[38;5;241m5e-5\u001b[39m))(x)\n\u001b[1;32m    203\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization(); x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/src/engine/input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got '<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7fb589f45fa0>' (of type <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>) as input for layer 'max_pooling2d'."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Two-Stream V4.1 - Cross-Attention Fusion\n",
    "# 核心思想：利用 eGeMAPS 全局特征作为 Context，通过 Attention 指导 Log-Mel 序列特征\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# 1. 基础配置\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 自动生成目录\n",
    "def create_experiment_dir(base_dir=\"Output\"):\n",
    "    script_name = \"twostream_v4_1_crossattn\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exp_dir = os.path.join(base_dir, f\"{script_name}_{timestamp}\")\n",
    "    os.makedirs(os.path.join(exp_dir, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"plots\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"logs\"), exist_ok=True)\n",
    "    return exp_dir, os.path.join(exp_dir, \"models\"), os.path.join(exp_dir, \"plots\"), os.path.join(exp_dir, \"logs\")\n",
    "\n",
    "EXP_DIR, MODEL_DIR, PLOT_DIR, LOG_DIR = create_experiment_dir()\n",
    "AUDIO_DIR = Path(\"AudioWAV\") \n",
    "\n",
    "# =====================\n",
    "# 2. 特征提取 (Log-Mel + eGeMAPS)\n",
    "# =====================\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "FIXED_SECONDS = 3.0\n",
    "MAX_FRAMES = int(math.ceil(FIXED_SECONDS * SR / 160))\n",
    "\n",
    "# 初始化 OpenSmile\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "def load_data_and_extract(audio_dir):\n",
    "    print(\"Scanning files...\")\n",
    "    paths, emotions, speakers = [], [], []\n",
    "    for f in audio_dir.glob(\"*.wav\"):\n",
    "        parts = f.stem.split(\"_\")\n",
    "        if len(parts) == 4:\n",
    "            paths.append(f); emotions.append(parts[2]); speakers.append(parts[0])\n",
    "    \n",
    "    print(f\"Extracting features for {len(paths)} files...\")\n",
    "    X_mel, X_ege = [], []\n",
    "    \n",
    "    for i, p in enumerate(paths):\n",
    "        if i % 500 == 0: print(f\"Processing {i}...\")\n",
    "        \n",
    "        # A. Log-Mel\n",
    "        y, _ = librosa.load(p, sr=SR, mono=True)\n",
    "        tgt = int(FIXED_SECONDS * SR)\n",
    "        if len(y) < tgt: y = np.pad(y, (0, tgt-len(y)))\n",
    "        else: y = y[:tgt]\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=N_MELS, hop_length=160)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "        feat = np.transpose(S_db[..., None], (1, 0, 2))\n",
    "        if feat.shape[0] < MAX_FRAMES:\n",
    "            feat = np.pad(feat, ((0, MAX_FRAMES-feat.shape[0]),(0,0),(0,0)))\n",
    "        else: feat = feat[:MAX_FRAMES]\n",
    "        X_mel.append(feat)\n",
    "        \n",
    "        # B. eGeMAPS (Functionals)\n",
    "        try:\n",
    "            ege = smile.process_file(p).values.flatten().astype(np.float32)\n",
    "            # 简单的NaN处理\n",
    "            if np.isnan(ege).any(): ege = np.nan_to_num(ege)\n",
    "            X_ege.append(ege)\n",
    "        except:\n",
    "            X_ege.append(np.zeros(88, dtype=np.float32))\n",
    "            \n",
    "    return np.stack(X_mel), np.stack(X_ege), np.array(emotions), np.array(speakers)\n",
    "\n",
    "# 执行提取 (如果是Notebook环境，确保只运行一次)\n",
    "if 'X_mel_all' not in globals():\n",
    "    X_mel_all, X_ege_all, y_all, spk_all = load_data_and_extract(AUDIO_DIR)\n",
    "\n",
    "# =====================\n",
    "# 3. 数据准备\n",
    "# =====================\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_all)\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "# 划分\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "tr_idx, te_idx = next(gss.split(X_mel_all, y_enc, groups=spk_all))\n",
    "\n",
    "X_mel_tr, X_mel_te = X_mel_all[tr_idx], X_mel_all[te_idx]\n",
    "X_ege_tr, X_ege_te = X_ege_all[tr_idx], X_ege_all[te_idx]\n",
    "y_tr, y_te = y_enc[tr_idx], y_enc[te_idx]\n",
    "\n",
    "# 归一化\n",
    "# Log-Mel: Global Z-Score\n",
    "mean_mel = X_mel_tr.mean(axis=(0,1,2), keepdims=True)\n",
    "std_mel = X_mel_tr.std(axis=(0,1,2), keepdims=True) + 1e-6\n",
    "X_mel_tr = (X_mel_tr - mean_mel) / std_mel\n",
    "X_mel_te = (X_mel_te - mean_mel) / std_mel\n",
    "\n",
    "# eGeMAPS: StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_ege_tr = scaler.fit_transform(X_ege_tr)\n",
    "X_ege_te = scaler.transform(X_ege_te)\n",
    "\n",
    "print(f\"Train shape: Mel {X_mel_tr.shape}, eGe {X_ege_tr.shape}\")\n",
    "\n",
    "# =====================\n",
    "# 4. 核心组件：Conformer & Cross-Attention\n",
    "# =====================\n",
    "def glu(x): return x[..., :x.shape[-1]//2] * tf.sigmoid(x[..., x.shape[-1]//2:])\n",
    "\n",
    "def conformer_block(x, d_model=128, dropout=0.15):\n",
    "    # FFN 1\n",
    "    r = x\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    \n",
    "    # MHSA\n",
    "    r = x\n",
    "    x = layers.MultiHeadAttention(4, d_model//4, dropout=dropout)(x, x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    # Conv\n",
    "    r = x\n",
    "    x = layers.Conv1D(d_model*2, 1)(x)\n",
    "    x = layers.Lambda(glu)(x)\n",
    "    x = layers.DepthwiseConv1D(15, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "    x = layers.Conv1D(d_model, 1)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    # FFN 2\n",
    "    r = x\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    return x\n",
    "\n",
    "# === 关键修改：互注意力融合层 ===\n",
    "class CrossAttentionFusion(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=4, key_dim=d_model//4, dropout=dropout)\n",
    "        self.layernorm = layers.LayerNormalization()\n",
    "        self.add = layers.Add()\n",
    "        \n",
    "    def call(self, sequence, context):\n",
    "        # sequence: (B, T, D) -> Query\n",
    "        # context: (B, D_ctx) -> Key, Value\n",
    "        \n",
    "        # 1. Expand context to be sequence-like for attention\n",
    "        # context: (B, 1, D)\n",
    "        context = tf.expand_dims(context, axis=1)\n",
    "        \n",
    "        # 2. Cross Attention\n",
    "        # Query = sequence (Conformer features)\n",
    "        # Key/Value = context (eGeMAPS features)\n",
    "        # 这样模型会根据 eGeMAPS 的信息，去“关注”序列中特定的时间步\n",
    "        attn_out = self.mha(query=sequence, value=context, key=context)\n",
    "        \n",
    "        # 3. Residual Connection + Norm\n",
    "        # 将 Attention 的结果加回原序列，实现“调制”效果\n",
    "        x = self.add([sequence, attn_out])\n",
    "        return self.layernorm(x)\n",
    "\n",
    "# =====================\n",
    "# 5. 模型构建 (修复版)\n",
    "# =====================\n",
    "def build_cross_fusion_model(mel_shape, ege_shape, n_classes, d_model=128):\n",
    "    # --- Stream 1: Conformer ---\n",
    "    in_mel = layers.Input(shape=mel_shape)\n",
    "    x = layers.GaussianNoise(0.02)(in_mel) \n",
    "    \n",
    "    # CNN Front-end\n",
    "    # === 修复点开始 ===\n",
    "    # 必须在 BatchNormalization() 后面加上 (x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)  # 注意这里加上了 (x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)  # 注意这里加上了 (x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)  # 注意这里加上了 (x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    # === 修复点结束 ===\n",
    "    \n",
    "    x = layers.Reshape((-1, x.shape[-1]))(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.Dropout(0.15)(x)\n",
    "    \n",
    "    # Conformer Encoders\n",
    "    x = conformer_block(x, d_model, dropout=0.15)\n",
    "    x = conformer_block(x, d_model, dropout=0.15)\n",
    "    \n",
    "    # --- Stream 2: eGeMAPS Context ---\n",
    "    in_ege = layers.Input(shape=ege_shape)\n",
    "    c = layers.GaussianNoise(0.05)(in_ege)\n",
    "    c = layers.Dense(d_model, activation='relu')(c)\n",
    "    c = layers.BatchNormalization()(c) # 这里你也漏了 (c)，但我顺手帮你补上了\n",
    "    c = layers.Dropout(0.3)(c) \n",
    "    \n",
    "    # --- Fusion: Cross-Attention ---\n",
    "    fused_seq = CrossAttentionFusion(d_model, dropout=0.2)(sequence=x, context=c)\n",
    "    \n",
    "    # --- Pooling & Classification ---\n",
    "    att = layers.Dense(1, activation=\"tanh\")(fused_seq)\n",
    "    att = layers.Softmax(axis=1)(att)\n",
    "    pooled = tf.reduce_sum(fused_seq * att, axis=1)\n",
    "    \n",
    "    final_vec = layers.Concatenate()([pooled, c])\n",
    "    \n",
    "    z = layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(5e-5))(final_vec)\n",
    "    z = layers.Dropout(0.3)(z)\n",
    "    out = layers.Dense(n_classes, activation=\"softmax\", name=\"emotion\")(z)\n",
    "    \n",
    "    return models.Model(inputs=[in_mel, in_ege], outputs=out)\n",
    "\n",
    "# =====================\n",
    "# 6. 训练配置\n",
    "# =====================\n",
    "class LabelSmoothingFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, smoothing=0.05, gamma=2.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "    def call(self, y_true, y_pred):\n",
    "        n = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = y_true * (1 - self.smoothing) + self.smoothing / n\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        return tf.reduce_sum(-y_true * tf.math.log(y_pred) * tf.pow(1 - y_pred, self.gamma), axis=-1)\n",
    "\n",
    "# Generator (Mixup)\n",
    "class DualMixupGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x1, x2, y, batch=64, alpha=0.2):\n",
    "        self.x1, self.x2, self.y = x1, x2, y\n",
    "        self.batch, self.alpha = batch, alpha\n",
    "        self.idx = np.arange(len(x1))\n",
    "        np.random.shuffle(self.idx)\n",
    "    def __len__(self): return int(np.ceil(len(self.x1)/self.batch))\n",
    "    def __getitem__(self, i):\n",
    "        inds = self.idx[i*self.batch:(i+1)*self.batch]\n",
    "        bx1, bx2, by = self.x1[inds], self.x2[inds], self.y[inds]\n",
    "        if np.random.random()<0.5: # Mixup\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            perm = np.random.permutation(len(bx1))\n",
    "            bx1 = lam*bx1 + (1-lam)*bx1[perm]\n",
    "            bx2 = lam*bx2 + (1-lam)*bx2[perm]\n",
    "            by = lam*by + (1-lam)*by[perm]\n",
    "        return [bx1, bx2], by\n",
    "    def on_epoch_end(self): np.random.shuffle(self.idx)\n",
    "\n",
    "# 编译\n",
    "model = build_cross_fusion_model(X_mel_tr.shape[1:], (88,), n_classes)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=8e-4, weight_decay=2e-4),\n",
    "    loss=LabelSmoothingFocalLoss(smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# 训练\n",
    "y_tr_oh = tf.keras.utils.to_categorical(y_tr)\n",
    "y_te_oh = tf.keras.utils.to_categorical(y_te)\n",
    "gen = DualMixupGen(X_mel_tr, X_ege_tr, y_tr_oh, batch=64)\n",
    "\n",
    "# Callbacks\n",
    "class F1Cb(callbacks.Callback):\n",
    "    def on_epoch_end(self, e, logs):\n",
    "        p = np.argmax(self.model.predict([X_mel_te, X_ege_te], verbose=0), axis=1)\n",
    "        f1 = f1_score(y_te, p, average='macro')\n",
    "        print(f\" — val_f1: {f1:.4f}\")\n",
    "        logs['val_macro_f1'] = f1\n",
    "\n",
    "ckpt = callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, \"best.h5\"), monitor='val_macro_f1', mode='max', save_best_only=True, verbose=1)\n",
    "early = callbacks.EarlyStopping(monitor='val_macro_f1', mode='max', patience=25, restore_best_weights=True)\n",
    "def sched(e): return 8e-4 * (e+1)/5 if e<5 else 8e-4 * 0.5 * (1+np.cos(np.pi*(e-5)/95))\n",
    "\n",
    "print(\"Starting Cross-Attention Fusion Training...\")\n",
    "history = model.fit(\n",
    "    gen, \n",
    "    validation_data=([X_mel_te, X_ege_te], y_te_oh),\n",
    "    epochs=100,\n",
    "    callbacks=[F1Cb(), ckpt, early, callbacks.LearningRateScheduler(sched)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 7. 评估\n",
    "# =====================\n",
    "print(\"Evaluating...\")\n",
    "p = np.argmax(model.predict([X_mel_te, X_ege_te], verbose=0), axis=1)\n",
    "print(classification_report(y_te, p, target_names=le.classes_, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_te, p)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix (Cross-Attn Fusion)\")\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"cm.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ca5b9-aa5f-4cf0-9221-9c6aac9e9614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
