{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aaec574-52c2-4db8-9db3-c8d67dfb8ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 05:32:04.307330: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-28 05:32:04.369247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-28 05:32:05.389604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.1\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✓ Experiment directory created: /mnt/user-data/outputs/conformer_v3_20251128_053206\n",
      "Total samples: 7442\n",
      "Emotion distribution:\n",
      "emotion\n",
      "ANG    1271\n",
      "DIS    1271\n",
      "FEA    1271\n",
      "HAP    1271\n",
      "SAD    1271\n",
      "NEU    1087\n",
      "Name: count, dtype: int64\n",
      "Feature shape: (300, 64, 1)\n",
      "Extracting features...\n",
      "  Processing 0/7442...\n",
      "  Processing 500/7442...\n",
      "  Processing 1000/7442...\n",
      "  Processing 1500/7442...\n",
      "  Processing 2000/7442...\n",
      "  Processing 2500/7442...\n",
      "  Processing 3000/7442...\n",
      "  Processing 3500/7442...\n",
      "  Processing 4000/7442...\n",
      "  Processing 4500/7442...\n",
      "  Processing 5000/7442...\n",
      "  Processing 5500/7442...\n",
      "  Processing 6000/7442...\n",
      "  Processing 6500/7442...\n",
      "  Processing 7000/7442...\n",
      "Feature matrix shape: (7442, 300, 64, 1)\n",
      "Classes: ['ANG' 'DIS' 'FEA' 'HAP' 'NEU' 'SAD']\n",
      "Number of classes: 6\n",
      "Train: (5890, 300, 64, 1), Test: (1552, 300, 64, 1)\n",
      "Normalized - Train mean: -0.0000, std: 1.0000\n",
      "\n",
      "============================================================\n",
      "Speech Emotion Recognition - Conformer V3\n",
      "Dataset: CREMA-D\n",
      "Experiment Directory: /mnt/user-data/outputs/conformer_v3_20251128_053206\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 05:33:02.348998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:01.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 300, 64, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNo  (None, 300, 64, 1)           0         ['input_1[0][0]']             \n",
      " ise)                                                                                             \n",
      "                                                                                                  \n",
      " spec_augment (SpecAugment)  (None, 300, 64, 1)           0         ['gaussian_noise[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 300, 64, 32)          320       ['spec_augment[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 300, 64, 32)          832       ['spec_augment[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 300, 64, 32)          1600      ['spec_augment[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 300, 64, 96)          0         ['conv2d[0][0]',              \n",
      "                                                                     'conv2d_1[0][0]',            \n",
      "                                                                     'conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 300, 64, 96)          384       ['concatenate[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 96)                   0         ['batch_normalization[0][0]'] \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 12)                   1164      ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 96)                   1248      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 1, 96)             0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 300, 64, 96)          0         ['batch_normalization[0][0]', \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 150, 32, 96)          0         ['multiply[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 150, 32, 128)         110720    ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 150, 32, 128)         512       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 128)                  0         ['batch_normalization_1[0][0]'\n",
      "  (GlobalAveragePooling2D)                                          ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   2064      ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  2176      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 1, 128)            0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 150, 32, 128)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    , 'reshape_1[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 75, 16, 128)          0         ['multiply_1[0][0]']          \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout2d (Spatial  (None, 75, 16, 128)          0         ['max_pooling2d_1[0][0]']     \n",
      " Dropout2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 75, 16, 256)          295168    ['spatial_dropout2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 75, 16, 256)          1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 256)                  0         ['batch_normalization_2[0][0]'\n",
      "  (GlobalAveragePooling2D)                                          ]                             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   8224      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 256)                  8448      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 1, 256)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 75, 16, 256)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    , 'reshape_2[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 37, 8, 256)           0         ['multiply_2[0][0]']          \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (Spati  (None, 37, 8, 256)           0         ['max_pooling2d_2[0][0]']     \n",
      " alDropout2D)                                                                                     \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 37, 2048)             0         ['spatial_dropout2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 37, 128)              262272    ['reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 37, 128)              0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 37, 512)              66048     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 37, 512)              0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 37, 128)              65664     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 37, 128)              0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 37, 128)              0         ['dropout_2[0][0]']           \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 37, 128)              0         ['dropout[0][0]',             \n",
      " Lambda)                                                             'tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 37, 128)              256       ['tf.__operators__.add[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 37, 128)              66048     ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 37, 128)              0         ['layer_normalization[0][0]', \n",
      " OpLambda)                                                           'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_1[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 37, 256)              33024     ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 37, 128)              0         ['conv1d[0][0]']              \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 37, 128)              0         ['conv1d[0][0]']              \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambd  (None, 37, 128)              0         ['tf.__operators__.getitem_1[0\n",
      " a)                                                                 ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 37, 128)              0         ['tf.__operators__.getitem[0][\n",
      " mbda)                                                              0]',                          \n",
      "                                                                     'tf.math.sigmoid[0][0]']     \n",
      "                                                                                                  \n",
      " depthwise_conv1d (Depthwis  (None, 37, 128)              2048      ['tf.math.multiply_1[0][0]']  \n",
      " eConv1D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 37, 128)              512       ['depthwise_conv1d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 37, 128)              0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 37, 128)              16512     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 37, 128)              0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 37, 128)              0         ['layer_normalization_1[0][0]'\n",
      " OpLambda)                                                          , 'dropout_3[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 37, 512)              66048     ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 37, 512)              0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 37, 128)              65664     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 37, 128)              0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 37, 128)              0         ['dropout_5[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 37, 128)              0         ['layer_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 37, 512)              66048     ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 37, 512)              0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 37, 128)              65664     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 37, 128)              0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (None, 37, 128)              0         ['dropout_7[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 37, 128)              0         ['layer_normalization_3[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_4[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 37, 128)              66048     ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 37, 128)              0         ['layer_normalization_4[0][0]'\n",
      " OpLambda)                                                          , 'multi_head_attention_1[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_5[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 37, 256)              33024     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 37, 128)              0         ['conv1d_2[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 37, 128)              0         ['conv1d_2[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_1 (TFOpLam  (None, 37, 128)              0         ['tf.__operators__.getitem_3[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (None, 37, 128)              0         ['tf.__operators__.getitem_2[0\n",
      " mbda)                                                              ][0]',                        \n",
      "                                                                     'tf.math.sigmoid_1[0][0]']   \n",
      "                                                                                                  \n",
      " depthwise_conv1d_1 (Depthw  (None, 37, 128)              2048      ['tf.math.multiply_4[0][0]']  \n",
      " iseConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 37, 128)              512       ['depthwise_conv1d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 37, 128)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 37, 128)              16512     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 37, 128)              0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 37, 128)              0         ['layer_normalization_5[0][0]'\n",
      " OpLambda)                                                          , 'dropout_8[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_6[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 37, 512)              66048     ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 37, 512)              0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 37, 128)              65664     ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 37, 128)              0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (None, 37, 128)              0         ['dropout_10[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 37, 128)              0         ['layer_normalization_6[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_7[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 37, 1)                129       ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " softmax (Softmax)           (None, 37, 1)                0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (None, 37, 128)              0         ['layer_normalization_7[0][0]'\n",
      " mbda)                                                              , 'softmax[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLa  (None, 128)                  0         ['tf.math.multiply_6[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 128)                  0         ['tf.math.reduce_sum[0][0]']  \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 64)                   8256      ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 64)                   0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " emotion (Dense)             (None, 6)                    390       ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1470115 (5.61 MB)\n",
      "Trainable params: 1468643 (5.60 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "============================================================\n",
      "Starting Conformer V3 training...\n",
      "Output directory: /mnt/user-data/outputs/conformer_v3_20251128_053206\n",
      "============================================================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 05:33:13.753466: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/spatial_dropout2d/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-11-28 05:33:15.289419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-11-28 05:33:15.850674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3db803bbf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-28 05:33:15.850713: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-11-28 05:33:15.857763: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-28 05:33:16.016282: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - ETA: 0s - loss: 1.2286 - accuracy: 0.2698 — val_macro_f1: 0.0486 ★ New Best!\n",
      "\n",
      "Epoch 1: val_macro_f1 improved from -inf to 0.04861, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 39s 170ms/step - loss: 1.2286 - accuracy: 0.2698 - val_loss: 2.5991 - val_accuracy: 0.1707 - val_macro_f1: 0.0486 - lr: 1.6000e-04\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.1343 - accuracy: 0.3273 — val_macro_f1: 0.1143 ★ New Best!\n",
      "\n",
      "Epoch 2: val_macro_f1 improved from 0.04861 to 0.11427, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 1.1343 - accuracy: 0.3273 - val_loss: 2.4026 - val_accuracy: 0.2165 - val_macro_f1: 0.1143 - lr: 3.2000e-04\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.1092 - accuracy: 0.3329 — val_macro_f1: 0.0593\n",
      "\n",
      "Epoch 3: val_macro_f1 did not improve from 0.11427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 1.1092 - accuracy: 0.3329 - val_loss: 1.7850 - val_accuracy: 0.1746 - val_macro_f1: 0.0593 - lr: 4.8000e-04\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0988 - accuracy: 0.3477 — val_macro_f1: 0.2786 ★ New Best!\n",
      "\n",
      "Epoch 4: val_macro_f1 improved from 0.11427 to 0.27861, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 1.0988 - accuracy: 0.3477 - val_loss: 1.1005 - val_accuracy: 0.3177 - val_macro_f1: 0.2786 - lr: 6.4000e-04\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.3645 — val_macro_f1: 0.3375 ★ New Best!\n",
      "\n",
      "Epoch 5: val_macro_f1 improved from 0.27861 to 0.33748, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 1.0626 - accuracy: 0.3645 - val_loss: 1.0039 - val_accuracy: 0.3860 - val_macro_f1: 0.3375 - lr: 8.0000e-04\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0401 - accuracy: 0.3830 — val_macro_f1: 0.3655 ★ New Best!\n",
      "\n",
      "Epoch 6: val_macro_f1 improved from 0.33748 to 0.36551, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 1.0401 - accuracy: 0.3830 - val_loss: 0.9924 - val_accuracy: 0.4195 - val_macro_f1: 0.3655 - lr: 8.0000e-04\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.4107 — val_macro_f1: 0.3841 ★ New Best!\n",
      "\n",
      "Epoch 7: val_macro_f1 improved from 0.36551 to 0.38415, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 1.0106 - accuracy: 0.4107 - val_loss: 0.9734 - val_accuracy: 0.4246 - val_macro_f1: 0.3841 - lr: 7.9978e-04\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.4299 — val_macro_f1: 0.4420 ★ New Best!\n",
      "\n",
      "Epoch 8: val_macro_f1 improved from 0.38415 to 0.44197, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 1.0047 - accuracy: 0.4299 - val_loss: 0.9170 - val_accuracy: 0.4691 - val_macro_f1: 0.4420 - lr: 7.9913e-04\n",
      "Epoch 9/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.4660 — val_macro_f1: 0.4280\n",
      "\n",
      "Epoch 9: val_macro_f1 did not improve from 0.44197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.9679 - accuracy: 0.4660 - val_loss: 0.9570 - val_accuracy: 0.4452 - val_macro_f1: 0.4280 - lr: 7.9803e-04\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9721 - accuracy: 0.4523 — val_macro_f1: 0.4605 ★ New Best!\n",
      "\n",
      "Epoch 10: val_macro_f1 improved from 0.44197 to 0.46055, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 0.9721 - accuracy: 0.4523 - val_loss: 0.9204 - val_accuracy: 0.4800 - val_macro_f1: 0.4605 - lr: 7.9651e-04\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9496 - accuracy: 0.4812 — val_macro_f1: 0.4729 ★ New Best!\n",
      "\n",
      "Epoch 11: val_macro_f1 improved from 0.46055 to 0.47287, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.9496 - accuracy: 0.4812 - val_loss: 0.9056 - val_accuracy: 0.4884 - val_macro_f1: 0.4729 - lr: 7.9454e-04\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9525 - accuracy: 0.4771 — val_macro_f1: 0.4664\n",
      "\n",
      "Epoch 12: val_macro_f1 did not improve from 0.47287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.9525 - accuracy: 0.4771 - val_loss: 0.9200 - val_accuracy: 0.4890 - val_macro_f1: 0.4664 - lr: 7.9215e-04\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9078 - accuracy: 0.5012 — val_macro_f1: 0.4858 ★ New Best!\n",
      "\n",
      "Epoch 13: val_macro_f1 improved from 0.47287 to 0.48576, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.9078 - accuracy: 0.5012 - val_loss: 0.8864 - val_accuracy: 0.4981 - val_macro_f1: 0.4858 - lr: 7.8933e-04\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8928 - accuracy: 0.5199 — val_macro_f1: 0.4563\n",
      "\n",
      "Epoch 14: val_macro_f1 did not improve from 0.48576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.8928 - accuracy: 0.5199 - val_loss: 0.9610 - val_accuracy: 0.4897 - val_macro_f1: 0.4563 - lr: 7.8608e-04\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8936 - accuracy: 0.5253 — val_macro_f1: 0.3685\n",
      "\n",
      "Epoch 15: val_macro_f1 did not improve from 0.48576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.8936 - accuracy: 0.5253 - val_loss: 1.0092 - val_accuracy: 0.4001 - val_macro_f1: 0.3685 - lr: 7.8241e-04\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.5253 — val_macro_f1: 0.5394 ★ New Best!\n",
      "\n",
      "Epoch 16: val_macro_f1 improved from 0.48576 to 0.53940, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.8865 - accuracy: 0.5253 - val_loss: 0.8544 - val_accuracy: 0.5419 - val_macro_f1: 0.5394 - lr: 7.7833e-04\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8624 - accuracy: 0.5472 — val_macro_f1: 0.5247\n",
      "\n",
      "Epoch 17: val_macro_f1 did not improve from 0.53940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.8624 - accuracy: 0.5472 - val_loss: 0.8269 - val_accuracy: 0.5432 - val_macro_f1: 0.5247 - lr: 7.7383e-04\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8532 - accuracy: 0.5562 — val_macro_f1: 0.5069\n",
      "\n",
      "Epoch 18: val_macro_f1 did not improve from 0.53940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.8532 - accuracy: 0.5562 - val_loss: 0.8755 - val_accuracy: 0.5258 - val_macro_f1: 0.5069 - lr: 7.6892e-04\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8660 - accuracy: 0.5404 — val_macro_f1: 0.5300\n",
      "\n",
      "Epoch 19: val_macro_f1 did not improve from 0.53940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.8660 - accuracy: 0.5404 - val_loss: 0.8282 - val_accuracy: 0.5406 - val_macro_f1: 0.5300 - lr: 7.6360e-04\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8162 - accuracy: 0.5705 — val_macro_f1: 0.5686 ★ New Best!\n",
      "\n",
      "Epoch 20: val_macro_f1 improved from 0.53940 to 0.56860, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.8162 - accuracy: 0.5705 - val_loss: 0.7927 - val_accuracy: 0.5735 - val_macro_f1: 0.5686 - lr: 7.5789e-04\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8333 - accuracy: 0.5776 — val_macro_f1: 0.4783\n",
      "\n",
      "Epoch 21: val_macro_f1 did not improve from 0.56860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.8333 - accuracy: 0.5776 - val_loss: 0.9449 - val_accuracy: 0.4903 - val_macro_f1: 0.4783 - lr: 7.5179e-04\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8124 - accuracy: 0.5806 — val_macro_f1: 0.5559\n",
      "\n",
      "Epoch 22: val_macro_f1 did not improve from 0.56860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.8124 - accuracy: 0.5806 - val_loss: 0.8201 - val_accuracy: 0.5593 - val_macro_f1: 0.5559 - lr: 7.4530e-04\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7859 - accuracy: 0.6051 — val_macro_f1: 0.5687 ★ New Best!\n",
      "\n",
      "Epoch 23: val_macro_f1 improved from 0.56860 to 0.56871, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.7859 - accuracy: 0.6051 - val_loss: 0.8048 - val_accuracy: 0.5735 - val_macro_f1: 0.5687 - lr: 7.3844e-04\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7919 - accuracy: 0.6041 — val_macro_f1: 0.5380\n",
      "\n",
      "Epoch 24: val_macro_f1 did not improve from 0.56871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7919 - accuracy: 0.6041 - val_loss: 0.8171 - val_accuracy: 0.5593 - val_macro_f1: 0.5380 - lr: 7.3120e-04\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.6151 — val_macro_f1: 0.5669\n",
      "\n",
      "Epoch 25: val_macro_f1 did not improve from 0.56871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7779 - accuracy: 0.6151 - val_loss: 0.8093 - val_accuracy: 0.5812 - val_macro_f1: 0.5669 - lr: 7.2361e-04\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7554 - accuracy: 0.6311 — val_macro_f1: 0.5863 ★ New Best!\n",
      "\n",
      "Epoch 26: val_macro_f1 improved from 0.56871 to 0.58632, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.7554 - accuracy: 0.6311 - val_loss: 0.7656 - val_accuracy: 0.5915 - val_macro_f1: 0.5863 - lr: 7.1566e-04\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7544 - accuracy: 0.6284 — val_macro_f1: 0.5516\n",
      "\n",
      "Epoch 27: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7544 - accuracy: 0.6284 - val_loss: 0.8029 - val_accuracy: 0.5644 - val_macro_f1: 0.5516 - lr: 7.0736e-04\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7854 - accuracy: 0.5908 — val_macro_f1: 0.5677\n",
      "\n",
      "Epoch 28: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.7854 - accuracy: 0.5908 - val_loss: 0.7965 - val_accuracy: 0.5812 - val_macro_f1: 0.5677 - lr: 6.9873e-04\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7684 - accuracy: 0.6267 — val_macro_f1: 0.5774\n",
      "\n",
      "Epoch 29: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.7684 - accuracy: 0.6267 - val_loss: 0.7577 - val_accuracy: 0.5857 - val_macro_f1: 0.5774 - lr: 6.8977e-04\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7324 - accuracy: 0.6469 — val_macro_f1: 0.5308\n",
      "\n",
      "Epoch 30: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.7324 - accuracy: 0.6469 - val_loss: 0.8121 - val_accuracy: 0.5573 - val_macro_f1: 0.5308 - lr: 6.8049e-04\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.6211 — val_macro_f1: 0.5461\n",
      "\n",
      "Epoch 31: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7665 - accuracy: 0.6211 - val_loss: 0.8129 - val_accuracy: 0.5548 - val_macro_f1: 0.5461 - lr: 6.7091e-04\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.6401 — val_macro_f1: 0.5835\n",
      "\n",
      "Epoch 32: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7345 - accuracy: 0.6401 - val_loss: 0.7674 - val_accuracy: 0.5928 - val_macro_f1: 0.5835 - lr: 6.6103e-04\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.6484 — val_macro_f1: 0.5448\n",
      "\n",
      "Epoch 33: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7381 - accuracy: 0.6484 - val_loss: 0.8493 - val_accuracy: 0.5638 - val_macro_f1: 0.5448 - lr: 6.5087e-04\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7110 - accuracy: 0.6638 — val_macro_f1: 0.5646\n",
      "\n",
      "Epoch 34: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.7110 - accuracy: 0.6638 - val_loss: 0.8507 - val_accuracy: 0.5741 - val_macro_f1: 0.5646 - lr: 6.4043e-04\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7564 - accuracy: 0.6460 — val_macro_f1: 0.5581\n",
      "\n",
      "Epoch 35: val_macro_f1 did not improve from 0.58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7564 - accuracy: 0.6460 - val_loss: 0.8173 - val_accuracy: 0.5715 - val_macro_f1: 0.5581 - lr: 6.2973e-04\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7274 - accuracy: 0.6623 — val_macro_f1: 0.5923 ★ New Best!\n",
      "\n",
      "Epoch 36: val_macro_f1 improved from 0.58632 to 0.59231, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.7274 - accuracy: 0.6623 - val_loss: 0.7900 - val_accuracy: 0.6018 - val_macro_f1: 0.5923 - lr: 6.1878e-04\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.6801 — val_macro_f1: 0.5855\n",
      "\n",
      "Epoch 37: val_macro_f1 did not improve from 0.59231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.6889 - accuracy: 0.6801 - val_loss: 0.7960 - val_accuracy: 0.5941 - val_macro_f1: 0.5855 - lr: 6.0759e-04\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.6832 — val_macro_f1: 0.5728\n",
      "\n",
      "Epoch 38: val_macro_f1 did not improve from 0.59231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.6925 - accuracy: 0.6832 - val_loss: 0.8257 - val_accuracy: 0.5812 - val_macro_f1: 0.5728 - lr: 5.9617e-04\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.6851 — val_macro_f1: 0.6093 ★ New Best!\n",
      "\n",
      "Epoch 39: val_macro_f1 improved from 0.59231 to 0.60933, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.6946 - accuracy: 0.6851 - val_loss: 0.7800 - val_accuracy: 0.6057 - val_macro_f1: 0.6093 - lr: 5.8454e-04\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.6934 — val_macro_f1: 0.6009\n",
      "\n",
      "Epoch 40: val_macro_f1 did not improve from 0.60933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.6695 - accuracy: 0.6934 - val_loss: 0.7657 - val_accuracy: 0.6089 - val_macro_f1: 0.6009 - lr: 5.7270e-04\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.7024 — val_macro_f1: 0.5950\n",
      "\n",
      "Epoch 41: val_macro_f1 did not improve from 0.60933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.6507 - accuracy: 0.7024 - val_loss: 0.8030 - val_accuracy: 0.6070 - val_macro_f1: 0.5950 - lr: 5.6068e-04\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.7002 — val_macro_f1: 0.5885\n",
      "\n",
      "Epoch 42: val_macro_f1 did not improve from 0.60933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.6460 - accuracy: 0.7002 - val_loss: 0.7968 - val_accuracy: 0.5947 - val_macro_f1: 0.5885 - lr: 5.4848e-04\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.7331 — val_macro_f1: 0.5880\n",
      "\n",
      "Epoch 43: val_macro_f1 did not improve from 0.60933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.6266 - accuracy: 0.7331 - val_loss: 0.7988 - val_accuracy: 0.5921 - val_macro_f1: 0.5880 - lr: 5.3612e-04\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.7124 — val_macro_f1: 0.6187 ★ New Best!\n",
      "\n",
      "Epoch 44: val_macro_f1 improved from 0.60933 to 0.61869, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.6353 - accuracy: 0.7124 - val_loss: 0.7735 - val_accuracy: 0.6237 - val_macro_f1: 0.6187 - lr: 5.2361e-04\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7331 — val_macro_f1: 0.5975\n",
      "\n",
      "Epoch 45: val_macro_f1 did not improve from 0.61869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.6098 - accuracy: 0.7331 - val_loss: 0.7960 - val_accuracy: 0.5973 - val_macro_f1: 0.5975 - lr: 5.1096e-04\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.7329 — val_macro_f1: 0.6202 ★ New Best!\n",
      "\n",
      "Epoch 46: val_macro_f1 improved from 0.61869 to 0.62021, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.6075 - accuracy: 0.7329 - val_loss: 0.7504 - val_accuracy: 0.6250 - val_macro_f1: 0.6202 - lr: 4.9819e-04\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7216 — val_macro_f1: 0.6227 ★ New Best!\n",
      "\n",
      "Epoch 47: val_macro_f1 improved from 0.62021 to 0.62269, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.6545 - accuracy: 0.7216 - val_loss: 0.7567 - val_accuracy: 0.6282 - val_macro_f1: 0.6227 - lr: 4.8532e-04\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.7319 — val_macro_f1: 0.6066\n",
      "\n",
      "Epoch 48: val_macro_f1 did not improve from 0.62269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.6338 - accuracy: 0.7319 - val_loss: 0.7798 - val_accuracy: 0.6128 - val_macro_f1: 0.6066 - lr: 4.7235e-04\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.7404 — val_macro_f1: 0.6250 ★ New Best!\n",
      "\n",
      "Epoch 49: val_macro_f1 improved from 0.62269 to 0.62499, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.6197 - accuracy: 0.7404 - val_loss: 0.7504 - val_accuracy: 0.6256 - val_macro_f1: 0.6250 - lr: 4.5931e-04\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.7397 — val_macro_f1: 0.6287 ★ New Best!\n",
      "\n",
      "Epoch 50: val_macro_f1 improved from 0.62499 to 0.62873, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6172 - accuracy: 0.7397 - val_loss: 0.7336 - val_accuracy: 0.6340 - val_macro_f1: 0.6287 - lr: 4.4619e-04\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.7475 — val_macro_f1: 0.6149\n",
      "\n",
      "Epoch 51: val_macro_f1 did not improve from 0.62873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.6305 - accuracy: 0.7475 - val_loss: 0.7861 - val_accuracy: 0.6211 - val_macro_f1: 0.6149 - lr: 4.3303e-04\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.7667 — val_macro_f1: 0.5821\n",
      "\n",
      "Epoch 52: val_macro_f1 did not improve from 0.62873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5979 - accuracy: 0.7667 - val_loss: 0.8204 - val_accuracy: 0.5870 - val_macro_f1: 0.5821 - lr: 4.1983e-04\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.7537 — val_macro_f1: 0.6054\n",
      "\n",
      "Epoch 53: val_macro_f1 did not improve from 0.62873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.6160 - accuracy: 0.7537 - val_loss: 0.8020 - val_accuracy: 0.6173 - val_macro_f1: 0.6054 - lr: 4.0661e-04\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5592 - accuracy: 0.7788 — val_macro_f1: 0.6308 ★ New Best!\n",
      "\n",
      "Epoch 54: val_macro_f1 improved from 0.62873 to 0.63084, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.5592 - accuracy: 0.7788 - val_loss: 0.7564 - val_accuracy: 0.6347 - val_macro_f1: 0.6308 - lr: 3.9339e-04\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7676 — val_macro_f1: 0.6190\n",
      "\n",
      "Epoch 55: val_macro_f1 did not improve from 0.63084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5776 - accuracy: 0.7676 - val_loss: 0.7696 - val_accuracy: 0.6256 - val_macro_f1: 0.6190 - lr: 3.8017e-04\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.7903 — val_macro_f1: 0.6113\n",
      "\n",
      "Epoch 56: val_macro_f1 did not improve from 0.63084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 121ms/step - loss: 0.5356 - accuracy: 0.7903 - val_loss: 0.7980 - val_accuracy: 0.6192 - val_macro_f1: 0.6113 - lr: 3.6697e-04\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7835 — val_macro_f1: 0.6194\n",
      "\n",
      "Epoch 57: val_macro_f1 did not improve from 0.63084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5843 - accuracy: 0.7835 - val_loss: 0.7951 - val_accuracy: 0.6295 - val_macro_f1: 0.6194 - lr: 3.5381e-04\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.7801 — val_macro_f1: 0.5586\n",
      "\n",
      "Epoch 58: val_macro_f1 did not improve from 0.63084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5855 - accuracy: 0.7801 - val_loss: 0.9284 - val_accuracy: 0.5657 - val_macro_f1: 0.5586 - lr: 3.4069e-04\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7890 — val_macro_f1: 0.6051\n",
      "\n",
      "Epoch 59: val_macro_f1 did not improve from 0.63084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5658 - accuracy: 0.7890 - val_loss: 0.7856 - val_accuracy: 0.6153 - val_macro_f1: 0.6051 - lr: 3.2765e-04\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7981 — val_macro_f1: 0.6321 ★ New Best!\n",
      "\n",
      "Epoch 60: val_macro_f1 improved from 0.63084 to 0.63211, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.5641 - accuracy: 0.7981 - val_loss: 0.7793 - val_accuracy: 0.6385 - val_macro_f1: 0.6321 - lr: 3.1468e-04\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.8076 — val_macro_f1: 0.6105\n",
      "\n",
      "Epoch 61: val_macro_f1 did not improve from 0.63211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5437 - accuracy: 0.8076 - val_loss: 0.7839 - val_accuracy: 0.6147 - val_macro_f1: 0.6105 - lr: 3.0181e-04\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8331 — val_macro_f1: 0.6176\n",
      "\n",
      "Epoch 62: val_macro_f1 did not improve from 0.63211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 121ms/step - loss: 0.4902 - accuracy: 0.8331 - val_loss: 0.8009 - val_accuracy: 0.6218 - val_macro_f1: 0.6176 - lr: 2.8904e-04\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.8158 — val_macro_f1: 0.6330 ★ New Best!\n",
      "\n",
      "Epoch 63: val_macro_f1 improved from 0.63211 to 0.63296, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.5324 - accuracy: 0.8158 - val_loss: 0.7535 - val_accuracy: 0.6372 - val_macro_f1: 0.6330 - lr: 2.7639e-04\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.8205 — val_macro_f1: 0.6129\n",
      "\n",
      "Epoch 64: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5240 - accuracy: 0.8205 - val_loss: 0.7783 - val_accuracy: 0.6205 - val_macro_f1: 0.6129 - lr: 2.6388e-04\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.8105 — val_macro_f1: 0.6064\n",
      "\n",
      "Epoch 65: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5293 - accuracy: 0.8105 - val_loss: 0.8024 - val_accuracy: 0.6173 - val_macro_f1: 0.6064 - lr: 2.5152e-04\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.8411 — val_macro_f1: 0.6287\n",
      "\n",
      "Epoch 66: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4903 - accuracy: 0.8411 - val_loss: 0.8068 - val_accuracy: 0.6360 - val_macro_f1: 0.6287 - lr: 2.3932e-04\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.8302 — val_macro_f1: 0.6317\n",
      "\n",
      "Epoch 67: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 121ms/step - loss: 0.5046 - accuracy: 0.8302 - val_loss: 0.7817 - val_accuracy: 0.6379 - val_macro_f1: 0.6317 - lr: 2.2730e-04\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8197 — val_macro_f1: 0.6272\n",
      "\n",
      "Epoch 68: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5185 - accuracy: 0.8197 - val_loss: 0.7926 - val_accuracy: 0.6308 - val_macro_f1: 0.6272 - lr: 2.1546e-04\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8238 — val_macro_f1: 0.6216\n",
      "\n",
      "Epoch 69: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5185 - accuracy: 0.8238 - val_loss: 0.7808 - val_accuracy: 0.6276 - val_macro_f1: 0.6216 - lr: 2.0383e-04\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8423 — val_macro_f1: 0.6261\n",
      "\n",
      "Epoch 70: val_macro_f1 did not improve from 0.63296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5057 - accuracy: 0.8423 - val_loss: 0.7905 - val_accuracy: 0.6321 - val_macro_f1: 0.6261 - lr: 1.9241e-04\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8424 — val_macro_f1: 0.6358 ★ New Best!\n",
      "\n",
      "Epoch 71: val_macro_f1 improved from 0.63296 to 0.63579, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.4984 - accuracy: 0.8424 - val_loss: 0.7784 - val_accuracy: 0.6405 - val_macro_f1: 0.6358 - lr: 1.8122e-04\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.8547 — val_macro_f1: 0.6313\n",
      "\n",
      "Epoch 72: val_macro_f1 did not improve from 0.63579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4919 - accuracy: 0.8547 - val_loss: 0.7936 - val_accuracy: 0.6366 - val_macro_f1: 0.6313 - lr: 1.7027e-04\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.8436 — val_macro_f1: 0.6198\n",
      "\n",
      "Epoch 73: val_macro_f1 did not improve from 0.63579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5163 - accuracy: 0.8436 - val_loss: 0.7895 - val_accuracy: 0.6231 - val_macro_f1: 0.6198 - lr: 1.5957e-04\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8684 — val_macro_f1: 0.6329\n",
      "\n",
      "Epoch 74: val_macro_f1 did not improve from 0.63579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4562 - accuracy: 0.8684 - val_loss: 0.8030 - val_accuracy: 0.6398 - val_macro_f1: 0.6329 - lr: 1.4913e-04\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.8633 — val_macro_f1: 0.6501 ★ New Best!\n",
      "\n",
      "Epoch 75: val_macro_f1 improved from 0.63579 to 0.65014, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 126ms/step - loss: 0.4879 - accuracy: 0.8633 - val_loss: 0.7769 - val_accuracy: 0.6527 - val_macro_f1: 0.6501 - lr: 1.3897e-04\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.8565 — val_macro_f1: 0.6505 ★ New Best!\n",
      "\n",
      "Epoch 76: val_macro_f1 improved from 0.65014 to 0.65050, saving model to /mnt/user-data/outputs/conformer_v3_20251128_053206/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.4958 - accuracy: 0.8565 - val_loss: 0.7626 - val_accuracy: 0.6534 - val_macro_f1: 0.6505 - lr: 1.2909e-04\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.8664 — val_macro_f1: 0.6425\n",
      "\n",
      "Epoch 77: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4564 - accuracy: 0.8664 - val_loss: 0.7846 - val_accuracy: 0.6463 - val_macro_f1: 0.6425 - lr: 1.1951e-04\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.8683 — val_macro_f1: 0.6253\n",
      "\n",
      "Epoch 78: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 121ms/step - loss: 0.4777 - accuracy: 0.8683 - val_loss: 0.7890 - val_accuracy: 0.6302 - val_macro_f1: 0.6253 - lr: 1.1023e-04\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8649 — val_macro_f1: 0.6321\n",
      "\n",
      "Epoch 79: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4762 - accuracy: 0.8649 - val_loss: 0.7855 - val_accuracy: 0.6392 - val_macro_f1: 0.6321 - lr: 1.0127e-04\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.8856 — val_macro_f1: 0.6406\n",
      "\n",
      "Epoch 80: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4455 - accuracy: 0.8856 - val_loss: 0.7936 - val_accuracy: 0.6443 - val_macro_f1: 0.6406 - lr: 9.2640e-05\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.8664 — val_macro_f1: 0.6339\n",
      "\n",
      "Epoch 81: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4794 - accuracy: 0.8664 - val_loss: 0.7744 - val_accuracy: 0.6372 - val_macro_f1: 0.6339 - lr: 8.4344e-05\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.8788 — val_macro_f1: 0.6335\n",
      "\n",
      "Epoch 82: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4728 - accuracy: 0.8788 - val_loss: 0.7817 - val_accuracy: 0.6385 - val_macro_f1: 0.6335 - lr: 7.6393e-05\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.8754 — val_macro_f1: 0.6316\n",
      "\n",
      "Epoch 83: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4880 - accuracy: 0.8754 - val_loss: 0.7828 - val_accuracy: 0.6360 - val_macro_f1: 0.6316 - lr: 6.8796e-05\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8793 — val_macro_f1: 0.6403\n",
      "\n",
      "Epoch 84: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 121ms/step - loss: 0.4628 - accuracy: 0.8793 - val_loss: 0.7757 - val_accuracy: 0.6456 - val_macro_f1: 0.6403 - lr: 6.1562e-05\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.8771 — val_macro_f1: 0.6330\n",
      "\n",
      "Epoch 85: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4711 - accuracy: 0.8771 - val_loss: 0.7808 - val_accuracy: 0.6385 - val_macro_f1: 0.6330 - lr: 5.4697e-05\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8725 — val_macro_f1: 0.6347\n",
      "\n",
      "Epoch 86: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4797 - accuracy: 0.8725 - val_loss: 0.7851 - val_accuracy: 0.6411 - val_macro_f1: 0.6347 - lr: 4.8210e-05\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8761 — val_macro_f1: 0.6373\n",
      "\n",
      "Epoch 87: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4577 - accuracy: 0.8761 - val_loss: 0.7783 - val_accuracy: 0.6418 - val_macro_f1: 0.6373 - lr: 4.2108e-05\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.8723 — val_macro_f1: 0.6350\n",
      "\n",
      "Epoch 88: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4677 - accuracy: 0.8723 - val_loss: 0.7796 - val_accuracy: 0.6392 - val_macro_f1: 0.6350 - lr: 3.6397e-05\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.8747 — val_macro_f1: 0.6415\n",
      "\n",
      "Epoch 89: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4602 - accuracy: 0.8747 - val_loss: 0.7722 - val_accuracy: 0.6463 - val_macro_f1: 0.6415 - lr: 3.1084e-05\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.8866 — val_macro_f1: 0.6370\n",
      "\n",
      "Epoch 90: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4700 - accuracy: 0.8866 - val_loss: 0.7785 - val_accuracy: 0.6418 - val_macro_f1: 0.6370 - lr: 2.6174e-05\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8992 — val_macro_f1: 0.6410\n",
      "\n",
      "Epoch 91: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4430 - accuracy: 0.8992 - val_loss: 0.7739 - val_accuracy: 0.6443 - val_macro_f1: 0.6410 - lr: 2.1673e-05\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.8817 — val_macro_f1: 0.6359\n",
      "\n",
      "Epoch 92: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4690 - accuracy: 0.8817 - val_loss: 0.7832 - val_accuracy: 0.6405 - val_macro_f1: 0.6359 - lr: 1.7586e-05\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8572 — val_macro_f1: 0.6409\n",
      "\n",
      "Epoch 93: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.5094 - accuracy: 0.8572 - val_loss: 0.7767 - val_accuracy: 0.6450 - val_macro_f1: 0.6409 - lr: 1.3916e-05\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8862 — val_macro_f1: 0.6420\n",
      "\n",
      "Epoch 94: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4635 - accuracy: 0.8862 - val_loss: 0.7798 - val_accuracy: 0.6463 - val_macro_f1: 0.6420 - lr: 1.0669e-05\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.8985 — val_macro_f1: 0.6441\n",
      "\n",
      "Epoch 95: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4258 - accuracy: 0.8985 - val_loss: 0.7761 - val_accuracy: 0.6482 - val_macro_f1: 0.6441 - lr: 7.8480e-06\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.9014 — val_macro_f1: 0.6403\n",
      "\n",
      "Epoch 96: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4292 - accuracy: 0.9014 - val_loss: 0.7812 - val_accuracy: 0.6443 - val_macro_f1: 0.6403 - lr: 5.4555e-06\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8869 — val_macro_f1: 0.6424\n",
      "\n",
      "Epoch 97: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4567 - accuracy: 0.8869 - val_loss: 0.7826 - val_accuracy: 0.6469 - val_macro_f1: 0.6424 - lr: 3.4944e-06\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8798 — val_macro_f1: 0.6429\n",
      "\n",
      "Epoch 98: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4748 - accuracy: 0.8798 - val_loss: 0.7813 - val_accuracy: 0.6476 - val_macro_f1: 0.6429 - lr: 1.9668e-06\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.8913 — val_macro_f1: 0.6426\n",
      "\n",
      "Epoch 99: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4600 - accuracy: 0.8913 - val_loss: 0.7797 - val_accuracy: 0.6469 - val_macro_f1: 0.6426 - lr: 8.7455e-07\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.9088 — val_macro_f1: 0.6409\n",
      "\n",
      "Epoch 100: val_macro_f1 did not improve from 0.65050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 122ms/step - loss: 0.4275 - accuracy: 0.9088 - val_loss: 0.7815 - val_accuracy: 0.6450 - val_macro_f1: 0.6409 - lr: 2.1870e-07\n",
      "\n",
      "Plotting training curves...\n",
      "  ✓ Saved: loss_curve.png\n",
      "  ✓ Saved: accuracy_curve.png\n",
      "  ✓ Saved: macro_f1_curve.png\n",
      "  ✓ Saved: learning_rate.png\n",
      "  ✓ Saved: training_overview.png\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "============================================================\n",
      "Classification Report - Conformer V3\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG     0.6618    0.8642    0.7496       265\n",
      "         DIS     0.6698    0.5358    0.5954       265\n",
      "         FEA     0.6272    0.5396    0.5801       265\n",
      "         HAP     0.5833    0.5547    0.5687       265\n",
      "         NEU     0.6763    0.8282    0.7446       227\n",
      "         SAD     0.6441    0.5736    0.6068       265\n",
      "\n",
      "    accuracy                         0.6450      1552\n",
      "   macro avg     0.6438    0.6494    0.6409      1552\n",
      "weighted avg     0.6430    0.6450    0.6383      1552\n",
      "\n",
      "\n",
      "Summary:\n",
      "  Accuracy:    0.6450\n",
      "  Macro F1:    0.6409\n",
      "  Weighted F1: 0.6383\n",
      "  ✓ Saved: confusion_matrix.png\n",
      "  ✓ Saved: confusion_matrix_normalized.png\n",
      "  ✓ Saved: class_f1_scores.png\n",
      "  ✓ Saved: precision_recall.png\n",
      "\n",
      "Comparing with previous models...\n",
      "  ✓ Saved: model_comparison.png\n",
      "\n",
      "============================================================\n",
      "Final Results\n",
      "============================================================\n",
      "Accuracy:    0.6450\n",
      "Macro F1:    0.6409\n",
      "Weighted F1: 0.6383\n",
      "\n",
      "Per-class F1:\n",
      "  ANG: 0.7496\n",
      "  DIS: 0.5954\n",
      "  FEA: 0.5801\n",
      "  HAP: 0.5687\n",
      "  NEU: 0.7446\n",
      "  SAD: 0.6068\n",
      "\n",
      "============================================================\n",
      "✓ All results saved to: /mnt/user-data/outputs/conformer_v3_20251128_053206\n",
      "  - Models: /mnt/user-data/outputs/conformer_v3_20251128_053206/models\n",
      "  - Plots:  /mnt/user-data/outputs/conformer_v3_20251128_053206/plots\n",
      "  - Logs:   /mnt/user-data/outputs/conformer_v3_20251128_053206/logs\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 语音情绪识别 - Conformer V3 完整版\n",
    "# 数据集: CREMA-D\n",
    "# 改进: 平衡正则化 + Mixup + Label Smoothing + 自动保存目录\n",
    "# ============================================================================\n",
    "\n",
    "# =====================\n",
    "# 0) 导入必要的库\n",
    "# =====================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 设置绘图风格\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 1) 自动创建输出目录\n",
    "# =====================\n",
    "def create_experiment_dir(base_dir=\"/mnt/user-data/outputs\", prefix=\"conformer_v3\"):\n",
    "    \"\"\"\n",
    "    创建带时间戳的实验目录\n",
    "    格式: conformer_v3_20251128_123456\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exp_dir = os.path.join(base_dir, f\"{prefix}_{timestamp}\")\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # 创建子目录\n",
    "    subdirs = [\"models\", \"plots\", \"logs\"]\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(exp_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    print(f\"✓ Experiment directory created: {exp_dir}\")\n",
    "    return exp_dir\n",
    "\n",
    "\n",
    "# 创建实验目录\n",
    "EXP_DIR = create_experiment_dir()\n",
    "MODEL_DIR = os.path.join(EXP_DIR, \"models\")\n",
    "PLOT_DIR = os.path.join(EXP_DIR, \"plots\")\n",
    "LOG_DIR = os.path.join(EXP_DIR, \"logs\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 2) 数据路径配置\n",
    "# =====================\n",
    "AUDIO_DIR = Path(\"../AudioWAV\")  # 修改为你的音频路径\n",
    "assert AUDIO_DIR.exists(), f\"Audio directory not found: {AUDIO_DIR}\"\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 3) 构建元数据\n",
    "# =====================\n",
    "def build_metadata(audio_dir):\n",
    "    \"\"\"从文件名解析元数据\"\"\"\n",
    "    records = []\n",
    "    for wav_file in audio_dir.glob(\"*.wav\"):\n",
    "        filename = wav_file.stem\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) == 4:\n",
    "            speaker, sentence, emotion, intensity = parts\n",
    "            records.append({\n",
    "                \"path\": wav_file,\n",
    "                \"speaker\": speaker,\n",
    "                \"sentence\": sentence,\n",
    "                \"emotion\": emotion,\n",
    "                \"intensity\": intensity\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "meta = build_metadata(AUDIO_DIR)\n",
    "print(f\"Total samples: {len(meta)}\")\n",
    "print(f\"Emotion distribution:\\n{meta['emotion'].value_counts()}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 4) 音频特征提取配置\n",
    "# =====================\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "FFT = 1024\n",
    "HOP = 160\n",
    "WIN = 400\n",
    "FIXED_SECONDS = 3.0\n",
    "MAX_FRAMES = int(math.ceil(FIXED_SECONDS * SR / HOP))\n",
    "\n",
    "print(f\"Feature shape: ({MAX_FRAMES}, {N_MELS}, 1)\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 5) Log-Mel 特征提取\n",
    "# =====================\n",
    "def load_logmel(path: Path):\n",
    "    \"\"\"加载音频并提取Log-Mel频谱图\"\"\"\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "    \n",
    "    target_len = int(FIXED_SECONDS * SR)\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=FFT, hop_length=HOP,\n",
    "        win_length=WIN, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "    feat = np.transpose(S_db[..., None], (1, 0, 2))\n",
    "    \n",
    "    if feat.shape[0] < MAX_FRAMES:\n",
    "        feat = np.pad(feat, ((0, MAX_FRAMES - feat.shape[0]), (0, 0), (0, 0)))\n",
    "    else:\n",
    "        feat = feat[:MAX_FRAMES]\n",
    "    \n",
    "    return feat\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 6) 批量提取特征\n",
    "# =====================\n",
    "print(\"Extracting features...\")\n",
    "specs = []\n",
    "emotions = []\n",
    "speakers = []\n",
    "\n",
    "for idx, row in meta.iterrows():\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"  Processing {idx}/{len(meta)}...\")\n",
    "    specs.append(load_logmel(row['path']))\n",
    "    emotions.append(row['emotion'])\n",
    "    speakers.append(row['speaker'])\n",
    "\n",
    "X = np.stack(specs)\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 7) 标签编码 & 数据划分\n",
    "# =====================\n",
    "le_emo = LabelEncoder()\n",
    "y = le_emo.fit_transform(emotions).astype(np.int32)\n",
    "groups = np.array(speakers)\n",
    "\n",
    "print(f\"Classes: {le_emo.classes_}\")\n",
    "print(f\"Number of classes: {len(le_emo.classes_)}\")\n",
    "\n",
    "# 说话人独立划分\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "Xtr, Xte = X[train_idx], X[test_idx]\n",
    "ytr, yte = y[train_idx], y[test_idx]\n",
    "\n",
    "print(f\"Train: {Xtr.shape}, Test: {Xte.shape}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 8) Z-Score 标准化\n",
    "# =====================\n",
    "mean_spec = Xtr.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_spec = Xtr.std(axis=(0, 1, 2), keepdims=True) + 1e-6\n",
    "\n",
    "Xtr = (Xtr - mean_spec) / std_spec\n",
    "Xte = (Xte - mean_spec) / std_spec\n",
    "\n",
    "print(f\"Normalized - Train mean: {Xtr.mean():.4f}, std: {Xtr.std():.4f}\")\n",
    "\n",
    "# 保存标准化参数\n",
    "np.save(os.path.join(MODEL_DIR, \"norm_mean.npy\"), mean_spec)\n",
    "np.save(os.path.join(MODEL_DIR, \"norm_std.npy\"), std_spec)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 9) 自定义层和函数\n",
    "# =====================\n",
    "\n",
    "class SpecAugment(layers.Layer):\n",
    "    \"\"\"SpecAugment 数据增强层\"\"\"\n",
    "    def __init__(self, time_mask_num=2, freq_mask_num=2, \n",
    "                 time_mask_max=16, freq_mask_max=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.time_mask_num = time_mask_num\n",
    "        self.freq_mask_num = freq_mask_num\n",
    "        self.time_mask_max = time_mask_max\n",
    "        self.freq_mask_max = freq_mask_max\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            return x\n",
    "        \n",
    "        batch_size = tf.shape(x)[0]\n",
    "        T = tf.shape(x)[1]\n",
    "        F = tf.shape(x)[2]\n",
    "        \n",
    "        for _ in range(self.time_mask_num):\n",
    "            t = tf.random.uniform([], 0, self.time_mask_max, dtype=tf.int32)\n",
    "            t0 = tf.random.uniform([], 0, tf.maximum(1, T - t), dtype=tf.int32)\n",
    "            mask = tf.concat([\n",
    "                tf.ones([batch_size, t0, F, 1]),\n",
    "                tf.zeros([batch_size, t, F, 1]),\n",
    "                tf.ones([batch_size, T - t0 - t, F, 1])\n",
    "            ], axis=1)\n",
    "            x = x * mask\n",
    "        \n",
    "        for _ in range(self.freq_mask_num):\n",
    "            f = tf.random.uniform([], 0, self.freq_mask_max, dtype=tf.int32)\n",
    "            f0 = tf.random.uniform([], 0, tf.maximum(1, F - f), dtype=tf.int32)\n",
    "            mask = tf.concat([\n",
    "                tf.ones([batch_size, T, f0, 1]),\n",
    "                tf.zeros([batch_size, T, f, 1]),\n",
    "                tf.ones([batch_size, T, F - f0 - f, 1])\n",
    "            ], axis=2)\n",
    "            x = x * mask\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"time_mask_num\": self.time_mask_num,\n",
    "            \"freq_mask_num\": self.freq_mask_num,\n",
    "            \"time_mask_max\": self.time_mask_max,\n",
    "            \"freq_mask_max\": self.freq_mask_max,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class LabelSmoothingFocalLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Label Smoothing + Focal Loss\"\"\"\n",
    "    def __init__(self, smoothing=0.1, gamma=2.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        n_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        \n",
    "        # Label smoothing\n",
    "        y_true = y_true * (1 - self.smoothing) + self.smoothing / n_classes\n",
    "        \n",
    "        # Focal loss\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1 - y_pred, self.gamma)\n",
    "        focal = weight * ce\n",
    "        \n",
    "        return tf.reduce_sum(focal, axis=-1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"smoothing\": self.smoothing,\n",
    "            \"gamma\": self.gamma,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def glu_activation(x):\n",
    "    \"\"\"GLU激活函数\"\"\"\n",
    "    channels = x.shape[-1] // 2\n",
    "    return x[..., :channels] * tf.sigmoid(x[..., channels:])\n",
    "\n",
    "\n",
    "def se_block(x, ratio=8):\n",
    "    \"\"\"SE通道注意力\"\"\"\n",
    "    channels = x.shape[-1]\n",
    "    squeeze = layers.GlobalAveragePooling2D()(x)\n",
    "    excite = layers.Dense(max(channels // ratio, 4), activation=\"relu\")(squeeze)\n",
    "    excite = layers.Dense(channels, activation=\"sigmoid\")(excite)\n",
    "    excite = layers.Reshape((1, 1, channels))(excite)\n",
    "    return layers.Multiply()([x, excite])\n",
    "\n",
    "\n",
    "def attentive_pooling(x):\n",
    "    \"\"\"注意力池化\"\"\"\n",
    "    attention = layers.Dense(1, activation=\"tanh\")(x)\n",
    "    attention = layers.Softmax(axis=1)(attention)\n",
    "    pooled = tf.reduce_sum(x * attention, axis=1)\n",
    "    return pooled\n",
    "\n",
    "\n",
    "def multi_scale_conv_block(x):\n",
    "    \"\"\"多尺度卷积块\"\"\"\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    conv5 = layers.Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    conv7 = layers.Conv2D(32, (7, 7), padding=\"same\", activation=\"relu\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    \n",
    "    concat = layers.Concatenate()([conv3, conv5, conv7])\n",
    "    concat = layers.BatchNormalization()(concat)\n",
    "    concat = se_block(concat, ratio=8)\n",
    "    concat = layers.MaxPool2D((2, 2))(concat)\n",
    "    \n",
    "    return concat\n",
    "\n",
    "\n",
    "def conformer_block(x, d_model=128, num_heads=4, conv_kernel=15, dropout=0.15):\n",
    "    \"\"\"Conformer Block\"\"\"\n",
    "    \n",
    "    # Feed Forward Module 1\n",
    "    ff1 = layers.Dense(d_model * 4, activation=\"swish\")(x)\n",
    "    ff1 = layers.Dropout(dropout)(ff1)\n",
    "    ff1 = layers.Dense(d_model)(ff1)\n",
    "    ff1 = layers.Dropout(dropout)(ff1)\n",
    "    x = layers.LayerNormalization()(x + 0.5 * ff1)\n",
    "    \n",
    "    # Multi-Head Self-Attention\n",
    "    attn = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=d_model // num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.LayerNormalization()(x + attn)\n",
    "    \n",
    "    # Convolution Module\n",
    "    conv = layers.Conv1D(d_model * 2, kernel_size=1)(x)\n",
    "    conv = glu_activation(conv)\n",
    "    conv = layers.DepthwiseConv1D(\n",
    "        kernel_size=conv_kernel, \n",
    "        padding=\"same\",\n",
    "        depthwise_regularizer=tf.keras.regularizers.l2(5e-5)\n",
    "    )(conv)\n",
    "    conv = layers.BatchNormalization()(conv)\n",
    "    conv = layers.Activation(\"swish\")(conv)\n",
    "    conv = layers.Conv1D(d_model, kernel_size=1)(conv)\n",
    "    conv = layers.Dropout(dropout)(conv)\n",
    "    x = layers.LayerNormalization()(x + conv)\n",
    "    \n",
    "    # Feed Forward Module 2\n",
    "    ff2 = layers.Dense(d_model * 4, activation=\"swish\")(x)\n",
    "    ff2 = layers.Dropout(dropout)(ff2)\n",
    "    ff2 = layers.Dense(d_model)(ff2)\n",
    "    ff2 = layers.Dropout(dropout)(ff2)\n",
    "    x = layers.LayerNormalization()(x + 0.5 * ff2)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 10) 构建 Conformer V3 模型\n",
    "# =====================\n",
    "def build_conformer_v3(input_shape, n_classes=6, d_model=128):\n",
    "    \"\"\"\n",
    "    Conformer V3 - 平衡版本\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 数据增强\n",
    "    x = layers.GaussianNoise(0.03)(inp)\n",
    "    x = SpecAugment(time_mask_num=2, freq_mask_num=2, \n",
    "                    time_mask_max=16, freq_mask_max=6)(x)\n",
    "    \n",
    "    # 多尺度卷积前端\n",
    "    x = multi_scale_conv_block(x)\n",
    "    \n",
    "    # 卷积层 1\n",
    "    x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\",\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x, ratio=8)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.25)(x)\n",
    "    \n",
    "    # 卷积层 2\n",
    "    x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\",\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x, ratio=8)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.25)(x)\n",
    "    \n",
    "    # Reshape for Conformer\n",
    "    T_prime = x.shape[1]\n",
    "    x = layers.Reshape((T_prime, -1))(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.Dropout(0.15)(x)\n",
    "    \n",
    "    # Conformer Blocks\n",
    "    x = conformer_block(x, d_model=d_model, num_heads=4, conv_kernel=15, dropout=0.15)\n",
    "    x = conformer_block(x, d_model=d_model, num_heads=4, conv_kernel=15, dropout=0.15)\n",
    "    \n",
    "    # 注意力池化\n",
    "    x = attentive_pooling(x)\n",
    "    \n",
    "    # 分类头\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\",\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(n_classes, activation=\"softmax\", name=\"emotion\")(x)\n",
    "    \n",
    "    model = models.Model(inp, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 11) Mixup 数据生成器\n",
    "# =====================\n",
    "class MixupGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"带Mixup的数据生成器\"\"\"\n",
    "    def __init__(self, x, y, batch_size=64, alpha=0.2, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(x))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[batch_indexes].copy()\n",
    "        batch_y = self.y[batch_indexes].copy()\n",
    "        \n",
    "        # 50%概率应用Mixup\n",
    "        if np.random.random() < 0.5 and self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            shuffle_idx = np.random.permutation(len(batch_x))\n",
    "            batch_x = lam * batch_x + (1 - lam) * batch_x[shuffle_idx]\n",
    "            batch_y = lam * batch_y + (1 - lam) * batch_y[shuffle_idx]\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 12) 自定义回调\n",
    "# =====================\n",
    "class MacroF1Callback(callbacks.Callback):\n",
    "    \"\"\"计算并记录 Macro F1\"\"\"\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0\n",
    "        self.f1_history = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(self.X_val, verbose=0), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_pred, average=\"macro\")\n",
    "        self.f1_history.append(f1)\n",
    "        logs = logs or {}\n",
    "        logs[\"val_macro_f1\"] = f1\n",
    "        \n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            print(f\" — val_macro_f1: {f1:.4f} ★ New Best!\")\n",
    "        else:\n",
    "            print(f\" — val_macro_f1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 13) 训练函数\n",
    "# =====================\n",
    "def train_conformer_v3(Xtr, ytr, Xte, yte, le_emo, \n",
    "                       epochs=100, batch_size=64, \n",
    "                       exp_dir=EXP_DIR, model_dir=MODEL_DIR, log_dir=LOG_DIR):\n",
    "    \"\"\"V3 完整训练流程\"\"\"\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    n_classes = len(le_emo.classes_)\n",
    "    model = build_conformer_v3(input_shape=Xtr.shape[1:], n_classes=n_classes)\n",
    "    \n",
    "    # 保存模型结构\n",
    "    model.summary()\n",
    "    with open(os.path.join(log_dir, \"model_summary.txt\"), \"w\") as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
    "    \n",
    "    # One-hot编码\n",
    "    ytr_onehot = tf.keras.utils.to_categorical(ytr, n_classes)\n",
    "    yte_onehot = tf.keras.utils.to_categorical(yte, n_classes)\n",
    "    \n",
    "    # 编译\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(\n",
    "            learning_rate=8e-4,\n",
    "            weight_decay=2e-4\n",
    "        ),\n",
    "        loss=LabelSmoothingFocalLoss(smoothing=0.1, gamma=2.0),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # 学习率调度\n",
    "    def lr_schedule(epoch):\n",
    "        warmup_epochs = 5\n",
    "        initial_lr = 8e-4\n",
    "        \n",
    "        if epoch < warmup_epochs:\n",
    "            return initial_lr * (epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - warmup_epochs) / (epochs - warmup_epochs)\n",
    "            return initial_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    # Mixup数据生成器\n",
    "    train_gen = MixupGenerator(Xtr, ytr_onehot, batch_size=batch_size, alpha=0.2)\n",
    "    \n",
    "    # F1回调\n",
    "    f1_callback = MacroF1Callback(Xte, yte)\n",
    "    \n",
    "    # 回调列表\n",
    "    callbacks_list = [\n",
    "        f1_callback,\n",
    "        callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_dir, \"best_model.h5\"),\n",
    "            monitor=\"val_macro_f1\",\n",
    "            mode=\"max\",\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_dir, \"last_model.h5\"),\n",
    "            save_best_only=False,\n",
    "            verbose=0\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor=\"val_macro_f1\",\n",
    "            mode=\"max\",\n",
    "            patience=25,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.LearningRateScheduler(lr_schedule, verbose=0),\n",
    "        callbacks.CSVLogger(os.path.join(log_dir, \"training_log.csv\"))\n",
    "    ]\n",
    "    \n",
    "    # 保存训练配置\n",
    "    config = {\n",
    "        \"model\": \"Conformer V3\",\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"initial_lr\": 8e-4,\n",
    "        \"weight_decay\": 2e-4,\n",
    "        \"mixup_alpha\": 0.2,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"focal_gamma\": 2.0,\n",
    "        \"dropout_rates\": \"0.15/0.25/0.4/0.3\",\n",
    "        \"l2_reg\": 5e-5,\n",
    "        \"train_samples\": len(Xtr),\n",
    "        \"test_samples\": len(Xte),\n",
    "        \"n_classes\": n_classes,\n",
    "        \"classes\": list(le_emo.classes_)\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(log_dir, \"config.txt\"), \"w\") as f:\n",
    "        for k, v in config.items():\n",
    "            f.write(f\"{k}: {v}\\n\")\n",
    "    \n",
    "    # 训练\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Starting Conformer V3 training...\")\n",
    "    print(f\"Output directory: {exp_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=(Xte, yte_onehot),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 保存F1历史\n",
    "    history.history['val_macro_f1'] = f1_callback.f1_history\n",
    "    \n",
    "    return model, history, f1_callback.best_f1\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 14) 评估函数\n",
    "# =====================\n",
    "def evaluate_model(model, Xte, yte, le_emo, plot_dir=PLOT_DIR, log_dir=LOG_DIR):\n",
    "    \"\"\"完整模型评估\"\"\"\n",
    "    \n",
    "    # 预测\n",
    "    y_pred_proba = model.predict(Xte, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    # 计算指标\n",
    "    macro_f1 = f1_score(yte, y_pred, average=\"macro\")\n",
    "    weighted_f1 = f1_score(yte, y_pred, average=\"weighted\")\n",
    "    accuracy = np.mean(y_pred == yte)\n",
    "    class_f1 = f1_score(yte, y_pred, average=None)\n",
    "    \n",
    "    # 分类报告\n",
    "    report = classification_report(yte, y_pred, target_names=le_emo.classes_, digits=4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Classification Report - Conformer V3\")\n",
    "    print(\"=\" * 60)\n",
    "    print(report)\n",
    "    \n",
    "    # 保存报告\n",
    "    with open(os.path.join(log_dir, \"classification_report.txt\"), \"w\") as f:\n",
    "        f.write(\"Classification Report - Conformer V3\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        f.write(report)\n",
    "        f.write(f\"\\nSummary:\\n\")\n",
    "        f.write(f\"  Accuracy:    {accuracy:.4f}\\n\")\n",
    "        f.write(f\"  Macro F1:    {macro_f1:.4f}\\n\")\n",
    "        f.write(f\"  Weighted F1: {weighted_f1:.4f}\\n\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"  Macro F1:    {macro_f1:.4f}\")\n",
    "    print(f\"  Weighted F1: {weighted_f1:.4f}\")\n",
    "    \n",
    "    # ========== 绘图 ==========\n",
    "    \n",
    "    # 1. 混淆矩阵\n",
    "    cm = confusion_matrix(yte, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "        xticklabels=le_emo.classes_, yticklabels=le_emo.classes_,\n",
    "        annot_kws={\"size\": 12}\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix — Conformer V3\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted\", fontsize=14)\n",
    "    plt.ylabel(\"True\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"confusion_matrix.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: confusion_matrix.png\")\n",
    "    \n",
    "    # 2. 归一化混淆矩阵\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm_norm, annot=True, fmt=\".2%\", cmap=\"Blues\",\n",
    "        xticklabels=le_emo.classes_, yticklabels=le_emo.classes_,\n",
    "        annot_kws={\"size\": 11}\n",
    "    )\n",
    "    plt.title(\"Normalized Confusion Matrix — Conformer V3\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted\", fontsize=14)\n",
    "    plt.ylabel(\"True\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"confusion_matrix_normalized.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: confusion_matrix_normalized.png\")\n",
    "    \n",
    "    # 3. 各类别F1柱状图\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(le_emo.classes_, class_f1, color=colors[:len(le_emo.classes_)])\n",
    "    plt.axhline(y=macro_f1, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Macro F1 = {macro_f1:.4f}')\n",
    "    plt.xlabel('Emotion Class', fontsize=14)\n",
    "    plt.ylabel('F1 Score', fontsize=14)\n",
    "    plt.title('Per-Class F1 Score — Conformer V3', fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.ylim(0, 1)\n",
    "    for bar, f1 in zip(bars, class_f1):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'{f1:.3f}', ha='center', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"class_f1_scores.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: class_f1_scores.png\")\n",
    "    \n",
    "    # 4. Precision vs Recall 对比\n",
    "    from sklearn.metrics import precision_score, recall_score\n",
    "    precision = precision_score(yte, y_pred, average=None)\n",
    "    recall = recall_score(yte, y_pred, average=None)\n",
    "    \n",
    "    x = np.arange(len(le_emo.classes_))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars1 = plt.bar(x - width/2, precision, width, label='Precision', color='#3498db')\n",
    "    bars2 = plt.bar(x + width/2, recall, width, label='Recall', color='#e74c3c')\n",
    "    plt.xlabel('Emotion Class', fontsize=14)\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    plt.title('Precision vs Recall — Conformer V3', fontsize=16)\n",
    "    plt.xticks(x, le_emo.classes_)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"precision_recall.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: precision_recall.png\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"class_f1\": dict(zip(le_emo.classes_, class_f1)),\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 15) 绘制训练曲线\n",
    "# =====================\n",
    "def plot_training_history(history, plot_dir=PLOT_DIR):\n",
    "    \"\"\"绘制并保存训练曲线\"\"\"\n",
    "    \n",
    "    # 1. Loss曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2, color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2, color='orange')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Training & Validation Loss', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"loss_curve.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: loss_curve.png\")\n",
    "    \n",
    "    # 2. Accuracy曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc', linewidth=2, color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc', linewidth=2, color='orange')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Training & Validation Accuracy', fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"accuracy_curve.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: accuracy_curve.png\")\n",
    "    \n",
    "    # 3. Macro F1曲线\n",
    "    if 'val_macro_f1' in history.history:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        f1_history = history.history['val_macro_f1']\n",
    "        plt.plot(f1_history, label='Val Macro F1', linewidth=2, color='green')\n",
    "        \n",
    "        # 标记最佳点\n",
    "        best_epoch = np.argmax(f1_history)\n",
    "        best_f1 = f1_history[best_epoch]\n",
    "        plt.axvline(x=best_epoch, color='red', linestyle='--', alpha=0.7)\n",
    "        plt.scatter([best_epoch], [best_f1], color='red', s=100, zorder=5)\n",
    "        plt.annotate(f'Best: {best_f1:.4f}\\nEpoch {best_epoch + 1}', \n",
    "                    xy=(best_epoch, best_f1), \n",
    "                    xytext=(best_epoch + 5, best_f1 - 0.05),\n",
    "                    fontsize=10, \n",
    "                    arrowprops=dict(arrowstyle='->', color='red'))\n",
    "        \n",
    "        plt.xlabel('Epoch', fontsize=12)\n",
    "        plt.ylabel('Macro F1', fontsize=12)\n",
    "        plt.title('Validation Macro F1', fontsize=14)\n",
    "        plt.legend(fontsize=11)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, \"macro_f1_curve.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Saved: macro_f1_curve.png\")\n",
    "    \n",
    "    # 4. 学习率曲线\n",
    "    if 'lr' in history.history:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(history.history['lr'], linewidth=2, color='purple')\n",
    "        plt.xlabel('Epoch', fontsize=12)\n",
    "        plt.ylabel('Learning Rate', fontsize=12)\n",
    "        plt.title('Learning Rate Schedule (Warmup + Cosine)', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, \"learning_rate.png\"), dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Saved: learning_rate.png\")\n",
    "    \n",
    "    # 5. 综合图（子图）\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss', fontsize=12)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Val', linewidth=2)\n",
    "    axes[0, 1].set_title('Accuracy', fontsize=12)\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Macro F1\n",
    "    if 'val_macro_f1' in history.history:\n",
    "        axes[1, 0].plot(history.history['val_macro_f1'], label='Val Macro F1', \n",
    "                        linewidth=2, color='green')\n",
    "        axes[1, 0].set_title('Validation Macro F1', fontsize=12)\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 1].plot(history.history['lr'], linewidth=2, color='purple')\n",
    "        axes[1, 1].set_title('Learning Rate', fontsize=12)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Training Overview — Conformer V3', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"training_overview.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: training_overview.png\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 16) 模型对比函数\n",
    "# =====================\n",
    "def compare_with_previous(current_results, plot_dir=PLOT_DIR):\n",
    "    \"\"\"与之前模型对比\"\"\"\n",
    "    \n",
    "    # 之前模型的结果\n",
    "    previous_results = {\n",
    "        \"CNN\": {\"macro_f1\": 0.4848, \"accuracy\": 0.5006},\n",
    "        \"CRNN\": {\"macro_f1\": 0.5187, \"accuracy\": 0.5258},\n",
    "        \"Transformer\": {\"macro_f1\": 0.5694, \"accuracy\": 0.5722},\n",
    "        \"Conformer_V1\": {\"macro_f1\": 0.6738, \"accuracy\": 0.6743},\n",
    "        \"Conformer_V2\": {\"macro_f1\": 0.6411, \"accuracy\": 0.6360},\n",
    "        \"Conformer_V3\": {\"macro_f1\": current_results[\"macro_f1\"], \n",
    "                         \"accuracy\": current_results[\"accuracy\"]}\n",
    "    }\n",
    "    \n",
    "    models = list(previous_results.keys())\n",
    "    macro_f1s = [previous_results[m][\"macro_f1\"] for m in models]\n",
    "    accuracies = [previous_results[m][\"accuracy\"] for m in models]\n",
    "    \n",
    "    # 对比图\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    bars1 = ax.bar(x - width/2, macro_f1s, width, label='Macro F1', color='#3498db')\n",
    "    bars2 = ax.bar(x + width/2, accuracies, width, label='Accuracy', color='#2ecc71')\n",
    "    \n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Score', fontsize=14)\n",
    "    ax.set_title('Model Comparison — All Experiments', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=15)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"model_comparison.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: model_comparison.png\")\n",
    "    \n",
    "    # 保存对比结果\n",
    "    with open(os.path.join(LOG_DIR, \"model_comparison.txt\"), \"w\") as f:\n",
    "        f.write(\"Model Comparison Results\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"{'Model':<20} {'Macro F1':<12} {'Accuracy':<12}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        for m in models:\n",
    "            f.write(f\"{m:<20} {previous_results[m]['macro_f1']:<12.4f} {previous_results[m]['accuracy']:<12.4f}\\n\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 17) 主程序\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Speech Emotion Recognition - Conformer V3\")\n",
    "    print(\"Dataset: CREMA-D\")\n",
    "    print(f\"Experiment Directory: {EXP_DIR}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 训练模型\n",
    "    model, history, best_f1 = train_conformer_v3(\n",
    "        Xtr, ytr, Xte, yte, le_emo,\n",
    "        epochs=100,\n",
    "        batch_size=64\n",
    "    )\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    print(\"\\nPlotting training curves...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # 评估模型\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    results = evaluate_model(model, Xte, yte, le_emo)\n",
    "    \n",
    "    # 与之前模型对比\n",
    "    print(\"\\nComparing with previous models...\")\n",
    "    compare_with_previous(results)\n",
    "    \n",
    "    # 保存最终结果\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Final Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy:    {results['accuracy']:.4f}\")\n",
    "    print(f\"Macro F1:    {results['macro_f1']:.4f}\")\n",
    "    print(f\"Weighted F1: {results['weighted_f1']:.4f}\")\n",
    "    print(\"\\nPer-class F1:\")\n",
    "    for emotion, f1 in results['class_f1'].items():\n",
    "        print(f\"  {emotion}: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"✓ All results saved to: {EXP_DIR}\")\n",
    "    print(f\"  - Models: {MODEL_DIR}\")\n",
    "    print(f\"  - Plots:  {PLOT_DIR}\")\n",
    "    print(f\"  - Logs:   {LOG_DIR}\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f5ca81-5247-4722-aaa7-cfd862027793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FocalLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 11\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# 加载最佳模型\u001B[39;00m\n\u001B[1;32m      9\u001B[0m best_model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_conformer.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[0;32m---> 11\u001B[0m     custom_objects\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFocalLoss\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mFocalLoss\u001B[49m}\n\u001B[1;32m     12\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# 预测\u001B[39;00m\n\u001B[1;32m     15\u001B[0m y_pred_proba \u001B[38;5;241m=\u001B[39m best_model\u001B[38;5;241m.\u001B[39mpredict(Xte, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FocalLoss' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc8b33-045a-427b-b612-1390e5d8a87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
