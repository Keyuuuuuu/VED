{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33eb0dce-d883-408d-8174-f155f6d728dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:25:48.567941: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 03:25:48.685852: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 03:25:49.726944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.1\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✓ Experiment directory created: VED/Output/conformer_v3_1_notebook_20251204_032550\n",
      "Total samples: 7442\n",
      "Emotion distribution:\n",
      "emotion\n",
      "ANG    1271\n",
      "DIS    1271\n",
      "FEA    1271\n",
      "HAP    1271\n",
      "SAD    1271\n",
      "NEU    1087\n",
      "Name: count, dtype: int64\n",
      "Feature shape: (300, 64, 1)\n",
      "Extracting features...\n",
      "  Processing 0/7442...\n",
      "  Processing 500/7442...\n",
      "  Processing 1000/7442...\n",
      "  Processing 1500/7442...\n",
      "  Processing 2000/7442...\n",
      "  Processing 2500/7442...\n",
      "  Processing 3000/7442...\n",
      "  Processing 3500/7442...\n",
      "  Processing 4000/7442...\n",
      "  Processing 4500/7442...\n",
      "  Processing 5000/7442...\n",
      "  Processing 5500/7442...\n",
      "  Processing 6000/7442...\n",
      "  Processing 6500/7442...\n",
      "  Processing 7000/7442...\n",
      "Feature matrix shape: (7442, 300, 64, 1)\n",
      "Classes: ['ANG' 'DIS' 'FEA' 'HAP' 'NEU' 'SAD']\n",
      "Number of classes: 6\n",
      "Train: (5890, 300, 64, 1), Test: (1552, 300, 64, 1)\n",
      "Normalized - Train mean: -0.0000, std: 1.0000\n",
      "\n",
      "============================================================\n",
      "Speech Emotion Recognition - Conformer V3.1 (Fine-tuned)\n",
      "Dataset: CREMA-D\n",
      "Experiment Directory: VED/Output/conformer_v3_1_notebook_20251204_032550\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:26:48.022411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:04.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 300, 64, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNo  (None, 300, 64, 1)           0         ['input_1[0][0]']             \n",
      " ise)                                                                                             \n",
      "                                                                                                  \n",
      " spec_augment (SpecAugment)  (None, 300, 64, 1)           0         ['gaussian_noise[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 300, 64, 32)          320       ['spec_augment[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 300, 64, 32)          832       ['spec_augment[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 300, 64, 32)          1600      ['spec_augment[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 300, 64, 96)          0         ['conv2d[0][0]',              \n",
      "                                                                     'conv2d_1[0][0]',            \n",
      "                                                                     'conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 300, 64, 96)          384       ['concatenate[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 96)                   0         ['batch_normalization[0][0]'] \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 12)                   1164      ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 96)                   1248      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 1, 96)             0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 300, 64, 96)          0         ['batch_normalization[0][0]', \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 150, 32, 96)          0         ['multiply[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 150, 32, 128)         110720    ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 150, 32, 128)         512       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 128)                  0         ['batch_normalization_1[0][0]'\n",
      "  (GlobalAveragePooling2D)                                          ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   2064      ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  2176      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 1, 128)            0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 150, 32, 128)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    , 'reshape_1[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 75, 16, 128)          0         ['multiply_1[0][0]']          \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout2d (Spatial  (None, 75, 16, 128)          0         ['max_pooling2d_1[0][0]']     \n",
      " Dropout2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 75, 16, 256)          295168    ['spatial_dropout2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 75, 16, 256)          1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 256)                  0         ['batch_normalization_2[0][0]'\n",
      "  (GlobalAveragePooling2D)                                          ]                             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   8224      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 256)                  8448      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 1, 256)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 75, 16, 256)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    , 'reshape_2[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 37, 8, 256)           0         ['multiply_2[0][0]']          \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (Spati  (None, 37, 8, 256)           0         ['max_pooling2d_2[0][0]']     \n",
      " alDropout2D)                                                                                     \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 37, 2048)             0         ['spatial_dropout2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 37, 128)              262272    ['reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 37, 128)              0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 37, 512)              66048     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 37, 512)              0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 37, 128)              65664     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 37, 128)              0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 37, 128)              0         ['dropout_2[0][0]']           \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 37, 128)              0         ['dropout[0][0]',             \n",
      " Lambda)                                                             'tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 37, 128)              256       ['tf.__operators__.add[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 37, 128)              66048     ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 37, 128)              0         ['layer_normalization[0][0]', \n",
      " OpLambda)                                                           'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_1[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 37, 256)              33024     ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 37, 128)              0         ['conv1d[0][0]']              \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 37, 128)              0         ['conv1d[0][0]']              \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambd  (None, 37, 128)              0         ['tf.__operators__.getitem_1[0\n",
      " a)                                                                 ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 37, 128)              0         ['tf.__operators__.getitem[0][\n",
      " mbda)                                                              0]',                          \n",
      "                                                                     'tf.math.sigmoid[0][0]']     \n",
      "                                                                                                  \n",
      " depthwise_conv1d (Depthwis  (None, 37, 128)              2048      ['tf.math.multiply_1[0][0]']  \n",
      " eConv1D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 37, 128)              512       ['depthwise_conv1d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 37, 128)              0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 37, 128)              16512     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 37, 128)              0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 37, 128)              0         ['layer_normalization_1[0][0]'\n",
      " OpLambda)                                                          , 'dropout_3[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 37, 512)              66048     ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 37, 512)              0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 37, 128)              65664     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 37, 128)              0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 37, 128)              0         ['dropout_5[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 37, 128)              0         ['layer_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 37, 512)              66048     ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 37, 512)              0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 37, 128)              65664     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 37, 128)              0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (None, 37, 128)              0         ['dropout_7[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 37, 128)              0         ['layer_normalization_3[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_4[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 37, 128)              66048     ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 37, 128)              0         ['layer_normalization_4[0][0]'\n",
      " OpLambda)                                                          , 'multi_head_attention_1[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_5[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 37, 256)              33024     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 37, 128)              0         ['conv1d_2[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 37, 128)              0         ['conv1d_2[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_1 (TFOpLam  (None, 37, 128)              0         ['tf.__operators__.getitem_3[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (None, 37, 128)              0         ['tf.__operators__.getitem_2[0\n",
      " mbda)                                                              ][0]',                        \n",
      "                                                                     'tf.math.sigmoid_1[0][0]']   \n",
      "                                                                                                  \n",
      " depthwise_conv1d_1 (Depthw  (None, 37, 128)              2048      ['tf.math.multiply_4[0][0]']  \n",
      " iseConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 37, 128)              512       ['depthwise_conv1d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 37, 128)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 37, 128)              16512     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 37, 128)              0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 37, 128)              0         ['layer_normalization_5[0][0]'\n",
      " OpLambda)                                                          , 'dropout_8[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_6[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 37, 512)              66048     ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 37, 512)              0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 37, 128)              65664     ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 37, 128)              0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (None, 37, 128)              0         ['dropout_10[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 37, 128)              0         ['layer_normalization_6[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_7[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 37, 1)                129       ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " softmax (Softmax)           (None, 37, 1)                0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (None, 37, 128)              0         ['layer_normalization_7[0][0]'\n",
      " mbda)                                                              , 'softmax[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLa  (None, 128)                  0         ['tf.math.multiply_6[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 128)                  0         ['tf.math.reduce_sum[0][0]']  \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 64)                   8256      ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 64)                   0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " emotion (Dense)             (None, 6)                    390       ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1470115 (5.61 MB)\n",
      "Trainable params: 1468643 (5.60 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "============================================================\n",
      "Starting Conformer V3.1 training...\n",
      "Output directory: VED/Output/conformer_v3_1_notebook_20251204_032550\n",
      "============================================================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 03:26:59.894706: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/spatial_dropout2d/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-12-04 03:27:01.467529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-12-04 03:27:02.114149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b304962ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-04 03:27:02.114191: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-12-04 03:27:02.123902: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-04 03:27:02.308019: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - ETA: 0s - loss: 1.1573 - accuracy: 0.3014 — val_macro_f1: 0.1104 ★ New Best!\n",
      "\n",
      "Epoch 1: val_macro_f1 improved from -inf to 0.11038, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 39s 168ms/step - loss: 1.1573 - accuracy: 0.3014 - val_loss: 2.6479 - val_accuracy: 0.2223 - val_macro_f1: 0.1104 - lr: 1.6000e-04\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0614 - accuracy: 0.3450 — val_macro_f1: 0.1014\n",
      "\n",
      "Epoch 2: val_macro_f1 did not improve from 0.11038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 1.0614 - accuracy: 0.3450 - val_loss: 2.5752 - val_accuracy: 0.2152 - val_macro_f1: 0.1014 - lr: 3.2000e-04\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0276 - accuracy: 0.3796 — val_macro_f1: 0.0491\n",
      "\n",
      "Epoch 3: val_macro_f1 did not improve from 0.11038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 1.0276 - accuracy: 0.3796 - val_loss: 2.0683 - val_accuracy: 0.1707 - val_macro_f1: 0.0491 - lr: 4.8000e-04\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.3975 — val_macro_f1: 0.3097 ★ New Best!\n",
      "\n",
      "Epoch 4: val_macro_f1 improved from 0.11038 to 0.30967, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 129ms/step - loss: 1.0060 - accuracy: 0.3975 - val_loss: 1.0818 - val_accuracy: 0.3447 - val_macro_f1: 0.3097 - lr: 6.4000e-04\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9773 - accuracy: 0.4143 — val_macro_f1: 0.3966 ★ New Best!\n",
      "\n",
      "Epoch 5: val_macro_f1 improved from 0.30967 to 0.39660, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 129ms/step - loss: 0.9773 - accuracy: 0.4143 - val_loss: 0.9788 - val_accuracy: 0.4104 - val_macro_f1: 0.3966 - lr: 8.0000e-04\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.4424 — val_macro_f1: 0.4232 ★ New Best!\n",
      "\n",
      "Epoch 6: val_macro_f1 improved from 0.39660 to 0.42322, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 129ms/step - loss: 0.9368 - accuracy: 0.4424 - val_loss: 0.9283 - val_accuracy: 0.4517 - val_macro_f1: 0.4232 - lr: 8.0000e-04\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.4666 — val_macro_f1: 0.3675\n",
      "\n",
      "Epoch 7: val_macro_f1 did not improve from 0.42322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.9150 - accuracy: 0.4666 - val_loss: 1.0038 - val_accuracy: 0.3956 - val_macro_f1: 0.3675 - lr: 7.9978e-04\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8886 - accuracy: 0.4866 — val_macro_f1: 0.4174\n",
      "\n",
      "Epoch 8: val_macro_f1 did not improve from 0.42322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.8886 - accuracy: 0.4866 - val_loss: 1.0225 - val_accuracy: 0.4620 - val_macro_f1: 0.4174 - lr: 7.9913e-04\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8725 - accuracy: 0.4993 — val_macro_f1: 0.4754 ★ New Best!\n",
      "\n",
      "Epoch 9: val_macro_f1 improved from 0.42322 to 0.47537, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 129ms/step - loss: 0.8725 - accuracy: 0.4993 - val_loss: 0.8393 - val_accuracy: 0.5045 - val_macro_f1: 0.4754 - lr: 7.9803e-04\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8248 - accuracy: 0.5216 — val_macro_f1: 0.5011 ★ New Best!\n",
      "\n",
      "Epoch 10: val_macro_f1 improved from 0.47537 to 0.50114, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.8248 - accuracy: 0.5216 - val_loss: 0.8634 - val_accuracy: 0.5110 - val_macro_f1: 0.5011 - lr: 7.9651e-04\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.5267 — val_macro_f1: 0.5040 ★ New Best!\n",
      "\n",
      "Epoch 11: val_macro_f1 improved from 0.50114 to 0.50405, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.8303 - accuracy: 0.5267 - val_loss: 0.8194 - val_accuracy: 0.5148 - val_macro_f1: 0.5040 - lr: 7.9454e-04\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8165 - accuracy: 0.5273 — val_macro_f1: 0.4773\n",
      "\n",
      "Epoch 12: val_macro_f1 did not improve from 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.8165 - accuracy: 0.5273 - val_loss: 0.8538 - val_accuracy: 0.4981 - val_macro_f1: 0.4773 - lr: 7.9215e-04\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7934 - accuracy: 0.5538 — val_macro_f1: 0.4117\n",
      "\n",
      "Epoch 13: val_macro_f1 did not improve from 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.7934 - accuracy: 0.5538 - val_loss: 0.9227 - val_accuracy: 0.4671 - val_macro_f1: 0.4117 - lr: 7.8933e-04\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7918 - accuracy: 0.5516 — val_macro_f1: 0.4261\n",
      "\n",
      "Epoch 14: val_macro_f1 did not improve from 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.7918 - accuracy: 0.5516 - val_loss: 0.9444 - val_accuracy: 0.4549 - val_macro_f1: 0.4261 - lr: 7.8608e-04\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.5635 — val_macro_f1: 0.4698\n",
      "\n",
      "Epoch 15: val_macro_f1 did not improve from 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.7829 - accuracy: 0.5635 - val_loss: 0.8800 - val_accuracy: 0.4794 - val_macro_f1: 0.4698 - lr: 7.8241e-04\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7529 - accuracy: 0.5912 — val_macro_f1: 0.4308\n",
      "\n",
      "Epoch 16: val_macro_f1 did not improve from 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.7529 - accuracy: 0.5912 - val_loss: 0.8872 - val_accuracy: 0.4510 - val_macro_f1: 0.4308 - lr: 7.7833e-04\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7558 - accuracy: 0.5798 — val_macro_f1: 0.5253 ★ New Best!\n",
      "\n",
      "Epoch 17: val_macro_f1 improved from 0.50405 to 0.52526, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.7558 - accuracy: 0.5798 - val_loss: 0.7947 - val_accuracy: 0.5412 - val_macro_f1: 0.5253 - lr: 7.7383e-04\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7553 - accuracy: 0.5805 — val_macro_f1: 0.4627\n",
      "\n",
      "Epoch 18: val_macro_f1 did not improve from 0.52526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.7553 - accuracy: 0.5805 - val_loss: 0.8851 - val_accuracy: 0.4961 - val_macro_f1: 0.4627 - lr: 7.6892e-04\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7038 - accuracy: 0.5980 — val_macro_f1: 0.5565 ★ New Best!\n",
      "\n",
      "Epoch 19: val_macro_f1 improved from 0.52526 to 0.55650, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.7038 - accuracy: 0.5980 - val_loss: 0.7718 - val_accuracy: 0.5580 - val_macro_f1: 0.5565 - lr: 7.6360e-04\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.6117 — val_macro_f1: 0.5886 ★ New Best!\n",
      "\n",
      "Epoch 20: val_macro_f1 improved from 0.55650 to 0.58862, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.7019 - accuracy: 0.6117 - val_loss: 0.7008 - val_accuracy: 0.5902 - val_macro_f1: 0.5886 - lr: 7.5789e-04\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7172 - accuracy: 0.6075 — val_macro_f1: 0.5419\n",
      "\n",
      "Epoch 21: val_macro_f1 did not improve from 0.58862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.7172 - accuracy: 0.6075 - val_loss: 0.7887 - val_accuracy: 0.5580 - val_macro_f1: 0.5419 - lr: 7.5179e-04\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7054 - accuracy: 0.6126 — val_macro_f1: 0.5497\n",
      "\n",
      "Epoch 22: val_macro_f1 did not improve from 0.58862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.7054 - accuracy: 0.6126 - val_loss: 0.8056 - val_accuracy: 0.5541 - val_macro_f1: 0.5497 - lr: 7.4530e-04\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.6370 — val_macro_f1: 0.5776\n",
      "\n",
      "Epoch 23: val_macro_f1 did not improve from 0.58862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6771 - accuracy: 0.6370 - val_loss: 0.7320 - val_accuracy: 0.5825 - val_macro_f1: 0.5776 - lr: 7.3844e-04\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.6355 — val_macro_f1: 0.5949 ★ New Best!\n",
      "\n",
      "Epoch 24: val_macro_f1 improved from 0.58862 to 0.59487, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 0.6661 - accuracy: 0.6355 - val_loss: 0.7012 - val_accuracy: 0.5992 - val_macro_f1: 0.5949 - lr: 7.3120e-04\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6711 - accuracy: 0.6424 — val_macro_f1: 0.5806\n",
      "\n",
      "Epoch 25: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6711 - accuracy: 0.6424 - val_loss: 0.7309 - val_accuracy: 0.5857 - val_macro_f1: 0.5806 - lr: 7.2361e-04\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.6440 — val_macro_f1: 0.5571\n",
      "\n",
      "Epoch 26: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.6638 - accuracy: 0.6440 - val_loss: 0.7675 - val_accuracy: 0.5754 - val_macro_f1: 0.5571 - lr: 7.1566e-04\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.6409 — val_macro_f1: 0.5692\n",
      "\n",
      "Epoch 27: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6592 - accuracy: 0.6409 - val_loss: 0.7315 - val_accuracy: 0.5722 - val_macro_f1: 0.5692 - lr: 7.0736e-04\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.6550 — val_macro_f1: 0.5826\n",
      "\n",
      "Epoch 28: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6429 - accuracy: 0.6550 - val_loss: 0.7522 - val_accuracy: 0.5838 - val_macro_f1: 0.5826 - lr: 6.9873e-04\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.6509 — val_macro_f1: 0.5518\n",
      "\n",
      "Epoch 29: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6631 - accuracy: 0.6509 - val_loss: 0.7584 - val_accuracy: 0.5573 - val_macro_f1: 0.5518 - lr: 6.8977e-04\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.6570 — val_macro_f1: 0.5270\n",
      "\n",
      "Epoch 30: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.6414 - accuracy: 0.6570 - val_loss: 0.8641 - val_accuracy: 0.5329 - val_macro_f1: 0.5270 - lr: 6.8049e-04\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.6808 — val_macro_f1: 0.5852\n",
      "\n",
      "Epoch 31: val_macro_f1 did not improve from 0.59487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.6021 - accuracy: 0.6808 - val_loss: 0.7168 - val_accuracy: 0.5999 - val_macro_f1: 0.5852 - lr: 6.7091e-04\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.6764 — val_macro_f1: 0.6254 ★ New Best!\n",
      "\n",
      "Epoch 32: val_macro_f1 improved from 0.59487 to 0.62538, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.6075 - accuracy: 0.6764 - val_loss: 0.6887 - val_accuracy: 0.6295 - val_macro_f1: 0.6254 - lr: 6.6103e-04\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5816 - accuracy: 0.7042 — val_macro_f1: 0.6276 ★ New Best!\n",
      "\n",
      "Epoch 33: val_macro_f1 improved from 0.62538 to 0.62762, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.5816 - accuracy: 0.7042 - val_loss: 0.6725 - val_accuracy: 0.6269 - val_macro_f1: 0.6276 - lr: 6.5087e-04\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7063 — val_macro_f1: 0.5670\n",
      "\n",
      "Epoch 34: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 124ms/step - loss: 0.5679 - accuracy: 0.7063 - val_loss: 0.7734 - val_accuracy: 0.5644 - val_macro_f1: 0.5670 - lr: 6.4043e-04\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.6837 — val_macro_f1: 0.6035\n",
      "\n",
      "Epoch 35: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.6184 - accuracy: 0.6837 - val_loss: 0.7578 - val_accuracy: 0.6108 - val_macro_f1: 0.6035 - lr: 6.2973e-04\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.6988 — val_macro_f1: 0.6025\n",
      "\n",
      "Epoch 36: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.6058 - accuracy: 0.6988 - val_loss: 0.7255 - val_accuracy: 0.6153 - val_macro_f1: 0.6025 - lr: 6.1878e-04\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7287 — val_macro_f1: 0.6088\n",
      "\n",
      "Epoch 37: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.5351 - accuracy: 0.7287 - val_loss: 0.6956 - val_accuracy: 0.6173 - val_macro_f1: 0.6088 - lr: 6.0759e-04\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.7138 — val_macro_f1: 0.6013\n",
      "\n",
      "Epoch 38: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.5622 - accuracy: 0.7138 - val_loss: 0.7296 - val_accuracy: 0.6128 - val_macro_f1: 0.6013 - lr: 5.9617e-04\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.7341 — val_macro_f1: 0.5805\n",
      "\n",
      "Epoch 39: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.5475 - accuracy: 0.7341 - val_loss: 0.7820 - val_accuracy: 0.5966 - val_macro_f1: 0.5805 - lr: 5.8454e-04\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.7358 — val_macro_f1: 0.5826\n",
      "\n",
      "Epoch 40: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.5436 - accuracy: 0.7358 - val_loss: 0.8091 - val_accuracy: 0.5883 - val_macro_f1: 0.5826 - lr: 5.7270e-04\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.7258 — val_macro_f1: 0.6199\n",
      "\n",
      "Epoch 41: val_macro_f1 did not improve from 0.62762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.5550 - accuracy: 0.7258 - val_loss: 0.6730 - val_accuracy: 0.6263 - val_macro_f1: 0.6199 - lr: 5.6068e-04\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.7428 — val_macro_f1: 0.6308 ★ New Best!\n",
      "\n",
      "Epoch 42: val_macro_f1 improved from 0.62762 to 0.63076, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.5190 - accuracy: 0.7428 - val_loss: 0.6883 - val_accuracy: 0.6340 - val_macro_f1: 0.6308 - lr: 5.4848e-04\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.7567 — val_macro_f1: 0.6227\n",
      "\n",
      "Epoch 43: val_macro_f1 did not improve from 0.63076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.5065 - accuracy: 0.7567 - val_loss: 0.7392 - val_accuracy: 0.6224 - val_macro_f1: 0.6227 - lr: 5.3612e-04\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.7667 — val_macro_f1: 0.6361 ★ New Best!\n",
      "\n",
      "Epoch 44: val_macro_f1 improved from 0.63076 to 0.63608, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 0.5225 - accuracy: 0.7667 - val_loss: 0.7145 - val_accuracy: 0.6366 - val_macro_f1: 0.6361 - lr: 5.2361e-04\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.7628 — val_macro_f1: 0.6071\n",
      "\n",
      "Epoch 45: val_macro_f1 did not improve from 0.63608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4965 - accuracy: 0.7628 - val_loss: 0.7337 - val_accuracy: 0.6115 - val_macro_f1: 0.6071 - lr: 5.1096e-04\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.7752 — val_macro_f1: 0.5878\n",
      "\n",
      "Epoch 46: val_macro_f1 did not improve from 0.63608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4712 - accuracy: 0.7752 - val_loss: 0.7703 - val_accuracy: 0.5921 - val_macro_f1: 0.5878 - lr: 4.9819e-04\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7599 — val_macro_f1: 0.5543\n",
      "\n",
      "Epoch 47: val_macro_f1 did not improve from 0.63608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.5019 - accuracy: 0.7599 - val_loss: 0.8516 - val_accuracy: 0.5683 - val_macro_f1: 0.5543 - lr: 4.8532e-04\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7626 — val_macro_f1: 0.5996\n",
      "\n",
      "Epoch 48: val_macro_f1 did not improve from 0.63608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4846 - accuracy: 0.7626 - val_loss: 0.7394 - val_accuracy: 0.6070 - val_macro_f1: 0.5996 - lr: 4.7235e-04\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.7511 — val_macro_f1: 0.6208\n",
      "\n",
      "Epoch 49: val_macro_f1 did not improve from 0.63608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.5163 - accuracy: 0.7511 - val_loss: 0.8104 - val_accuracy: 0.6186 - val_macro_f1: 0.6208 - lr: 4.5931e-04\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.7789 — val_macro_f1: 0.6528 ★ New Best!\n",
      "\n",
      "Epoch 50: val_macro_f1 improved from 0.63608 to 0.65275, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 0.4669 - accuracy: 0.7789 - val_loss: 0.6493 - val_accuracy: 0.6546 - val_macro_f1: 0.6528 - lr: 4.4619e-04\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.7727 — val_macro_f1: 0.6419\n",
      "\n",
      "Epoch 51: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.4738 - accuracy: 0.7727 - val_loss: 0.7064 - val_accuracy: 0.6469 - val_macro_f1: 0.6419 - lr: 4.3303e-04\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.7757 — val_macro_f1: 0.5971\n",
      "\n",
      "Epoch 52: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.4788 - accuracy: 0.7757 - val_loss: 0.7891 - val_accuracy: 0.6082 - val_macro_f1: 0.5971 - lr: 4.1983e-04\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7968 — val_macro_f1: 0.6359\n",
      "\n",
      "Epoch 53: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.4543 - accuracy: 0.7968 - val_loss: 0.7454 - val_accuracy: 0.6443 - val_macro_f1: 0.6359 - lr: 4.0661e-04\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.8148 — val_macro_f1: 0.6428\n",
      "\n",
      "Epoch 54: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.4152 - accuracy: 0.8148 - val_loss: 0.7347 - val_accuracy: 0.6443 - val_macro_f1: 0.6428 - lr: 3.9339e-04\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8010 — val_macro_f1: 0.6280\n",
      "\n",
      "Epoch 55: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4456 - accuracy: 0.8010 - val_loss: 0.7490 - val_accuracy: 0.6321 - val_macro_f1: 0.6280 - lr: 3.8017e-04\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.8092 — val_macro_f1: 0.6443\n",
      "\n",
      "Epoch 56: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4372 - accuracy: 0.8092 - val_loss: 0.7155 - val_accuracy: 0.6501 - val_macro_f1: 0.6443 - lr: 3.6697e-04\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8202 — val_macro_f1: 0.6436\n",
      "\n",
      "Epoch 57: val_macro_f1 did not improve from 0.65275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4350 - accuracy: 0.8202 - val_loss: 0.7303 - val_accuracy: 0.6501 - val_macro_f1: 0.6436 - lr: 3.5381e-04\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.8154 — val_macro_f1: 0.6601 ★ New Best!\n",
      "\n",
      "Epoch 58: val_macro_f1 improved from 0.65275 to 0.66011, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 128ms/step - loss: 0.4631 - accuracy: 0.8154 - val_loss: 0.7016 - val_accuracy: 0.6630 - val_macro_f1: 0.6601 - lr: 3.4069e-04\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.8411 — val_macro_f1: 0.5623\n",
      "\n",
      "Epoch 59: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.4155 - accuracy: 0.8411 - val_loss: 0.8716 - val_accuracy: 0.5825 - val_macro_f1: 0.5623 - lr: 3.2765e-04\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8019 — val_macro_f1: 0.6508\n",
      "\n",
      "Epoch 60: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.4641 - accuracy: 0.8019 - val_loss: 0.6967 - val_accuracy: 0.6534 - val_macro_f1: 0.6508 - lr: 3.1468e-04\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.8423 — val_macro_f1: 0.6562\n",
      "\n",
      "Epoch 61: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4069 - accuracy: 0.8423 - val_loss: 0.7269 - val_accuracy: 0.6579 - val_macro_f1: 0.6562 - lr: 3.0181e-04\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8528 — val_macro_f1: 0.6597\n",
      "\n",
      "Epoch 62: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3818 - accuracy: 0.8528 - val_loss: 0.7350 - val_accuracy: 0.6617 - val_macro_f1: 0.6597 - lr: 2.8904e-04\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8535 — val_macro_f1: 0.6494\n",
      "\n",
      "Epoch 63: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3937 - accuracy: 0.8535 - val_loss: 0.7609 - val_accuracy: 0.6546 - val_macro_f1: 0.6494 - lr: 2.7639e-04\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8518 — val_macro_f1: 0.6363\n",
      "\n",
      "Epoch 64: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3899 - accuracy: 0.8518 - val_loss: 0.7358 - val_accuracy: 0.6405 - val_macro_f1: 0.6363 - lr: 2.6388e-04\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8574 — val_macro_f1: 0.6482\n",
      "\n",
      "Epoch 65: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.3828 - accuracy: 0.8574 - val_loss: 0.7262 - val_accuracy: 0.6521 - val_macro_f1: 0.6482 - lr: 2.5152e-04\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8553 — val_macro_f1: 0.6088\n",
      "\n",
      "Epoch 66: val_macro_f1 did not improve from 0.66011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3795 - accuracy: 0.8553 - val_loss: 0.7825 - val_accuracy: 0.6153 - val_macro_f1: 0.6088 - lr: 2.3932e-04\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8358 — val_macro_f1: 0.6617 ★ New Best!\n",
      "\n",
      "Epoch 67: val_macro_f1 improved from 0.66011 to 0.66172, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 0.4075 - accuracy: 0.8358 - val_loss: 0.7233 - val_accuracy: 0.6656 - val_macro_f1: 0.6617 - lr: 2.2730e-04\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8441 — val_macro_f1: 0.6454\n",
      "\n",
      "Epoch 68: val_macro_f1 did not improve from 0.66172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4039 - accuracy: 0.8441 - val_loss: 0.7425 - val_accuracy: 0.6514 - val_macro_f1: 0.6454 - lr: 2.1546e-04\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8664 — val_macro_f1: 0.6511\n",
      "\n",
      "Epoch 69: val_macro_f1 did not improve from 0.66172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3519 - accuracy: 0.8664 - val_loss: 0.7599 - val_accuracy: 0.6546 - val_macro_f1: 0.6511 - lr: 2.0383e-04\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8594 — val_macro_f1: 0.6707 ★ New Best!\n",
      "\n",
      "Epoch 70: val_macro_f1 improved from 0.66172 to 0.67073, saving model to VED/Output/conformer_v3_1_notebook_20251204_032550/models/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 127ms/step - loss: 0.3881 - accuracy: 0.8594 - val_loss: 0.7172 - val_accuracy: 0.6714 - val_macro_f1: 0.6707 - lr: 1.9241e-04\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8671 — val_macro_f1: 0.6553\n",
      "\n",
      "Epoch 71: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.4049 - accuracy: 0.8671 - val_loss: 0.7204 - val_accuracy: 0.6579 - val_macro_f1: 0.6553 - lr: 1.8122e-04\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8806 — val_macro_f1: 0.6657\n",
      "\n",
      "Epoch 72: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3746 - accuracy: 0.8806 - val_loss: 0.7112 - val_accuracy: 0.6695 - val_macro_f1: 0.6657 - lr: 1.7027e-04\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.8767 — val_macro_f1: 0.6608\n",
      "\n",
      "Epoch 73: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3647 - accuracy: 0.8767 - val_loss: 0.7387 - val_accuracy: 0.6656 - val_macro_f1: 0.6608 - lr: 1.5957e-04\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8805 — val_macro_f1: 0.6543\n",
      "\n",
      "Epoch 74: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3660 - accuracy: 0.8805 - val_loss: 0.7326 - val_accuracy: 0.6559 - val_macro_f1: 0.6543 - lr: 1.4913e-04\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.9002 — val_macro_f1: 0.6585\n",
      "\n",
      "Epoch 75: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3145 - accuracy: 0.9002 - val_loss: 0.7650 - val_accuracy: 0.6637 - val_macro_f1: 0.6585 - lr: 1.3897e-04\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8808 — val_macro_f1: 0.6618\n",
      "\n",
      "Epoch 76: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3512 - accuracy: 0.8808 - val_loss: 0.7366 - val_accuracy: 0.6649 - val_macro_f1: 0.6618 - lr: 1.2909e-04\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8756 — val_macro_f1: 0.6588\n",
      "\n",
      "Epoch 77: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3717 - accuracy: 0.8756 - val_loss: 0.7306 - val_accuracy: 0.6637 - val_macro_f1: 0.6588 - lr: 1.1951e-04\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.9070 — val_macro_f1: 0.6584\n",
      "\n",
      "Epoch 78: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3336 - accuracy: 0.9070 - val_loss: 0.7431 - val_accuracy: 0.6617 - val_macro_f1: 0.6584 - lr: 1.1023e-04\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8879 — val_macro_f1: 0.6598\n",
      "\n",
      "Epoch 79: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3425 - accuracy: 0.8879 - val_loss: 0.7436 - val_accuracy: 0.6637 - val_macro_f1: 0.6598 - lr: 1.0127e-04\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.9109 — val_macro_f1: 0.6641\n",
      "\n",
      "Epoch 80: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3088 - accuracy: 0.9109 - val_loss: 0.7335 - val_accuracy: 0.6682 - val_macro_f1: 0.6641 - lr: 9.2640e-05\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.8829 — val_macro_f1: 0.6638\n",
      "\n",
      "Epoch 81: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.3604 - accuracy: 0.8829 - val_loss: 0.7281 - val_accuracy: 0.6675 - val_macro_f1: 0.6638 - lr: 8.4344e-05\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9027 — val_macro_f1: 0.6707\n",
      "\n",
      "Epoch 82: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3263 - accuracy: 0.9027 - val_loss: 0.7337 - val_accuracy: 0.6733 - val_macro_f1: 0.6707 - lr: 7.6393e-05\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8995 — val_macro_f1: 0.6683\n",
      "\n",
      "Epoch 83: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3643 - accuracy: 0.8995 - val_loss: 0.7106 - val_accuracy: 0.6714 - val_macro_f1: 0.6683 - lr: 6.8796e-05\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3171 - accuracy: 0.9161 — val_macro_f1: 0.6598\n",
      "\n",
      "Epoch 84: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3171 - accuracy: 0.9161 - val_loss: 0.7328 - val_accuracy: 0.6643 - val_macro_f1: 0.6598 - lr: 6.1562e-05\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8832 — val_macro_f1: 0.6569\n",
      "\n",
      "Epoch 85: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3538 - accuracy: 0.8832 - val_loss: 0.7335 - val_accuracy: 0.6604 - val_macro_f1: 0.6569 - lr: 5.4697e-05\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.8956 — val_macro_f1: 0.6668\n",
      "\n",
      "Epoch 86: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.3445 - accuracy: 0.8956 - val_loss: 0.7346 - val_accuracy: 0.6701 - val_macro_f1: 0.6668 - lr: 4.8210e-05\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9049 — val_macro_f1: 0.6584\n",
      "\n",
      "Epoch 87: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 123ms/step - loss: 0.3261 - accuracy: 0.9049 - val_loss: 0.7353 - val_accuracy: 0.6617 - val_macro_f1: 0.6584 - lr: 4.2108e-05\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8902 — val_macro_f1: 0.6618\n",
      "\n",
      "Epoch 88: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3473 - accuracy: 0.8902 - val_loss: 0.7272 - val_accuracy: 0.6649 - val_macro_f1: 0.6618 - lr: 3.6397e-05\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.9080 — val_macro_f1: 0.6678\n",
      "\n",
      "Epoch 89: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3247 - accuracy: 0.9080 - val_loss: 0.7292 - val_accuracy: 0.6707 - val_macro_f1: 0.6678 - lr: 3.1084e-05\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.9053 — val_macro_f1: 0.6644\n",
      "\n",
      "Epoch 90: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3327 - accuracy: 0.9053 - val_loss: 0.7304 - val_accuracy: 0.6682 - val_macro_f1: 0.6644 - lr: 2.6174e-05\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.9070 — val_macro_f1: 0.6560\n",
      "\n",
      "Epoch 91: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 124ms/step - loss: 0.3260 - accuracy: 0.9070 - val_loss: 0.7423 - val_accuracy: 0.6604 - val_macro_f1: 0.6560 - lr: 2.1673e-05\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.9095 — val_macro_f1: 0.6666\n",
      "\n",
      "Epoch 92: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 11s 124ms/step - loss: 0.3265 - accuracy: 0.9095 - val_loss: 0.7294 - val_accuracy: 0.6695 - val_macro_f1: 0.6666 - lr: 1.7586e-05\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.9000 — val_macro_f1: 0.6606\n",
      "\n",
      "Epoch 93: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3476 - accuracy: 0.9000 - val_loss: 0.7319 - val_accuracy: 0.6643 - val_macro_f1: 0.6606 - lr: 1.3916e-05\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.8910 — val_macro_f1: 0.6587\n",
      "\n",
      "Epoch 94: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3693 - accuracy: 0.8910 - val_loss: 0.7252 - val_accuracy: 0.6624 - val_macro_f1: 0.6587 - lr: 1.0669e-05\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.9080 — val_macro_f1: 0.6548\n",
      "\n",
      "Epoch 95: val_macro_f1 did not improve from 0.67073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 70.\n",
      "93/93 [==============================] - 12s 125ms/step - loss: 0.3233 - accuracy: 0.9080 - val_loss: 0.7316 - val_accuracy: 0.6585 - val_macro_f1: 0.6548 - lr: 7.8480e-06\n",
      "Epoch 95: early stopping\n",
      "\n",
      "Plotting training curves...\n",
      "  ✓ Saved: training_overview.png\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "============================================================\n",
      "Classification Report - Conformer V3.1\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG     0.7424    0.8264    0.7821       265\n",
      "         DIS     0.6681    0.5698    0.6151       265\n",
      "         FEA     0.5953    0.6717    0.6312       265\n",
      "         HAP     0.6725    0.5811    0.6235       265\n",
      "         NEU     0.7273    0.8106    0.7667       227\n",
      "         SAD     0.6240    0.5887    0.6058       265\n",
      "\n",
      "    accuracy                         0.6714      1552\n",
      "   macro avg     0.6716    0.6747    0.6707      1552\n",
      "weighted avg     0.6702    0.6714    0.6684      1552\n",
      "\n",
      "\n",
      "Summary:\n",
      "  Accuracy:    0.6714\n",
      "  Macro F1:    0.6707\n",
      "  Weighted F1: 0.6684\n",
      "\n",
      "Comparing with previous models...\n",
      "  ✓ Saved: model_comparison.png\n",
      "\n",
      "============================================================\n",
      "Final Results\n",
      "============================================================\n",
      "Accuracy:    0.6714\n",
      "Macro F1:    0.6707\n",
      "Weighted F1: 0.6684\n",
      "\n",
      "============================================================\n",
      "✓ All results saved to: VED/Output/conformer_v3_1_notebook_20251204_032550\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 语音情绪识别 - Conformer V3.1 (微调冲刺版)\n",
    "# 数据集: CREMA-D\n",
    "# 修改: \n",
    "# 1. 自动根据当前文件名创建输出目录\n",
    "# 2. V3.1 配置: 降低 Smoothing/Noise/Dropout 以提升上限\n",
    "# ============================================================================\n",
    "\n",
    "# =====================\n",
    "# 0) 导入必要的库\n",
    "# =====================\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 设置绘图风格\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 1) 自动创建输出目录 (根据文件名)\n",
    "# =====================\n",
    "def create_experiment_dir(base_dir=\"VED/Output\"):\n",
    "    \"\"\"\n",
    "    创建带时间戳的实验目录，目录名基于当前脚本文件名\n",
    "    \"\"\"\n",
    "    # 获取当前脚本的文件名（不带后缀）\n",
    "    try:\n",
    "        # 如果是 .py 脚本运行\n",
    "        script_name = os.path.splitext(os.path.basename(__file__))[0]\n",
    "    except NameError:\n",
    "        # 如果是在 Jupyter Notebook 中运行，使用默认名称\n",
    "        script_name = \"conformer_v3_1_notebook\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exp_dir = os.path.join(base_dir, f\"{script_name}_{timestamp}\")\n",
    "    \n",
    "    # 确保基础路径存在\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # 创建子目录\n",
    "    subdirs = [\"models\", \"plots\", \"logs\"]\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(exp_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    print(f\"✓ Experiment directory created: {exp_dir}\")\n",
    "    return exp_dir\n",
    "\n",
    "\n",
    "# 创建实验目录\n",
    "EXP_DIR = create_experiment_dir()\n",
    "MODEL_DIR = os.path.join(EXP_DIR, \"models\")\n",
    "PLOT_DIR = os.path.join(EXP_DIR, \"plots\")\n",
    "LOG_DIR = os.path.join(EXP_DIR, \"logs\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 2) 数据路径配置\n",
    "# =====================\n",
    "AUDIO_DIR = Path(\"../AudioWAV\")  # 请确保此路径正确\n",
    "assert AUDIO_DIR.exists(), f\"Audio directory not found: {AUDIO_DIR}\"\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 3) 构建元数据\n",
    "# =====================\n",
    "def build_metadata(audio_dir):\n",
    "    \"\"\"从文件名解析元数据\"\"\"\n",
    "    records = []\n",
    "    for wav_file in audio_dir.glob(\"*.wav\"):\n",
    "        filename = wav_file.stem\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) == 4:\n",
    "            speaker, sentence, emotion, intensity = parts\n",
    "            records.append({\n",
    "                \"path\": wav_file,\n",
    "                \"speaker\": speaker,\n",
    "                \"sentence\": sentence,\n",
    "                \"emotion\": emotion,\n",
    "                \"intensity\": intensity\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "meta = build_metadata(AUDIO_DIR)\n",
    "print(f\"Total samples: {len(meta)}\")\n",
    "print(f\"Emotion distribution:\\n{meta['emotion'].value_counts()}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 4) 音频特征提取配置\n",
    "# =====================\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "FFT = 1024\n",
    "HOP = 160\n",
    "WIN = 400\n",
    "FIXED_SECONDS = 3.0\n",
    "MAX_FRAMES = int(math.ceil(FIXED_SECONDS * SR / HOP))\n",
    "\n",
    "print(f\"Feature shape: ({MAX_FRAMES}, {N_MELS}, 1)\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 5) Log-Mel 特征提取\n",
    "# =====================\n",
    "def load_logmel(path: Path):\n",
    "    \"\"\"加载音频并提取Log-Mel频谱图\"\"\"\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "    \n",
    "    target_len = int(FIXED_SECONDS * SR)\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=FFT, hop_length=HOP,\n",
    "        win_length=WIN, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "    feat = np.transpose(S_db[..., None], (1, 0, 2))\n",
    "    \n",
    "    if feat.shape[0] < MAX_FRAMES:\n",
    "        feat = np.pad(feat, ((0, MAX_FRAMES - feat.shape[0]), (0, 0), (0, 0)))\n",
    "    else:\n",
    "        feat = feat[:MAX_FRAMES]\n",
    "    \n",
    "    return feat\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 6) 批量提取特征\n",
    "# =====================\n",
    "print(\"Extracting features...\")\n",
    "specs = []\n",
    "emotions = []\n",
    "speakers = []\n",
    "\n",
    "for idx, row in meta.iterrows():\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"  Processing {idx}/{len(meta)}...\")\n",
    "    specs.append(load_logmel(row['path']))\n",
    "    emotions.append(row['emotion'])\n",
    "    speakers.append(row['speaker'])\n",
    "\n",
    "X = np.stack(specs)\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 7) 标签编码 & 数据划分\n",
    "# =====================\n",
    "le_emo = LabelEncoder()\n",
    "y = le_emo.fit_transform(emotions).astype(np.int32)\n",
    "groups = np.array(speakers)\n",
    "\n",
    "print(f\"Classes: {le_emo.classes_}\")\n",
    "print(f\"Number of classes: {len(le_emo.classes_)}\")\n",
    "\n",
    "# 说话人独立划分\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "Xtr, Xte = X[train_idx], X[test_idx]\n",
    "ytr, yte = y[train_idx], y[test_idx]\n",
    "\n",
    "print(f\"Train: {Xtr.shape}, Test: {Xte.shape}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 8) Z-Score 标准化\n",
    "# =====================\n",
    "mean_spec = Xtr.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_spec = Xtr.std(axis=(0, 1, 2), keepdims=True) + 1e-6\n",
    "\n",
    "Xtr = (Xtr - mean_spec) / std_spec\n",
    "Xte = (Xte - mean_spec) / std_spec\n",
    "\n",
    "print(f\"Normalized - Train mean: {Xtr.mean():.4f}, std: {Xtr.std():.4f}\")\n",
    "\n",
    "# 保存标准化参数\n",
    "np.save(os.path.join(MODEL_DIR, \"norm_mean.npy\"), mean_spec)\n",
    "np.save(os.path.join(MODEL_DIR, \"norm_std.npy\"), std_spec)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 9) 自定义层和函数\n",
    "# =====================\n",
    "\n",
    "class SpecAugment(layers.Layer):\n",
    "    \"\"\"SpecAugment 数据增强层\"\"\"\n",
    "    def __init__(self, time_mask_num=2, freq_mask_num=2, \n",
    "                 time_mask_max=16, freq_mask_max=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.time_mask_num = time_mask_num\n",
    "        self.freq_mask_num = freq_mask_num\n",
    "        self.time_mask_max = time_mask_max\n",
    "        self.freq_mask_max = freq_mask_max\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            return x\n",
    "        \n",
    "        batch_size = tf.shape(x)[0]\n",
    "        T = tf.shape(x)[1]\n",
    "        F = tf.shape(x)[2]\n",
    "        \n",
    "        for _ in range(self.time_mask_num):\n",
    "            t = tf.random.uniform([], 0, self.time_mask_max, dtype=tf.int32)\n",
    "            t0 = tf.random.uniform([], 0, tf.maximum(1, T - t), dtype=tf.int32)\n",
    "            mask = tf.concat([\n",
    "                tf.ones([batch_size, t0, F, 1]),\n",
    "                tf.zeros([batch_size, t, F, 1]),\n",
    "                tf.ones([batch_size, T - t0 - t, F, 1])\n",
    "            ], axis=1)\n",
    "            x = x * mask\n",
    "        \n",
    "        for _ in range(self.freq_mask_num):\n",
    "            f = tf.random.uniform([], 0, self.freq_mask_max, dtype=tf.int32)\n",
    "            f0 = tf.random.uniform([], 0, tf.maximum(1, F - f), dtype=tf.int32)\n",
    "            mask = tf.concat([\n",
    "                tf.ones([batch_size, T, f0, 1]),\n",
    "                tf.zeros([batch_size, T, f, 1]),\n",
    "                tf.ones([batch_size, T, F - f0 - f, 1])\n",
    "            ], axis=2)\n",
    "            x = x * mask\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"time_mask_num\": self.time_mask_num,\n",
    "            \"freq_mask_num\": self.freq_mask_num,\n",
    "            \"time_mask_max\": self.time_mask_max,\n",
    "            \"freq_mask_max\": self.freq_mask_max,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class LabelSmoothingFocalLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Label Smoothing + Focal Loss\"\"\"\n",
    "    def __init__(self, smoothing=0.05, gamma=2.0, **kwargs):\n",
    "        # V3.1 修改：默认 smoothing 降为 0.05\n",
    "        super().__init__(**kwargs)\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        n_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        \n",
    "        # Label smoothing\n",
    "        y_true = y_true * (1 - self.smoothing) + self.smoothing / n_classes\n",
    "        \n",
    "        # Focal loss\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1 - y_pred, self.gamma)\n",
    "        focal = weight * ce\n",
    "        \n",
    "        return tf.reduce_sum(focal, axis=-1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"smoothing\": self.smoothing,\n",
    "            \"gamma\": self.gamma,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def glu_activation(x):\n",
    "    \"\"\"GLU激活函数\"\"\"\n",
    "    channels = x.shape[-1] // 2\n",
    "    return x[..., :channels] * tf.sigmoid(x[..., channels:])\n",
    "\n",
    "\n",
    "def se_block(x, ratio=8):\n",
    "    \"\"\"SE通道注意力\"\"\"\n",
    "    channels = x.shape[-1]\n",
    "    squeeze = layers.GlobalAveragePooling2D()(x)\n",
    "    excite = layers.Dense(max(channels // ratio, 4), activation=\"relu\")(squeeze)\n",
    "    excite = layers.Dense(channels, activation=\"sigmoid\")(excite)\n",
    "    excite = layers.Reshape((1, 1, channels))(excite)\n",
    "    return layers.Multiply()([x, excite])\n",
    "\n",
    "\n",
    "def attentive_pooling(x):\n",
    "    \"\"\"注意力池化\"\"\"\n",
    "    attention = layers.Dense(1, activation=\"tanh\")(x)\n",
    "    attention = layers.Softmax(axis=1)(attention)\n",
    "    pooled = tf.reduce_sum(x * attention, axis=1)\n",
    "    return pooled\n",
    "\n",
    "\n",
    "def multi_scale_conv_block(x):\n",
    "    \"\"\"多尺度卷积块\"\"\"\n",
    "    # L2 正则保持 5e-5 (V3)\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    conv5 = layers.Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    conv7 = layers.Conv2D(32, (7, 7), padding=\"same\", activation=\"relu\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    \n",
    "    concat = layers.Concatenate()([conv3, conv5, conv7])\n",
    "    concat = layers.BatchNormalization()(concat)\n",
    "    concat = se_block(concat, ratio=8)\n",
    "    concat = layers.MaxPool2D((2, 2))(concat)\n",
    "    \n",
    "    return concat\n",
    "\n",
    "\n",
    "def conformer_block(x, d_model=128, num_heads=4, conv_kernel=15, dropout=0.15):\n",
    "    \"\"\"Conformer Block\"\"\"\n",
    "    # Feed Forward Module 1\n",
    "    ff1 = layers.Dense(d_model * 4, activation=\"swish\")(x)\n",
    "    ff1 = layers.Dropout(dropout)(ff1)\n",
    "    ff1 = layers.Dense(d_model)(ff1)\n",
    "    ff1 = layers.Dropout(dropout)(ff1)\n",
    "    x = layers.LayerNormalization()(x + 0.5 * ff1)\n",
    "    \n",
    "    # Multi-Head Self-Attention\n",
    "    attn = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=d_model // num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.LayerNormalization()(x + attn)\n",
    "    \n",
    "    # Convolution Module\n",
    "    conv = layers.Conv1D(d_model * 2, kernel_size=1)(x)\n",
    "    conv = glu_activation(conv)\n",
    "    conv = layers.DepthwiseConv1D(\n",
    "        kernel_size=conv_kernel, \n",
    "        padding=\"same\",\n",
    "        depthwise_regularizer=tf.keras.regularizers.l2(5e-5)\n",
    "    )(conv)\n",
    "    conv = layers.BatchNormalization()(conv)\n",
    "    conv = layers.Activation(\"swish\")(conv)\n",
    "    conv = layers.Conv1D(d_model, kernel_size=1)(conv)\n",
    "    conv = layers.Dropout(dropout)(conv)\n",
    "    x = layers.LayerNormalization()(x + conv)\n",
    "    \n",
    "    # Feed Forward Module 2\n",
    "    ff2 = layers.Dense(d_model * 4, activation=\"swish\")(x)\n",
    "    ff2 = layers.Dropout(dropout)(ff2)\n",
    "    ff2 = layers.Dense(d_model)(ff2)\n",
    "    ff2 = layers.Dropout(dropout)(ff2)\n",
    "    x = layers.LayerNormalization()(x + 0.5 * ff2)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 10) 构建 Conformer V3.1 模型\n",
    "# =====================\n",
    "def build_conformer_v3_1(input_shape, n_classes=6, d_model=128):\n",
    "    \"\"\"\n",
    "    Conformer V3.1 - 微调冲刺版\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # V3.1 修改：噪声降低 0.03 -> 0.02\n",
    "    x = layers.GaussianNoise(0.02)(inp)\n",
    "    x = SpecAugment(time_mask_num=2, freq_mask_num=2, \n",
    "                    time_mask_max=16, freq_mask_max=6)(x)\n",
    "    \n",
    "    # 多尺度卷积前端\n",
    "    x = multi_scale_conv_block(x)\n",
    "    \n",
    "    # 卷积层 1 - V3.1 修改：Dropout 0.25 -> 0.2\n",
    "    x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\",\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x, ratio=8)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    # 卷积层 2 - V3.1 修改：Dropout 0.25 -> 0.2\n",
    "    x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\",\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x, ratio=8)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "    x = layers.SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    # Reshape for Conformer\n",
    "    T_prime = x.shape[1]\n",
    "    x = layers.Reshape((T_prime, -1))(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.Dropout(0.15)(x)\n",
    "    \n",
    "    # Conformer Blocks\n",
    "    x = conformer_block(x, d_model=d_model, num_heads=4, conv_kernel=15, dropout=0.15)\n",
    "    x = conformer_block(x, d_model=d_model, num_heads=4, conv_kernel=15, dropout=0.15)\n",
    "    \n",
    "    # 注意力池化\n",
    "    x = attentive_pooling(x)\n",
    "    \n",
    "    # 分类头 - V3.1 修改：Dropout 0.4 -> 0.3 / 0.3 -> 0.2\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", \n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(n_classes, activation=\"softmax\", name=\"emotion\")(x)\n",
    "    \n",
    "    model = models.Model(inp, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 11) Mixup 数据生成器\n",
    "# =====================\n",
    "class MixupGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"带Mixup的数据生成器\"\"\"\n",
    "    def __init__(self, x, y, batch_size=64, alpha=0.2, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(x))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[batch_indexes].copy()\n",
    "        batch_y = self.y[batch_indexes].copy()\n",
    "        \n",
    "        # 50%概率应用Mixup\n",
    "        if np.random.random() < 0.5 and self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            shuffle_idx = np.random.permutation(len(batch_x))\n",
    "            batch_x = lam * batch_x + (1 - lam) * batch_x[shuffle_idx]\n",
    "            batch_y = lam * batch_y + (1 - lam) * batch_y[shuffle_idx]\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 12) 自定义回调\n",
    "# =====================\n",
    "class MacroF1Callback(callbacks.Callback):\n",
    "    \"\"\"计算并记录 Macro F1\"\"\"\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0\n",
    "        self.f1_history = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(self.X_val, verbose=0), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_pred, average=\"macro\")\n",
    "        self.f1_history.append(f1)\n",
    "        logs = logs or {}\n",
    "        logs[\"val_macro_f1\"] = f1\n",
    "        \n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            print(f\" — val_macro_f1: {f1:.4f} ★ New Best!\")\n",
    "        else:\n",
    "            print(f\" — val_macro_f1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 13) 训练函数\n",
    "# =====================\n",
    "def train_conformer_v3_1(Xtr, ytr, Xte, yte, le_emo, \n",
    "                         epochs=100, batch_size=64, \n",
    "                         exp_dir=EXP_DIR, model_dir=MODEL_DIR, log_dir=LOG_DIR):\n",
    "    \"\"\"V3.1 完整训练流程\"\"\"\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    n_classes = len(le_emo.classes_)\n",
    "    model = build_conformer_v3_1(input_shape=Xtr.shape[1:], n_classes=n_classes)\n",
    "    \n",
    "    # 保存模型结构\n",
    "    model.summary()\n",
    "    with open(os.path.join(log_dir, \"model_summary.txt\"), \"w\") as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
    "    \n",
    "    # One-hot编码\n",
    "    ytr_onehot = tf.keras.utils.to_categorical(ytr, n_classes)\n",
    "    yte_onehot = tf.keras.utils.to_categorical(yte, n_classes)\n",
    "    \n",
    "    # 编译\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(\n",
    "            learning_rate=8e-4,\n",
    "            weight_decay=2e-4\n",
    "        ),\n",
    "        # V3.1 修改：Smoothing 0.1 -> 0.05\n",
    "        loss=LabelSmoothingFocalLoss(smoothing=0.05, gamma=2.0),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # 学习率调度\n",
    "    def lr_schedule(epoch):\n",
    "        warmup_epochs = 5\n",
    "        initial_lr = 8e-4\n",
    "        \n",
    "        if epoch < warmup_epochs:\n",
    "            return initial_lr * (epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - warmup_epochs) / (epochs - warmup_epochs)\n",
    "            return initial_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    # Mixup数据生成器\n",
    "    train_gen = MixupGenerator(Xtr, ytr_onehot, batch_size=batch_size, alpha=0.2)\n",
    "    \n",
    "    # F1回调\n",
    "    f1_callback = MacroF1Callback(Xte, yte)\n",
    "    \n",
    "    # 回调列表\n",
    "    callbacks_list = [\n",
    "        f1_callback,\n",
    "        callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_dir, \"best_model.h5\"),\n",
    "            monitor=\"val_macro_f1\",\n",
    "            mode=\"max\",\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_dir, \"last_model.h5\"),\n",
    "            save_best_only=False,\n",
    "            verbose=0\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor=\"val_macro_f1\",\n",
    "            mode=\"max\",\n",
    "            patience=25,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.LearningRateScheduler(lr_schedule, verbose=0),\n",
    "        callbacks.CSVLogger(os.path.join(log_dir, \"training_log.csv\"))\n",
    "    ]\n",
    "    \n",
    "    # 保存训练配置\n",
    "    config = {\n",
    "        \"model\": \"Conformer V3.1\",\n",
    "        \"description\": \"Lower smoothing/noise/dropout compared to V3\",\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"initial_lr\": 8e-4,\n",
    "        \"weight_decay\": 2e-4,\n",
    "        \"mixup_alpha\": 0.2,\n",
    "        \"label_smoothing\": 0.05,\n",
    "        \"focal_gamma\": 2.0,\n",
    "        \"dropout_rates\": \"0.15/0.2/0.3/0.2\",\n",
    "        \"l2_reg\": 5e-5,\n",
    "        \"n_classes\": n_classes\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(log_dir, \"config.txt\"), \"w\") as f:\n",
    "        for k, v in config.items():\n",
    "            f.write(f\"{k}: {v}\\n\")\n",
    "    \n",
    "    # 训练\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Starting Conformer V3.1 training...\")\n",
    "    print(f\"Output directory: {exp_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=(Xte, yte_onehot),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 保存F1历史\n",
    "    history.history['val_macro_f1'] = f1_callback.f1_history\n",
    "    \n",
    "    return model, history, f1_callback.best_f1\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 14) 评估函数\n",
    "# =====================\n",
    "def evaluate_model(model, Xte, yte, le_emo, plot_dir=PLOT_DIR, log_dir=LOG_DIR):\n",
    "    \"\"\"完整模型评估\"\"\"\n",
    "    \n",
    "    # 预测\n",
    "    y_pred_proba = model.predict(Xte, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    # 计算指标\n",
    "    macro_f1 = f1_score(yte, y_pred, average=\"macro\")\n",
    "    weighted_f1 = f1_score(yte, y_pred, average=\"weighted\")\n",
    "    accuracy = np.mean(y_pred == yte)\n",
    "    class_f1 = f1_score(yte, y_pred, average=None)\n",
    "    \n",
    "    # 分类报告\n",
    "    report = classification_report(yte, y_pred, target_names=le_emo.classes_, digits=4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Classification Report - Conformer V3.1\")\n",
    "    print(\"=\" * 60)\n",
    "    print(report)\n",
    "    \n",
    "    # 保存报告\n",
    "    with open(os.path.join(log_dir, \"classification_report.txt\"), \"w\") as f:\n",
    "        f.write(\"Classification Report - Conformer V3.1\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        f.write(report)\n",
    "        f.write(f\"\\nSummary:\\n\")\n",
    "        f.write(f\"  Accuracy:    {accuracy:.4f}\\n\")\n",
    "        f.write(f\"  Macro F1:    {macro_f1:.4f}\\n\")\n",
    "        f.write(f\"  Weighted F1: {weighted_f1:.4f}\\n\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"  Macro F1:    {macro_f1:.4f}\")\n",
    "    print(f\"  Weighted F1: {weighted_f1:.4f}\")\n",
    "    \n",
    "    # ========== 绘图 ==========\n",
    "    \n",
    "    # 1. 混淆矩阵\n",
    "    cm = confusion_matrix(yte, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "        xticklabels=le_emo.classes_, yticklabels=le_emo.classes_,\n",
    "        annot_kws={\"size\": 12}\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix — Conformer V3.1\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted\", fontsize=14)\n",
    "    plt.ylabel(\"True\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"confusion_matrix.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. 归一化混淆矩阵\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm_norm, annot=True, fmt=\".2%\", cmap=\"Blues\",\n",
    "        xticklabels=le_emo.classes_, yticklabels=le_emo.classes_,\n",
    "        annot_kws={\"size\": 11}\n",
    "    )\n",
    "    plt.title(\"Normalized Confusion Matrix — Conformer V3.1\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted\", fontsize=14)\n",
    "    plt.ylabel(\"True\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"confusion_matrix_normalized.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. 各类别F1柱状图\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(le_emo.classes_, class_f1, color=colors[:len(le_emo.classes_)])\n",
    "    plt.axhline(y=macro_f1, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Macro F1 = {macro_f1:.4f}')\n",
    "    plt.xlabel('Emotion Class', fontsize=14)\n",
    "    plt.ylabel('F1 Score', fontsize=14)\n",
    "    plt.title('Per-Class F1 Score — Conformer V3.1', fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.ylim(0, 1)\n",
    "    for bar, f1 in zip(bars, class_f1):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'{f1:.3f}', ha='center', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"class_f1_scores.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"class_f1\": dict(zip(le_emo.classes_, class_f1))\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 15) 绘制训练曲线\n",
    "# =====================\n",
    "def plot_training_history(history, plot_dir=PLOT_DIR):\n",
    "    \"\"\"绘制并保存训练曲线\"\"\"\n",
    "    \n",
    "    # 综合图（子图）\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss', fontsize=12)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Val', linewidth=2)\n",
    "    axes[0, 1].set_title('Accuracy', fontsize=12)\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Macro F1\n",
    "    if 'val_macro_f1' in history.history:\n",
    "        axes[1, 0].plot(history.history['val_macro_f1'], label='Val Macro F1', \n",
    "                        linewidth=2, color='green')\n",
    "        axes[1, 0].set_title('Validation Macro F1', fontsize=12)\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 1].plot(history.history['lr'], linewidth=2, color='purple')\n",
    "        axes[1, 1].set_title('Learning Rate', fontsize=12)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Training Overview — Conformer V3.1', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"training_overview.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: training_overview.png\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 16) 模型对比函数\n",
    "# =====================\n",
    "def compare_with_previous(current_results, plot_dir=PLOT_DIR):\n",
    "    \"\"\"与之前模型对比\"\"\"\n",
    "    \n",
    "    previous_results = {\n",
    "        \"CNN\": {\"macro_f1\": 0.4848},\n",
    "        \"Conformer_V1\": {\"macro_f1\": 0.6738},\n",
    "        \"Conformer_V3\": {\"macro_f1\": 0.6505},\n",
    "        \"Conformer_V3.1\": {\"macro_f1\": current_results[\"macro_f1\"]}\n",
    "    }\n",
    "    \n",
    "    models = list(previous_results.keys())\n",
    "    macro_f1s = [previous_results[m][\"macro_f1\"] for m in models]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(models, macro_f1s, color='#3498db', width=0.5)\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=14)\n",
    "    plt.ylabel('Macro F1 Score', fontsize=14)\n",
    "    plt.title('Model Comparison', fontsize=16)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height, f'{height:.4f}', \n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"model_comparison.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Saved: model_comparison.png\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 17) 主程序\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Speech Emotion Recognition - Conformer V3.1 (Fine-tuned)\")\n",
    "    print(\"Dataset: CREMA-D\")\n",
    "    print(f\"Experiment Directory: {EXP_DIR}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 训练模型\n",
    "    model, history, best_f1 = train_conformer_v3_1(\n",
    "        Xtr, ytr, Xte, yte, le_emo,\n",
    "        epochs=100,\n",
    "        batch_size=64\n",
    "    )\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    print(\"\\nPlotting training curves...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # 评估模型\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    results = evaluate_model(model, Xte, yte, le_emo)\n",
    "    \n",
    "    # 与之前模型对比\n",
    "    print(\"\\nComparing with previous models...\")\n",
    "    compare_with_previous(results)\n",
    "    \n",
    "    # 保存最终结果\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Final Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy:    {results['accuracy']:.4f}\")\n",
    "    print(f\"Macro F1:    {results['macro_f1']:.4f}\")\n",
    "    print(f\"Weighted F1: {results['weighted_f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"✓ All results saved to: {EXP_DIR}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a25fb-9096-441b-8939-3444951895ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
