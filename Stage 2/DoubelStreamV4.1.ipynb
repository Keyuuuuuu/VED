{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb78e637-fe5f-412a-badc-67cd23bb79b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: Mel (5890, 300, 64, 1), eGe (5890, 88)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 300, 64, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (Gaussian  (None, 300, 64, 1)           0         ['input_2[0][0]']             \n",
      " Noise)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 300, 64, 32)          320       ['gaussian_noise_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 300, 64, 32)          128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 150, 32, 32)          0         ['batch_normalization_1[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 150, 32, 64)          18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 150, 32, 64)          256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 75, 16, 64)           0         ['batch_normalization_2[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 75, 16, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 75, 16, 128)          512       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 37, 8, 128)           0         ['batch_normalization_3[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 296, 128)             0         ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 296, 128)             16512     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 296, 128)             0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 296, 512)             66048     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 296, 512)             0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 296, 128)             65664     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 296, 128)             0         ['dense_2[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 296, 128)             0         ['dropout[0][0]',             \n",
      " Lambda)                                                             'tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 296, 128)             256       ['tf.__operators__.add[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 296, 128)             66048     ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 296, 128)             0         ['layer_normalization[0][0]', \n",
      " OpLambda)                                                           'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_1[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 296, 256)             33024     ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 296, 128)             0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv1d (Depthwis  (None, 296, 128)             2048      ['lambda[0][0]']              \n",
      " eConv1D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 296, 128)             512       ['depthwise_conv1d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 296, 128)             0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 296, 128)             16512     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 296, 128)             0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 296, 128)             0         ['layer_normalization_1[0][0]'\n",
      " OpLambda)                                                          , 'dropout_2[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 296, 512)             66048     ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 296, 512)             0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 296, 128)             65664     ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 296, 128)             0         ['dense_4[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 296, 128)             0         ['layer_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 296, 512)             66048     ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 296, 512)             0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 296, 128)             65664     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 296, 128)             0         ['dense_6[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 296, 128)             0         ['layer_normalization_3[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_4[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 296, 128)             66048     ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 296, 128)             0         ['layer_normalization_4[0][0]'\n",
      " OpLambda)                                                          , 'multi_head_attention_1[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_5[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 296, 256)             33024     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 296, 128)             0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " depthwise_conv1d_1 (Depthw  (None, 296, 128)             2048      ['lambda_1[0][0]']            \n",
      " iseConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 296, 128)             512       ['depthwise_conv1d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 296, 128)             0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 296, 128)             16512     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 296, 128)             0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 296, 128)             0         ['layer_normalization_5[0][0]'\n",
      " OpLambda)                                                          , 'dropout_5[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_6[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 296, 512)             66048     ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 296, 512)             0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 88)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 296, 128)             65664     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " gaussian_noise_2 (Gaussian  (None, 88)                   0         ['input_3[0][0]']             \n",
      " Noise)                                                                                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (None, 296, 128)             0         ['dense_8[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 128)                  11392     ['gaussian_noise_2[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 296, 128)             0         ['layer_normalization_6[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 128)                  512       ['dense_9[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 296, 128)             256       ['tf.__operators__.add_7[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 128)                  0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " cross_attention_fusion (Cr  (None, 296, 128)             66304     ['layer_normalization_7[0][0]'\n",
      " ossAttentionFusion)                                                , 'dropout_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 296, 1)               129       ['cross_attention_fusion[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " softmax (Softmax)           (None, 296, 1)               0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (None, 296, 128)             0         ['cross_attention_fusion[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'softmax[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLa  (None, 128)                  0         ['tf.math.multiply_4[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 256)                  0         ['tf.math.reduce_sum[0][0]',  \n",
      "                                                                     'dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 64)                   16448     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 64)                   0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " emotion (Dense)             (None, 6)                    390       ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 970439 (3.70 MB)\n",
      "Trainable params: 969223 (3.70 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Starting Cross-Attention Fusion Training...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 05:55:49.559838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-12-04 05:55:50.046207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa87730eee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-04 05:55:50.046250: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-12-04 05:55:50.054164: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-04 05:55:50.225215: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - ETA: 0s - loss: 1.2825 - accuracy: 0.2976 — val_f1: 0.0503\n",
      "\n",
      "Epoch 1: val_macro_f1 improved from -inf to 0.05033, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 32s 120ms/step - loss: 1.2825 - accuracy: 0.2976 - val_loss: 3.6201 - val_accuracy: 0.1714 - val_macro_f1: 0.0503 - lr: 1.6000e-04\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0816 - accuracy: 0.3642 — val_f1: 0.0840\n",
      "\n",
      "Epoch 2: val_macro_f1 improved from 0.05033 to 0.08398, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 87ms/step - loss: 1.0816 - accuracy: 0.3642 - val_loss: 3.2738 - val_accuracy: 0.1869 - val_macro_f1: 0.0840 - lr: 3.2000e-04\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.0133 - accuracy: 0.4008 — val_f1: 0.2987\n",
      "\n",
      "Epoch 3: val_macro_f1 improved from 0.08398 to 0.29871, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 88ms/step - loss: 1.0133 - accuracy: 0.4008 - val_loss: 1.3373 - val_accuracy: 0.3338 - val_macro_f1: 0.2987 - lr: 4.8000e-04\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9581 - accuracy: 0.4272 — val_f1: 0.3588\n",
      "\n",
      "Epoch 4: val_macro_f1 improved from 0.29871 to 0.35885, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 87ms/step - loss: 0.9581 - accuracy: 0.4272 - val_loss: 1.0192 - val_accuracy: 0.3756 - val_macro_f1: 0.3588 - lr: 6.4000e-04\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.4421 — val_f1: 0.4644\n",
      "\n",
      "Epoch 5: val_macro_f1 improved from 0.35885 to 0.46438, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 88ms/step - loss: 0.9568 - accuracy: 0.4421 - val_loss: 0.8968 - val_accuracy: 0.4755 - val_macro_f1: 0.4644 - lr: 8.0000e-04\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8966 - accuracy: 0.4739 — val_f1: 0.4510\n",
      "\n",
      "Epoch 6: val_macro_f1 did not improve from 0.46438\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.8966 - accuracy: 0.4739 - val_loss: 0.8976 - val_accuracy: 0.4594 - val_macro_f1: 0.4510 - lr: 8.0000e-04\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.4742 — val_f1: 0.4734\n",
      "\n",
      "Epoch 7: val_macro_f1 improved from 0.46438 to 0.47339, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 86ms/step - loss: 0.8912 - accuracy: 0.4742 - val_loss: 0.8731 - val_accuracy: 0.4762 - val_macro_f1: 0.4734 - lr: 7.9978e-04\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8625 - accuracy: 0.4927 — val_f1: 0.4934\n",
      "\n",
      "Epoch 8: val_macro_f1 improved from 0.47339 to 0.49335, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 86ms/step - loss: 0.8625 - accuracy: 0.4927 - val_loss: 0.8489 - val_accuracy: 0.5032 - val_macro_f1: 0.4934 - lr: 7.9913e-04\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8330 - accuracy: 0.5063 — val_f1: 0.4608\n",
      "\n",
      "Epoch 9: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.8330 - accuracy: 0.5063 - val_loss: 0.8583 - val_accuracy: 0.4697 - val_macro_f1: 0.4608 - lr: 7.9803e-04\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8119 - accuracy: 0.5234 — val_f1: 0.4509\n",
      "\n",
      "Epoch 10: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.8119 - accuracy: 0.5234 - val_loss: 0.8575 - val_accuracy: 0.4794 - val_macro_f1: 0.4509 - lr: 7.9651e-04\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.5265 — val_f1: 0.4092\n",
      "\n",
      "Epoch 11: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.8234 - accuracy: 0.5265 - val_loss: 0.9328 - val_accuracy: 0.4401 - val_macro_f1: 0.4092 - lr: 7.9454e-04\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8061 - accuracy: 0.5255 — val_f1: 0.3327\n",
      "\n",
      "Epoch 12: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.8061 - accuracy: 0.5255 - val_loss: 1.0863 - val_accuracy: 0.3905 - val_macro_f1: 0.3327 - lr: 7.9215e-04\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8007 - accuracy: 0.5455 — val_f1: 0.4803\n",
      "\n",
      "Epoch 13: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.8007 - accuracy: 0.5455 - val_loss: 0.8480 - val_accuracy: 0.5026 - val_macro_f1: 0.4803 - lr: 7.8933e-04\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.5626 — val_f1: 0.4487\n",
      "\n",
      "Epoch 14: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.7702 - accuracy: 0.5626 - val_loss: 0.9084 - val_accuracy: 0.4826 - val_macro_f1: 0.4487 - lr: 7.8608e-04\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.5506 — val_f1: 0.4660\n",
      "\n",
      "Epoch 15: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.7872 - accuracy: 0.5506 - val_loss: 0.8805 - val_accuracy: 0.4936 - val_macro_f1: 0.4660 - lr: 7.8241e-04\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7751 - accuracy: 0.5643 — val_f1: 0.4807\n",
      "\n",
      "Epoch 16: val_macro_f1 did not improve from 0.49335\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.7751 - accuracy: 0.5643 - val_loss: 0.8121 - val_accuracy: 0.4981 - val_macro_f1: 0.4807 - lr: 7.7833e-04\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.5808 — val_f1: 0.5190\n",
      "\n",
      "Epoch 17: val_macro_f1 improved from 0.49335 to 0.51895, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 87ms/step - loss: 0.7475 - accuracy: 0.5808 - val_loss: 0.7964 - val_accuracy: 0.5329 - val_macro_f1: 0.5190 - lr: 7.7383e-04\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7490 - accuracy: 0.5718 — val_f1: 0.5033\n",
      "\n",
      "Epoch 18: val_macro_f1 did not improve from 0.51895\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.7490 - accuracy: 0.5718 - val_loss: 0.8261 - val_accuracy: 0.5155 - val_macro_f1: 0.5033 - lr: 7.6892e-04\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7330 - accuracy: 0.5981 — val_f1: 0.5237\n",
      "\n",
      "Epoch 19: val_macro_f1 improved from 0.51895 to 0.52368, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 87ms/step - loss: 0.7330 - accuracy: 0.5981 - val_loss: 0.7928 - val_accuracy: 0.5290 - val_macro_f1: 0.5237 - lr: 7.6360e-04\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.6048 — val_f1: 0.4399\n",
      "\n",
      "Epoch 20: val_macro_f1 did not improve from 0.52368\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6965 - accuracy: 0.6048 - val_loss: 0.8953 - val_accuracy: 0.4588 - val_macro_f1: 0.4399 - lr: 7.5789e-04\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.5886 — val_f1: 0.3704\n",
      "\n",
      "Epoch 21: val_macro_f1 did not improve from 0.52368\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.7276 - accuracy: 0.5886 - val_loss: 0.9730 - val_accuracy: 0.4085 - val_macro_f1: 0.3704 - lr: 7.5179e-04\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7017 - accuracy: 0.6110 — val_f1: 0.5520\n",
      "\n",
      "Epoch 22: val_macro_f1 improved from 0.52368 to 0.55202, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 87ms/step - loss: 0.7017 - accuracy: 0.6110 - val_loss: 0.7891 - val_accuracy: 0.5599 - val_macro_f1: 0.5520 - lr: 7.4530e-04\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.6214 — val_f1: 0.4052\n",
      "\n",
      "Epoch 23: val_macro_f1 did not improve from 0.55202\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6836 - accuracy: 0.6214 - val_loss: 0.9769 - val_accuracy: 0.4459 - val_macro_f1: 0.4052 - lr: 7.3844e-04\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.6440 — val_f1: 0.3448\n",
      "\n",
      "Epoch 24: val_macro_f1 did not improve from 0.55202\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6341 - accuracy: 0.6440 - val_loss: 1.0511 - val_accuracy: 0.3950 - val_macro_f1: 0.3448 - lr: 7.3120e-04\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.5917 — val_f1: 0.4631\n",
      "\n",
      "Epoch 25: val_macro_f1 did not improve from 0.55202\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.7229 - accuracy: 0.5917 - val_loss: 0.8920 - val_accuracy: 0.4729 - val_macro_f1: 0.4631 - lr: 7.2361e-04\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.6241 — val_f1: 0.5833\n",
      "\n",
      "Epoch 26: val_macro_f1 improved from 0.55202 to 0.58325, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 88ms/step - loss: 0.6804 - accuracy: 0.6241 - val_loss: 0.7473 - val_accuracy: 0.5863 - val_macro_f1: 0.5833 - lr: 7.1566e-04\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.6301 — val_f1: 0.4152\n",
      "\n",
      "Epoch 27: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.6745 - accuracy: 0.6301 - val_loss: 0.9826 - val_accuracy: 0.4646 - val_macro_f1: 0.4152 - lr: 7.0736e-04\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.6540 — val_f1: 0.5308\n",
      "\n",
      "Epoch 28: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6302 - accuracy: 0.6540 - val_loss: 0.8147 - val_accuracy: 0.5335 - val_macro_f1: 0.5308 - lr: 6.9873e-04\n",
      "Epoch 29/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6339 - accuracy: 0.6622 — val_f1: 0.3540\n",
      "\n",
      "Epoch 29: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6341 - accuracy: 0.6621 - val_loss: 1.1391 - val_accuracy: 0.4001 - val_macro_f1: 0.3540 - lr: 6.8977e-04\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.6548 — val_f1: 0.3765\n",
      "\n",
      "Epoch 30: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.6371 - accuracy: 0.6548 - val_loss: 1.1167 - val_accuracy: 0.3892 - val_macro_f1: 0.3765 - lr: 6.8049e-04\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.6496 — val_f1: 0.4058\n",
      "\n",
      "Epoch 31: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 0.6402 - accuracy: 0.6496 - val_loss: 0.9948 - val_accuracy: 0.4549 - val_macro_f1: 0.4058 - lr: 6.7091e-04\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.6701 — val_f1: 0.5541\n",
      "\n",
      "Epoch 32: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6013 - accuracy: 0.6701 - val_loss: 0.7816 - val_accuracy: 0.5689 - val_macro_f1: 0.5541 - lr: 6.6103e-04\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.6944 — val_f1: 0.2671\n",
      "\n",
      "Epoch 33: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.5809 - accuracy: 0.6944 - val_loss: 1.4453 - val_accuracy: 0.3473 - val_macro_f1: 0.2671 - lr: 6.5087e-04\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.6808 — val_f1: 0.4853\n",
      "\n",
      "Epoch 34: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5991 - accuracy: 0.6808 - val_loss: 0.8154 - val_accuracy: 0.5071 - val_macro_f1: 0.4853 - lr: 6.4043e-04\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.6727 — val_f1: 0.5613\n",
      "\n",
      "Epoch 35: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.6227 - accuracy: 0.6727 - val_loss: 0.8136 - val_accuracy: 0.5580 - val_macro_f1: 0.5613 - lr: 6.2973e-04\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5775 - accuracy: 0.7048 — val_f1: 0.5128\n",
      "\n",
      "Epoch 36: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.5775 - accuracy: 0.7048 - val_loss: 0.8444 - val_accuracy: 0.5226 - val_macro_f1: 0.5128 - lr: 6.1878e-04\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.7250 — val_f1: 0.5412\n",
      "\n",
      "Epoch 37: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5333 - accuracy: 0.7250 - val_loss: 0.8224 - val_accuracy: 0.5457 - val_macro_f1: 0.5412 - lr: 6.0759e-04\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.7107 — val_f1: 0.5167\n",
      "\n",
      "Epoch 38: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5631 - accuracy: 0.7107 - val_loss: 0.8446 - val_accuracy: 0.5380 - val_macro_f1: 0.5167 - lr: 5.9617e-04\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.7126 — val_f1: 0.4856\n",
      "\n",
      "Epoch 39: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5646 - accuracy: 0.7126 - val_loss: 1.0094 - val_accuracy: 0.4936 - val_macro_f1: 0.4856 - lr: 5.8454e-04\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.7275 — val_f1: 0.4343\n",
      "\n",
      "Epoch 40: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5415 - accuracy: 0.7275 - val_loss: 1.0453 - val_accuracy: 0.4427 - val_macro_f1: 0.4343 - lr: 5.7270e-04\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.6964 — val_f1: 0.4571\n",
      "\n",
      "Epoch 41: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.5755 - accuracy: 0.6964 - val_loss: 1.0017 - val_accuracy: 0.4884 - val_macro_f1: 0.4571 - lr: 5.6068e-04\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.7428 — val_f1: 0.5429\n",
      "\n",
      "Epoch 42: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5138 - accuracy: 0.7428 - val_loss: 0.7998 - val_accuracy: 0.5419 - val_macro_f1: 0.5429 - lr: 5.4848e-04\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.7540 — val_f1: 0.5494\n",
      "\n",
      "Epoch 43: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.4888 - accuracy: 0.7540 - val_loss: 0.8300 - val_accuracy: 0.5464 - val_macro_f1: 0.5494 - lr: 5.3612e-04\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.7472 — val_f1: 0.5699\n",
      "\n",
      "Epoch 44: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5283 - accuracy: 0.7472 - val_loss: 0.7627 - val_accuracy: 0.5728 - val_macro_f1: 0.5699 - lr: 5.2361e-04\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.7735 — val_f1: 0.5443\n",
      "\n",
      "Epoch 45: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4878 - accuracy: 0.7735 - val_loss: 0.8382 - val_accuracy: 0.5619 - val_macro_f1: 0.5443 - lr: 5.1096e-04\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.8090 — val_f1: 0.4582\n",
      "\n",
      "Epoch 46: val_macro_f1 did not improve from 0.58325\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4220 - accuracy: 0.8090 - val_loss: 0.9415 - val_accuracy: 0.4903 - val_macro_f1: 0.4582 - lr: 4.9819e-04\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.7710 — val_f1: 0.5891\n",
      "\n",
      "Epoch 47: val_macro_f1 improved from 0.58325 to 0.58914, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 86ms/step - loss: 0.4834 - accuracy: 0.7710 - val_loss: 0.7785 - val_accuracy: 0.5954 - val_macro_f1: 0.5891 - lr: 4.8532e-04\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.7813 — val_f1: 0.5518\n",
      "\n",
      "Epoch 48: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4615 - accuracy: 0.7813 - val_loss: 0.8568 - val_accuracy: 0.5522 - val_macro_f1: 0.5518 - lr: 4.7235e-04\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.7645 — val_f1: 0.5461\n",
      "\n",
      "Epoch 49: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.5016 - accuracy: 0.7645 - val_loss: 0.8472 - val_accuracy: 0.5535 - val_macro_f1: 0.5461 - lr: 4.5931e-04\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.7740 — val_f1: 0.5840\n",
      "\n",
      "Epoch 50: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4747 - accuracy: 0.7740 - val_loss: 0.7448 - val_accuracy: 0.5876 - val_macro_f1: 0.5840 - lr: 4.4619e-04\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4392 - accuracy: 0.8121 — val_f1: 0.5580\n",
      "\n",
      "Epoch 51: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.4392 - accuracy: 0.8121 - val_loss: 0.8706 - val_accuracy: 0.5528 - val_macro_f1: 0.5580 - lr: 4.3303e-04\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8071 — val_f1: 0.5629\n",
      "\n",
      "Epoch 52: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4636 - accuracy: 0.8071 - val_loss: 0.8165 - val_accuracy: 0.5773 - val_macro_f1: 0.5629 - lr: 4.1983e-04\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8278 — val_f1: 0.4669\n",
      "\n",
      "Epoch 53: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.4324 - accuracy: 0.8278 - val_loss: 1.0151 - val_accuracy: 0.4871 - val_macro_f1: 0.4669 - lr: 4.0661e-04\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8513 — val_f1: 0.4513\n",
      "\n",
      "Epoch 54: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.3720 - accuracy: 0.8513 - val_loss: 1.0061 - val_accuracy: 0.4736 - val_macro_f1: 0.4513 - lr: 3.9339e-04\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8404 — val_f1: 0.5631\n",
      "\n",
      "Epoch 55: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4156 - accuracy: 0.8404 - val_loss: 0.8836 - val_accuracy: 0.5631 - val_macro_f1: 0.5631 - lr: 3.8017e-04\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.8205 — val_f1: 0.5728\n",
      "\n",
      "Epoch 56: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4329 - accuracy: 0.8205 - val_loss: 0.8102 - val_accuracy: 0.5831 - val_macro_f1: 0.5728 - lr: 3.6697e-04\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.8428 — val_f1: 0.4838\n",
      "\n",
      "Epoch 57: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.4242 - accuracy: 0.8428 - val_loss: 0.9969 - val_accuracy: 0.4974 - val_macro_f1: 0.4838 - lr: 3.5381e-04\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.8426 — val_f1: 0.5584\n",
      "\n",
      "Epoch 58: val_macro_f1 did not improve from 0.58914\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.4469 - accuracy: 0.8426 - val_loss: 0.8780 - val_accuracy: 0.5573 - val_macro_f1: 0.5584 - lr: 3.4069e-04\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8679 — val_f1: 0.6085\n",
      "\n",
      "Epoch 59: val_macro_f1 improved from 0.58914 to 0.60849, saving model to Output/twostream_v4_1_crossattn_20251204_055535/models/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 87ms/step - loss: 0.3790 - accuracy: 0.8679 - val_loss: 0.7695 - val_accuracy: 0.6076 - val_macro_f1: 0.6085 - lr: 3.2765e-04\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8613 — val_f1: 0.5808\n",
      "\n",
      "Epoch 60: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3983 - accuracy: 0.8613 - val_loss: 0.8173 - val_accuracy: 0.5902 - val_macro_f1: 0.5808 - lr: 3.1468e-04\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.8771 — val_f1: 0.5594\n",
      "\n",
      "Epoch 61: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3771 - accuracy: 0.8771 - val_loss: 0.8489 - val_accuracy: 0.5567 - val_macro_f1: 0.5594 - lr: 3.0181e-04\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.9139 — val_f1: 0.5679\n",
      "\n",
      "Epoch 62: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.2965 - accuracy: 0.9139 - val_loss: 0.8803 - val_accuracy: 0.5657 - val_macro_f1: 0.5679 - lr: 2.8904e-04\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8862 — val_f1: 0.5560\n",
      "\n",
      "Epoch 63: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 0.3536 - accuracy: 0.8862 - val_loss: 0.9023 - val_accuracy: 0.5509 - val_macro_f1: 0.5560 - lr: 2.7639e-04\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.8839 — val_f1: 0.5533\n",
      "\n",
      "Epoch 64: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.3613 - accuracy: 0.8839 - val_loss: 0.8445 - val_accuracy: 0.5606 - val_macro_f1: 0.5533 - lr: 2.6388e-04\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.9010 — val_f1: 0.4933\n",
      "\n",
      "Epoch 65: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.3383 - accuracy: 0.9010 - val_loss: 1.0177 - val_accuracy: 0.5103 - val_macro_f1: 0.4933 - lr: 2.5152e-04\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.8913 — val_f1: 0.5309\n",
      "\n",
      "Epoch 66: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3449 - accuracy: 0.8913 - val_loss: 0.9257 - val_accuracy: 0.5451 - val_macro_f1: 0.5309 - lr: 2.3932e-04\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.9034 — val_f1: 0.5606\n",
      "\n",
      "Epoch 67: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3507 - accuracy: 0.9034 - val_loss: 0.8810 - val_accuracy: 0.5561 - val_macro_f1: 0.5606 - lr: 2.2730e-04\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.9102 — val_f1: 0.5798\n",
      "\n",
      "Epoch 68: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3310 - accuracy: 0.9102 - val_loss: 0.8703 - val_accuracy: 0.5799 - val_macro_f1: 0.5798 - lr: 2.1546e-04\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.9170 — val_f1: 0.5733\n",
      "\n",
      "Epoch 69: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3160 - accuracy: 0.9170 - val_loss: 0.8689 - val_accuracy: 0.5754 - val_macro_f1: 0.5733 - lr: 2.0383e-04\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.9024 — val_f1: 0.5599\n",
      "\n",
      "Epoch 70: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 0.3628 - accuracy: 0.9024 - val_loss: 0.8520 - val_accuracy: 0.5625 - val_macro_f1: 0.5599 - lr: 1.9241e-04\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9239 — val_f1: 0.5833\n",
      "\n",
      "Epoch 71: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.3273 - accuracy: 0.9239 - val_loss: 0.8448 - val_accuracy: 0.5805 - val_macro_f1: 0.5833 - lr: 1.8122e-04\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.9170 — val_f1: 0.5558\n",
      "\n",
      "Epoch 72: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3476 - accuracy: 0.9170 - val_loss: 0.8674 - val_accuracy: 0.5638 - val_macro_f1: 0.5558 - lr: 1.7027e-04\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.9294 — val_f1: 0.5012\n",
      "\n",
      "Epoch 73: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3132 - accuracy: 0.9294 - val_loss: 0.9958 - val_accuracy: 0.5129 - val_macro_f1: 0.5012 - lr: 1.5957e-04\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.9209 — val_f1: 0.5650\n",
      "\n",
      "Epoch 74: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3293 - accuracy: 0.9209 - val_loss: 0.8975 - val_accuracy: 0.5741 - val_macro_f1: 0.5650 - lr: 1.4913e-04\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.9387 — val_f1: 0.5001\n",
      "\n",
      "Epoch 75: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3047 - accuracy: 0.9387 - val_loss: 1.0368 - val_accuracy: 0.5000 - val_macro_f1: 0.5001 - lr: 1.3897e-04\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.9025 — val_f1: 0.5638\n",
      "\n",
      "Epoch 76: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.3574 - accuracy: 0.9025 - val_loss: 0.9074 - val_accuracy: 0.5644 - val_macro_f1: 0.5638 - lr: 1.2909e-04\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9377 — val_f1: 0.5887\n",
      "\n",
      "Epoch 77: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.3001 - accuracy: 0.9377 - val_loss: 0.8809 - val_accuracy: 0.5915 - val_macro_f1: 0.5887 - lr: 1.1951e-04\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.9521 — val_f1: 0.5682\n",
      "\n",
      "Epoch 78: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.2786 - accuracy: 0.9521 - val_loss: 0.9196 - val_accuracy: 0.5715 - val_macro_f1: 0.5682 - lr: 1.1023e-04\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9494 — val_f1: 0.5641\n",
      "\n",
      "Epoch 79: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.2818 - accuracy: 0.9494 - val_loss: 0.9213 - val_accuracy: 0.5735 - val_macro_f1: 0.5641 - lr: 1.0127e-04\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.9419 — val_f1: 0.5747\n",
      "\n",
      "Epoch 80: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.2859 - accuracy: 0.9419 - val_loss: 0.9011 - val_accuracy: 0.5786 - val_macro_f1: 0.5747 - lr: 9.2640e-05\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.9540 — val_f1: 0.5750\n",
      "\n",
      "Epoch 81: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.2772 - accuracy: 0.9540 - val_loss: 0.9006 - val_accuracy: 0.5773 - val_macro_f1: 0.5750 - lr: 8.4344e-05\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.9453 — val_f1: 0.5642\n",
      "\n",
      "Epoch 82: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.2877 - accuracy: 0.9453 - val_loss: 0.9372 - val_accuracy: 0.5683 - val_macro_f1: 0.5642 - lr: 7.6393e-05\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.9433 — val_f1: 0.5885\n",
      "\n",
      "Epoch 83: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 0.2968 - accuracy: 0.9433 - val_loss: 0.8998 - val_accuracy: 0.5896 - val_macro_f1: 0.5885 - lr: 6.8796e-05\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9689 — val_f1: 0.5833\n",
      "\n",
      "Epoch 84: val_macro_f1 did not improve from 0.60849\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.2520 - accuracy: 0.9689 - val_loss: 0.8909 - val_accuracy: 0.5844 - val_macro_f1: 0.5833 - lr: 6.1562e-05\n",
      "Evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG     0.7023    0.7925    0.7447       265\n",
      "         DIS     0.5512    0.5887    0.5693       265\n",
      "         FEA     0.5447    0.5057    0.5245       265\n",
      "         HAP     0.5932    0.5283    0.5589       265\n",
      "         NEU     0.7540    0.6211    0.6812       227\n",
      "         SAD     0.5382    0.6113    0.5724       265\n",
      "\n",
      "    accuracy                         0.6076      1552\n",
      "   macro avg     0.6140    0.6079    0.6085      1552\n",
      "weighted avg     0.6105    0.6076    0.6067      1552\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Two-Stream V4.1 - Cross-Attention Fusion\n",
    "# 核心思想：利用 eGeMAPS 全局特征作为 Context，通过 Attention 指导 Log-Mel 序列特征\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# 1. 基础配置\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 自动生成目录\n",
    "def create_experiment_dir(base_dir=\"Output\"):\n",
    "    script_name = \"twostream_v4_1_crossattn\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exp_dir = os.path.join(base_dir, f\"{script_name}_{timestamp}\")\n",
    "    os.makedirs(os.path.join(exp_dir, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"plots\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"logs\"), exist_ok=True)\n",
    "    return exp_dir, os.path.join(exp_dir, \"models\"), os.path.join(exp_dir, \"plots\"), os.path.join(exp_dir, \"logs\")\n",
    "\n",
    "EXP_DIR, MODEL_DIR, PLOT_DIR, LOG_DIR = create_experiment_dir()\n",
    "AUDIO_DIR = Path(\"../AudioWAV\")\n",
    "\n",
    "# =====================\n",
    "# 2. 特征提取 (Log-Mel + eGeMAPS)\n",
    "# =====================\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "FIXED_SECONDS = 3.0\n",
    "MAX_FRAMES = int(math.ceil(FIXED_SECONDS * SR / 160))\n",
    "\n",
    "# 初始化 OpenSmile\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "def load_data_and_extract(audio_dir):\n",
    "    print(\"Scanning files...\")\n",
    "    paths, emotions, speakers = [], [], []\n",
    "    for f in audio_dir.glob(\"*.wav\"):\n",
    "        parts = f.stem.split(\"_\")\n",
    "        if len(parts) == 4:\n",
    "            paths.append(f); emotions.append(parts[2]); speakers.append(parts[0])\n",
    "    \n",
    "    print(f\"Extracting features for {len(paths)} files...\")\n",
    "    X_mel, X_ege = [], []\n",
    "    \n",
    "    for i, p in enumerate(paths):\n",
    "        if i % 500 == 0: print(f\"Processing {i}...\")\n",
    "        \n",
    "        # A. Log-Mel\n",
    "        y, _ = librosa.load(p, sr=SR, mono=True)\n",
    "        tgt = int(FIXED_SECONDS * SR)\n",
    "        if len(y) < tgt: y = np.pad(y, (0, tgt-len(y)))\n",
    "        else: y = y[:tgt]\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=N_MELS, hop_length=160)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "        feat = np.transpose(S_db[..., None], (1, 0, 2))\n",
    "        if feat.shape[0] < MAX_FRAMES:\n",
    "            feat = np.pad(feat, ((0, MAX_FRAMES-feat.shape[0]),(0,0),(0,0)))\n",
    "        else: feat = feat[:MAX_FRAMES]\n",
    "        X_mel.append(feat)\n",
    "        \n",
    "        # B. eGeMAPS (Functionals)\n",
    "        try:\n",
    "            ege = smile.process_file(p).values.flatten().astype(np.float32)\n",
    "            # 简单的NaN处理\n",
    "            if np.isnan(ege).any(): ege = np.nan_to_num(ege)\n",
    "            X_ege.append(ege)\n",
    "        except:\n",
    "            X_ege.append(np.zeros(88, dtype=np.float32))\n",
    "            \n",
    "    return np.stack(X_mel), np.stack(X_ege), np.array(emotions), np.array(speakers)\n",
    "\n",
    "# 执行提取 (如果是Notebook环境，确保只运行一次)\n",
    "if 'X_mel_all' not in globals():\n",
    "    X_mel_all, X_ege_all, y_all, spk_all = load_data_and_extract(AUDIO_DIR)\n",
    "\n",
    "# =====================\n",
    "# 3. 数据准备\n",
    "# =====================\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_all)\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "# 划分\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "tr_idx, te_idx = next(gss.split(X_mel_all, y_enc, groups=spk_all))\n",
    "\n",
    "X_mel_tr, X_mel_te = X_mel_all[tr_idx], X_mel_all[te_idx]\n",
    "X_ege_tr, X_ege_te = X_ege_all[tr_idx], X_ege_all[te_idx]\n",
    "y_tr, y_te = y_enc[tr_idx], y_enc[te_idx]\n",
    "\n",
    "# 归一化\n",
    "# Log-Mel: Global Z-Score\n",
    "mean_mel = X_mel_tr.mean(axis=(0,1,2), keepdims=True)\n",
    "std_mel = X_mel_tr.std(axis=(0,1,2), keepdims=True) + 1e-6\n",
    "X_mel_tr = (X_mel_tr - mean_mel) / std_mel\n",
    "X_mel_te = (X_mel_te - mean_mel) / std_mel\n",
    "\n",
    "# eGeMAPS: StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_ege_tr = scaler.fit_transform(X_ege_tr)\n",
    "X_ege_te = scaler.transform(X_ege_te)\n",
    "\n",
    "print(f\"Train shape: Mel {X_mel_tr.shape}, eGe {X_ege_tr.shape}\")\n",
    "\n",
    "# =====================\n",
    "# 4. 核心组件：Conformer & Cross-Attention\n",
    "# =====================\n",
    "def glu(x): return x[..., :x.shape[-1]//2] * tf.sigmoid(x[..., x.shape[-1]//2:])\n",
    "\n",
    "def conformer_block(x, d_model=128, dropout=0.15):\n",
    "    # FFN 1\n",
    "    r = x\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    \n",
    "    # MHSA\n",
    "    r = x\n",
    "    x = layers.MultiHeadAttention(4, d_model//4, dropout=dropout)(x, x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    # Conv\n",
    "    r = x\n",
    "    x = layers.Conv1D(d_model*2, 1)(x)\n",
    "    x = layers.Lambda(glu)(x)\n",
    "    x = layers.DepthwiseConv1D(15, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "    x = layers.Conv1D(d_model, 1)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    # FFN 2\n",
    "    r = x\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    return x\n",
    "\n",
    "# === 关键修改：互注意力融合层 ===\n",
    "class CrossAttentionFusion(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=4, key_dim=d_model//4, dropout=dropout)\n",
    "        self.layernorm = layers.LayerNormalization()\n",
    "        self.add = layers.Add()\n",
    "        \n",
    "    def call(self, sequence, context):\n",
    "        # sequence: (B, T, D) -> Query\n",
    "        # context: (B, D_ctx) -> Key, Value\n",
    "        \n",
    "        # 1. Expand context to be sequence-like for attention\n",
    "        # context: (B, 1, D)\n",
    "        context = tf.expand_dims(context, axis=1)\n",
    "        \n",
    "        # 2. Cross Attention\n",
    "        # Query = sequence (Conformer features)\n",
    "        # Key/Value = context (eGeMAPS features)\n",
    "        # 这样模型会根据 eGeMAPS 的信息，去“关注”序列中特定的时间步\n",
    "        attn_out = self.mha(query=sequence, value=context, key=context)\n",
    "        \n",
    "        # 3. Residual Connection + Norm\n",
    "        # 将 Attention 的结果加回原序列，实现“调制”效果\n",
    "        x = self.add([sequence, attn_out])\n",
    "        return self.layernorm(x)\n",
    "\n",
    "# =====================\n",
    "# 5. 模型构建 (修复版)\n",
    "# =====================\n",
    "def build_cross_fusion_model(mel_shape, ege_shape, n_classes, d_model=128):\n",
    "    # --- Stream 1: Conformer ---\n",
    "    in_mel = layers.Input(shape=mel_shape)\n",
    "    x = layers.GaussianNoise(0.02)(in_mel) \n",
    "    \n",
    "    # CNN Front-end\n",
    "    # === 修复点开始 ===\n",
    "    # 必须在 BatchNormalization() 后面加上 (x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)  # 注意这里加上了 (x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)  # 注意这里加上了 (x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-5))(x)\n",
    "    x = layers.BatchNormalization()(x)  # 注意这里加上了 (x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    # === 修复点结束 ===\n",
    "    \n",
    "    x = layers.Reshape((-1, x.shape[-1]))(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.Dropout(0.15)(x)\n",
    "    \n",
    "    # Conformer Encoders\n",
    "    x = conformer_block(x, d_model, dropout=0.15)\n",
    "    x = conformer_block(x, d_model, dropout=0.15)\n",
    "    \n",
    "    # --- Stream 2: eGeMAPS Context ---\n",
    "    in_ege = layers.Input(shape=ege_shape)\n",
    "    c = layers.GaussianNoise(0.05)(in_ege)\n",
    "    c = layers.Dense(d_model, activation='relu')(c)\n",
    "    c = layers.BatchNormalization()(c) # 这里你也漏了 (c)，但我顺手帮你补上了\n",
    "    c = layers.Dropout(0.3)(c) \n",
    "    \n",
    "    # --- Fusion: Cross-Attention ---\n",
    "    fused_seq = CrossAttentionFusion(d_model, dropout=0.2)(sequence=x, context=c)\n",
    "    \n",
    "    # --- Pooling & Classification ---\n",
    "    att = layers.Dense(1, activation=\"tanh\")(fused_seq)\n",
    "    att = layers.Softmax(axis=1)(att)\n",
    "    pooled = tf.reduce_sum(fused_seq * att, axis=1)\n",
    "    \n",
    "    final_vec = layers.Concatenate()([pooled, c])\n",
    "    \n",
    "    z = layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(5e-5))(final_vec)\n",
    "    z = layers.Dropout(0.3)(z)\n",
    "    out = layers.Dense(n_classes, activation=\"softmax\", name=\"emotion\")(z)\n",
    "    \n",
    "    return models.Model(inputs=[in_mel, in_ege], outputs=out)\n",
    "\n",
    "# =====================\n",
    "# 6. 训练配置\n",
    "# =====================\n",
    "class LabelSmoothingFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, smoothing=0.05, gamma=2.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "    def call(self, y_true, y_pred):\n",
    "        n = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = y_true * (1 - self.smoothing) + self.smoothing / n\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        return tf.reduce_sum(-y_true * tf.math.log(y_pred) * tf.pow(1 - y_pred, self.gamma), axis=-1)\n",
    "\n",
    "# Generator (Mixup)\n",
    "class DualMixupGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x1, x2, y, batch=64, alpha=0.2):\n",
    "        self.x1, self.x2, self.y = x1, x2, y\n",
    "        self.batch, self.alpha = batch, alpha\n",
    "        self.idx = np.arange(len(x1))\n",
    "        np.random.shuffle(self.idx)\n",
    "    def __len__(self): return int(np.ceil(len(self.x1)/self.batch))\n",
    "    def __getitem__(self, i):\n",
    "        inds = self.idx[i*self.batch:(i+1)*self.batch]\n",
    "        bx1, bx2, by = self.x1[inds], self.x2[inds], self.y[inds]\n",
    "        if np.random.random()<0.5: # Mixup\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            perm = np.random.permutation(len(bx1))\n",
    "            bx1 = lam*bx1 + (1-lam)*bx1[perm]\n",
    "            bx2 = lam*bx2 + (1-lam)*bx2[perm]\n",
    "            by = lam*by + (1-lam)*by[perm]\n",
    "        return [bx1, bx2], by\n",
    "    def on_epoch_end(self): np.random.shuffle(self.idx)\n",
    "\n",
    "# 编译\n",
    "model = build_cross_fusion_model(X_mel_tr.shape[1:], (88,), n_classes)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=8e-4, weight_decay=2e-4),\n",
    "    loss=LabelSmoothingFocalLoss(smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# 训练\n",
    "y_tr_oh = tf.keras.utils.to_categorical(y_tr)\n",
    "y_te_oh = tf.keras.utils.to_categorical(y_te)\n",
    "gen = DualMixupGen(X_mel_tr, X_ege_tr, y_tr_oh, batch=64)\n",
    "\n",
    "# Callbacks\n",
    "class F1Cb(callbacks.Callback):\n",
    "    def on_epoch_end(self, e, logs):\n",
    "        p = np.argmax(self.model.predict([X_mel_te, X_ege_te], verbose=0), axis=1)\n",
    "        f1 = f1_score(y_te, p, average='macro')\n",
    "        print(f\" — val_f1: {f1:.4f}\")\n",
    "        logs['val_macro_f1'] = f1\n",
    "\n",
    "ckpt = callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, \"best.h5\"), monitor='val_macro_f1', mode='max', save_best_only=True, verbose=1)\n",
    "early = callbacks.EarlyStopping(monitor='val_macro_f1', mode='max', patience=25, restore_best_weights=True)\n",
    "def sched(e): return 8e-4 * (e+1)/5 if e<5 else 8e-4 * 0.5 * (1+np.cos(np.pi*(e-5)/95))\n",
    "\n",
    "print(\"Starting Cross-Attention Fusion Training...\")\n",
    "history = model.fit(\n",
    "    gen, \n",
    "    validation_data=([X_mel_te, X_ege_te], y_te_oh),\n",
    "    epochs=100,\n",
    "    callbacks=[F1Cb(), ckpt, early, callbacks.LearningRateScheduler(sched)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 7. 评估\n",
    "# =====================\n",
    "print(\"Evaluating...\")\n",
    "p = np.argmax(model.predict([X_mel_te, X_ege_te], verbose=0), axis=1)\n",
    "print(classification_report(y_te, p, target_names=le.classes_, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_te, p)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix (Cross-Attn Fusion)\")\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"cm.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ca5b9-aa5f-4cf0-9221-9c6aac9e9614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
