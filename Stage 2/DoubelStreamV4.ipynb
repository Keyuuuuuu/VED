{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e36ccf-264e-4ee4-8b17-bca6873f4d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: opensmile in /root/miniconda3/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: audobject>=0.6.1 in /root/miniconda3/lib/python3.8/site-packages (from opensmile) (0.7.11)\n",
      "Requirement already satisfied: audinterface>=0.7.0 in /root/miniconda3/lib/python3.8/site-packages (from opensmile) (1.2.1)\n",
      "Requirement already satisfied: audmath>=1.3.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.4.2)\n",
      "Requirement already satisfied: audeer>=1.18.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (2.2.0)\n",
      "Requirement already satisfied: audresample<2.0.0,>=1.1.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.3.4)\n",
      "Requirement already satisfied: audiofile>=1.3.0 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.5.0)\n",
      "Requirement already satisfied: audformat<2.0.0,>=1.0.1 in /root/miniconda3/lib/python3.8/site-packages (from audinterface>=0.7.0->opensmile) (1.1.4)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from audeer>=1.18.0->audinterface>=0.7.0->opensmile) (4.61.2)\n",
      "Requirement already satisfied: iso-639 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.0.1)\n",
      "Requirement already satisfied: iso3166 in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.1.1)\n",
      "Requirement already satisfied: oyaml in /root/miniconda3/lib/python3.8/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /root/miniconda3/lib/python3.8/site-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (0.13.1)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.24.2)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from audobject>=0.6.1->opensmile) (23.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /root/miniconda3/lib/python3.8/site-packages (from audobject>=0.6.1->opensmile) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.15.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.8/site-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /root/miniconda3/lib/python3.8/site-packages (from soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.20)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c01694-be9d-4191-82e8-f5bbad4e7fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:38:54.314971: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 04:38:54.400959: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 04:38:55.454420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.13.1\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✓ Experiment dir: Output/two_stream_v4_20251204_043856\n",
      "Samples: 7442\n",
      "Initializing OpenSmile for eGeMAPS extraction...\n",
      "Extracting ALL features (Log-Mel + eGeMAPS)... This may take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7442/7442 [13:48<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Mel shape: (7442, 300, 64, 1)\n",
      "eGeMAPS shape: (7442, 88)\n",
      "Data normalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:52:47.605941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:03.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_mel (InputLayer)      [(None, 300, 64, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNo  (None, 300, 64, 1)           0         ['input_mel[0][0]']           \n",
      " ise)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 300, 64, 32)          320       ['gaussian_noise[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 300, 64, 32)          128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 150, 32, 32)          0         ['batch_normalization[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 150, 32, 64)          18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 150, 32, 64)          256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 75, 16, 64)           0         ['batch_normalization_1[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 75, 16, 128)          73856     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 75, 16, 128)          512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 37, 8, 128)           0         ['batch_normalization_2[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 37, 1024)             0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 37, 128)              131200    ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 37, 512)              66048     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 37, 128)              65664     ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 37, 128)              0         ['dense_2[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 37, 128)              0         ['dense[0][0]',               \n",
      " Lambda)                                                             'tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 37, 128)              256       ['tf.__operators__.add[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 37, 128)              66048     ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 37, 128)              0         ['layer_normalization[0][0]', \n",
      " OpLambda)                                                           'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_1[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 37, 256)              33024     ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 37, 128)              0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv1d (Depthwis  (None, 37, 128)              2048      ['lambda[0][0]']              \n",
      " eConv1D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 37, 128)              512       ['depthwise_conv1d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 37, 128)              0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 37, 128)              16512     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 37, 128)              0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 37, 128)              0         ['layer_normalization_1[0][0]'\n",
      " OpLambda)                                                          , 'dropout[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 37, 512)              66048     ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 37, 128)              65664     ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 37, 128)              0         ['dense_4[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 37, 128)              0         ['layer_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 37, 512)              66048     ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 37, 128)              65664     ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 37, 128)              0         ['dense_6[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 37, 128)              0         ['layer_normalization_3[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_4[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 37, 128)              66048     ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 37, 128)              0         ['layer_normalization_4[0][0]'\n",
      " OpLambda)                                                          , 'multi_head_attention_1[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_5[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 37, 256)              33024     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 37, 128)              0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " depthwise_conv1d_1 (Depthw  (None, 37, 128)              2048      ['lambda_1[0][0]']            \n",
      " iseConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 37, 128)              512       ['depthwise_conv1d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 37, 128)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 37, 128)              16512     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 37, 128)              0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 37, 128)              0         ['layer_normalization_5[0][0]'\n",
      " OpLambda)                                                          , 'dropout_1[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_6[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 37, 512)              66048     ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 37, 128)              65664     ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " input_ege (InputLayer)      [(None, 88)]                 0         []                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (None, 37, 128)              0         ['dense_8[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (Gaussian  (None, 88)                   0         ['input_ege[0][0]']           \n",
      " Noise)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 37, 128)              0         ['layer_normalization_6[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 64)                   5696      ['gaussian_noise_1[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 37, 128)              256       ['tf.__operators__.add_7[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 64)                   256       ['dense_10[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 37, 1)                129       ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 64)                   0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " softmax (Softmax)           (None, 37, 1)                0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 32)                   2080      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (None, 37, 128)              0         ['layer_normalization_7[0][0]'\n",
      " mbda)                                                              , 'softmax[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 32)                   128       ['dense_11[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLa  (None, 128)                  0         ['tf.math.multiply_4[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 32)                   0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 160)                  0         ['tf.math.reduce_sum[0][0]',  \n",
      "                                                                     'dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 128)                  20608     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " emotion (Dense)             (None, 6)                    774       ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1019623 (3.89 MB)\n",
      "Trainable params: 1018471 (3.89 MB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Starting Two-Stream Training...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 04:52:59.251349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-12-04 04:52:59.759906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc7d4854d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-04 04:52:59.759947: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-12-04 04:52:59.769162: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-04 04:52:59.948195: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/93 [============================>.] - ETA: 0s - loss: 1.1081 - accuracy: 0.3350 — val_macro_f1: 0.0785\n",
      "\n",
      "Epoch 1: val_macro_f1 improved from -inf to 0.07852, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 28s 83ms/step - loss: 1.1067 - accuracy: 0.3353 - val_loss: 1.3227 - val_accuracy: 0.1830 - val_macro_f1: 0.0785 - lr: 1.6000e-04\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9652 - accuracy: 0.4194 — val_macro_f1: 0.1202\n",
      "\n",
      "Epoch 2: val_macro_f1 improved from 0.07852 to 0.12018, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 52ms/step - loss: 0.9652 - accuracy: 0.4194 - val_loss: 1.9225 - val_accuracy: 0.2171 - val_macro_f1: 0.1202 - lr: 3.2000e-04\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.9186 - accuracy: 0.4525 — val_macro_f1: 0.1322\n",
      "\n",
      "Epoch 3: val_macro_f1 improved from 0.12018 to 0.13222, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 53ms/step - loss: 0.9186 - accuracy: 0.4525 - val_loss: 1.8677 - val_accuracy: 0.2229 - val_macro_f1: 0.1322 - lr: 4.8000e-04\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8538 - accuracy: 0.4937 — val_macro_f1: 0.2067\n",
      "\n",
      "Epoch 4: val_macro_f1 improved from 0.13222 to 0.20672, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 53ms/step - loss: 0.8538 - accuracy: 0.4937 - val_loss: 1.3769 - val_accuracy: 0.2829 - val_macro_f1: 0.2067 - lr: 6.4000e-04\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8354 - accuracy: 0.5022 — val_macro_f1: 0.3485\n",
      "\n",
      "Epoch 5: val_macro_f1 improved from 0.20672 to 0.34845, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 53ms/step - loss: 0.8354 - accuracy: 0.5022 - val_loss: 1.1459 - val_accuracy: 0.3860 - val_macro_f1: 0.3485 - lr: 8.0000e-04\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.5246 — val_macro_f1: 0.3789\n",
      "\n",
      "Epoch 6: val_macro_f1 improved from 0.34845 to 0.37887, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 52ms/step - loss: 0.8089 - accuracy: 0.5246 - val_loss: 0.9471 - val_accuracy: 0.3950 - val_macro_f1: 0.3789 - lr: 8.0000e-04\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7840 - accuracy: 0.5470 — val_macro_f1: 0.4944\n",
      "\n",
      "Epoch 7: val_macro_f1 improved from 0.37887 to 0.49442, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 52ms/step - loss: 0.7840 - accuracy: 0.5470 - val_loss: 0.8444 - val_accuracy: 0.5006 - val_macro_f1: 0.4944 - lr: 7.9978e-04\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.5986 — val_macro_f1: 0.4321\n",
      "\n",
      "Epoch 8: val_macro_f1 did not improve from 0.49442\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.7052 - accuracy: 0.5986 - val_loss: 0.9774 - val_accuracy: 0.4639 - val_macro_f1: 0.4321 - lr: 7.9913e-04\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.6229 — val_macro_f1: 0.5068\n",
      "\n",
      "Epoch 9: val_macro_f1 improved from 0.49442 to 0.50682, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 53ms/step - loss: 0.6600 - accuracy: 0.6229 - val_loss: 0.8440 - val_accuracy: 0.5052 - val_macro_f1: 0.5068 - lr: 7.9803e-04\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.6472 — val_macro_f1: 0.4700\n",
      "\n",
      "Epoch 10: val_macro_f1 did not improve from 0.50682\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6186 - accuracy: 0.6472 - val_loss: 0.8966 - val_accuracy: 0.4684 - val_macro_f1: 0.4700 - lr: 7.9651e-04\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.6447 — val_macro_f1: 0.5654\n",
      "\n",
      "Epoch 11: val_macro_f1 improved from 0.50682 to 0.56542, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 54ms/step - loss: 0.6496 - accuracy: 0.6447 - val_loss: 0.7566 - val_accuracy: 0.5670 - val_macro_f1: 0.5654 - lr: 7.9454e-04\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.6798 — val_macro_f1: 0.5515\n",
      "\n",
      "Epoch 12: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6085 - accuracy: 0.6798 - val_loss: 0.7483 - val_accuracy: 0.5573 - val_macro_f1: 0.5515 - lr: 7.9215e-04\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.7087 — val_macro_f1: 0.5437\n",
      "\n",
      "Epoch 13: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.5457 - accuracy: 0.7087 - val_loss: 0.7885 - val_accuracy: 0.5406 - val_macro_f1: 0.5437 - lr: 7.8933e-04\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.7290 — val_macro_f1: 0.5209\n",
      "\n",
      "Epoch 14: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.5425 - accuracy: 0.7290 - val_loss: 0.8436 - val_accuracy: 0.5367 - val_macro_f1: 0.5209 - lr: 7.8608e-04\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.7537 — val_macro_f1: 0.3799\n",
      "\n",
      "Epoch 15: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.5055 - accuracy: 0.7537 - val_loss: 1.0534 - val_accuracy: 0.4323 - val_macro_f1: 0.3799 - lr: 7.8241e-04\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7594 — val_macro_f1: 0.3805\n",
      "\n",
      "Epoch 16: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4846 - accuracy: 0.7594 - val_loss: 1.1372 - val_accuracy: 0.4143 - val_macro_f1: 0.3805 - lr: 7.7833e-04\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.7705 — val_macro_f1: 0.5487\n",
      "\n",
      "Epoch 17: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4661 - accuracy: 0.7705 - val_loss: 0.8014 - val_accuracy: 0.5490 - val_macro_f1: 0.5487 - lr: 7.7383e-04\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4200 - accuracy: 0.8010 — val_macro_f1: 0.5304\n",
      "\n",
      "Epoch 18: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4200 - accuracy: 0.8010 - val_loss: 0.8714 - val_accuracy: 0.5380 - val_macro_f1: 0.5304 - lr: 7.6892e-04\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4790 - accuracy: 0.7829 — val_macro_f1: 0.5239\n",
      "\n",
      "Epoch 19: val_macro_f1 did not improve from 0.56542\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4790 - accuracy: 0.7829 - val_loss: 0.9200 - val_accuracy: 0.5296 - val_macro_f1: 0.5239 - lr: 7.6360e-04\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8341 — val_macro_f1: 0.5933\n",
      "\n",
      "Epoch 20: val_macro_f1 improved from 0.56542 to 0.59330, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 54ms/step - loss: 0.3869 - accuracy: 0.8341 - val_loss: 0.8030 - val_accuracy: 0.5889 - val_macro_f1: 0.5933 - lr: 7.5789e-04\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.8750 — val_macro_f1: 0.5656\n",
      "\n",
      "Epoch 21: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3595 - accuracy: 0.8750 - val_loss: 0.8441 - val_accuracy: 0.5799 - val_macro_f1: 0.5656 - lr: 7.5179e-04\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4066 - accuracy: 0.8732 — val_macro_f1: 0.5578\n",
      "\n",
      "Epoch 22: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4066 - accuracy: 0.8732 - val_loss: 0.7981 - val_accuracy: 0.5638 - val_macro_f1: 0.5578 - lr: 7.4530e-04\n",
      "Epoch 23/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.8776 — val_macro_f1: 0.5586\n",
      "\n",
      "Epoch 23: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3392 - accuracy: 0.8771 - val_loss: 0.8299 - val_accuracy: 0.5554 - val_macro_f1: 0.5586 - lr: 7.3844e-04\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8776 — val_macro_f1: 0.5284\n",
      "\n",
      "Epoch 24: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3276 - accuracy: 0.8776 - val_loss: 0.8998 - val_accuracy: 0.5361 - val_macro_f1: 0.5284 - lr: 7.3120e-04\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.8236 — val_macro_f1: 0.5023\n",
      "\n",
      "Epoch 25: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4309 - accuracy: 0.8236 - val_loss: 0.9852 - val_accuracy: 0.5013 - val_macro_f1: 0.5023 - lr: 7.2361e-04\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.9044 — val_macro_f1: 0.5789\n",
      "\n",
      "Epoch 26: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3241 - accuracy: 0.9044 - val_loss: 0.8471 - val_accuracy: 0.5715 - val_macro_f1: 0.5789 - lr: 7.1566e-04\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8859 — val_macro_f1: 0.5615\n",
      "\n",
      "Epoch 27: val_macro_f1 did not improve from 0.59330\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.3748 - accuracy: 0.8859 - val_loss: 0.8718 - val_accuracy: 0.5657 - val_macro_f1: 0.5615 - lr: 7.0736e-04\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.9216 — val_macro_f1: 0.6178\n",
      "\n",
      "Epoch 28: val_macro_f1 improved from 0.59330 to 0.61784, saving model to Output/two_stream_v4_20251204_043856/models/best_fusion_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2864 - accuracy: 0.9216 - val_loss: 0.7861 - val_accuracy: 0.6198 - val_macro_f1: 0.6178 - lr: 6.9873e-04\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.9382 — val_macro_f1: 0.5289\n",
      "\n",
      "Epoch 29: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2936 - accuracy: 0.9382 - val_loss: 0.9343 - val_accuracy: 0.5438 - val_macro_f1: 0.5289 - lr: 6.8977e-04\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.9088 — val_macro_f1: 0.5942\n",
      "\n",
      "Epoch 30: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3201 - accuracy: 0.9088 - val_loss: 0.8590 - val_accuracy: 0.5986 - val_macro_f1: 0.5942 - lr: 6.8049e-04\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.9440 — val_macro_f1: 0.5656\n",
      "\n",
      "Epoch 31: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2675 - accuracy: 0.9440 - val_loss: 0.8966 - val_accuracy: 0.5735 - val_macro_f1: 0.5656 - lr: 6.7091e-04\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.9178 — val_macro_f1: 0.5975\n",
      "\n",
      "Epoch 32: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3250 - accuracy: 0.9178 - val_loss: 0.7788 - val_accuracy: 0.5966 - val_macro_f1: 0.5975 - lr: 6.6103e-04\n",
      "Epoch 33/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9543 — val_macro_f1: 0.5966\n",
      "\n",
      "Epoch 33: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2686 - accuracy: 0.9545 - val_loss: 0.8581 - val_accuracy: 0.6063 - val_macro_f1: 0.5966 - lr: 6.5087e-04\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9618 — val_macro_f1: 0.5769\n",
      "\n",
      "Epoch 34: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2344 - accuracy: 0.9618 - val_loss: 0.8962 - val_accuracy: 0.5838 - val_macro_f1: 0.5769 - lr: 6.4043e-04\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.9438 — val_macro_f1: 0.4724\n",
      "\n",
      "Epoch 35: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2781 - accuracy: 0.9438 - val_loss: 0.9916 - val_accuracy: 0.5006 - val_macro_f1: 0.4724 - lr: 6.2973e-04\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.9368 — val_macro_f1: 0.5694\n",
      "\n",
      "Epoch 36: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2922 - accuracy: 0.9368 - val_loss: 0.8954 - val_accuracy: 0.5767 - val_macro_f1: 0.5694 - lr: 6.1878e-04\n",
      "Epoch 37/100\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9554 — val_macro_f1: 0.5466\n",
      "\n",
      "Epoch 37: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2308 - accuracy: 0.9552 - val_loss: 0.9661 - val_accuracy: 0.5573 - val_macro_f1: 0.5466 - lr: 6.0759e-04\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9448 — val_macro_f1: 0.6106\n",
      "\n",
      "Epoch 38: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2503 - accuracy: 0.9448 - val_loss: 0.8296 - val_accuracy: 0.6121 - val_macro_f1: 0.6106 - lr: 5.9617e-04\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9591 — val_macro_f1: 0.5469\n",
      "\n",
      "Epoch 39: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.2303 - accuracy: 0.9591 - val_loss: 0.8981 - val_accuracy: 0.5599 - val_macro_f1: 0.5469 - lr: 5.8454e-04\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8747 — val_macro_f1: 0.5204\n",
      "\n",
      "Epoch 40: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.3648 - accuracy: 0.8747 - val_loss: 0.9772 - val_accuracy: 0.5277 - val_macro_f1: 0.5204 - lr: 5.7270e-04\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2980 - accuracy: 0.9338 — val_macro_f1: 0.5874\n",
      "\n",
      "Epoch 41: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2980 - accuracy: 0.9338 - val_loss: 0.9006 - val_accuracy: 0.5909 - val_macro_f1: 0.5874 - lr: 5.6068e-04\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.9158 — val_macro_f1: 0.5008\n",
      "\n",
      "Epoch 42: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3145 - accuracy: 0.9158 - val_loss: 0.9762 - val_accuracy: 0.5129 - val_macro_f1: 0.5008 - lr: 5.4848e-04\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.9287 — val_macro_f1: 0.2992\n",
      "\n",
      "Epoch 43: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2970 - accuracy: 0.9287 - val_loss: 1.3670 - val_accuracy: 0.3441 - val_macro_f1: 0.2992 - lr: 5.3612e-04\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9112 — val_macro_f1: 0.5970\n",
      "\n",
      "Epoch 44: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3261 - accuracy: 0.9112 - val_loss: 0.8305 - val_accuracy: 0.5973 - val_macro_f1: 0.5970 - lr: 5.2361e-04\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.9457 — val_macro_f1: 0.5872\n",
      "\n",
      "Epoch 45: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2656 - accuracy: 0.9457 - val_loss: 0.8528 - val_accuracy: 0.5909 - val_macro_f1: 0.5872 - lr: 5.1096e-04\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.9436 — val_macro_f1: 0.6025\n",
      "\n",
      "Epoch 46: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2523 - accuracy: 0.9436 - val_loss: 0.8356 - val_accuracy: 0.6050 - val_macro_f1: 0.6025 - lr: 4.9819e-04\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9754 — val_macro_f1: 0.5925\n",
      "\n",
      "Epoch 47: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2259 - accuracy: 0.9754 - val_loss: 0.8818 - val_accuracy: 0.5921 - val_macro_f1: 0.5925 - lr: 4.8532e-04\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.9433 — val_macro_f1: 0.6105\n",
      "\n",
      "Epoch 48: val_macro_f1 did not improve from 0.61784\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2450 - accuracy: 0.9433 - val_loss: 0.8641 - val_accuracy: 0.6089 - val_macro_f1: 0.6105 - lr: 4.7235e-04\n",
      "\n",
      "Evaluating Best Fusion Model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG     0.7234    0.7698    0.7459       265\n",
      "         DIS     0.6164    0.5396    0.5755       265\n",
      "         FEA     0.6786    0.4302    0.5266       265\n",
      "         HAP     0.5691    0.6528    0.6081       265\n",
      "         NEU     0.6965    0.6167    0.6542       227\n",
      "         SAD     0.5151    0.7094    0.5968       265\n",
      "\n",
      "    accuracy                         0.6198      1552\n",
      "   macro avg     0.6332    0.6198    0.6178      1552\n",
      "weighted avg     0.6316    0.6198    0.6169      1552\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Output/two_stream_v4_20251204_043856\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 语音情绪识别 - Two-Stream Network (Conformer + eGeMAPS)\n",
    "# 方案: V4 (基于 V3.1 内核)\n",
    "# 特性: Log-Mel (时频细节) + eGeMAPS (韵律统计) 特征融合\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile  # 必须安装: pip install opensmile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 设置绘图\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# =====================\n",
    "# 1) 目录设置\n",
    "# =====================\n",
    "def create_experiment_dir(base_dir=\"Output\"):\n",
    "    script_name = \"two_stream_v4\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    exp_dir = os.path.join(base_dir, f\"{script_name}_{timestamp}\")\n",
    "    os.makedirs(os.path.join(exp_dir, \"models\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"plots\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(exp_dir, \"logs\"), exist_ok=True)\n",
    "    print(f\"✓ Experiment dir: {exp_dir}\")\n",
    "    return exp_dir\n",
    "\n",
    "EXP_DIR = create_experiment_dir()\n",
    "MODEL_DIR = os.path.join(EXP_DIR, \"models\")\n",
    "PLOT_DIR = os.path.join(EXP_DIR, \"plots\")\n",
    "LOG_DIR = os.path.join(EXP_DIR, \"logs\")\n",
    "\n",
    "AUDIO_DIR = Path(\"../AudioWAV\")\n",
    "assert AUDIO_DIR.exists()\n",
    "\n",
    "# =====================\n",
    "# 2) 元数据构建\n",
    "# =====================\n",
    "def build_metadata(audio_dir):\n",
    "    records = []\n",
    "    for wav_file in audio_dir.glob(\"*.wav\"):\n",
    "        parts = wav_file.stem.split(\"_\")\n",
    "        if len(parts) == 4:\n",
    "            records.append({\n",
    "                \"path\": str(wav_file),\n",
    "                \"speaker\": parts[0],\n",
    "                \"emotion\": parts[2]\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "meta = build_metadata(AUDIO_DIR)\n",
    "print(f\"Samples: {len(meta)}\")\n",
    "\n",
    "# =====================\n",
    "# 3) 特征提取 A: Log-Mel (流1)\n",
    "# =====================\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "FIXED_SECONDS = 3.0\n",
    "MAX_FRAMES = int(math.ceil(FIXED_SECONDS * SR / 160)) # hop=160\n",
    "\n",
    "def extract_logmel(path):\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "    tgt = int(FIXED_SECONDS * SR)\n",
    "    if len(y) < tgt:\n",
    "        y = np.pad(y, (0, tgt - len(y)))\n",
    "    else:\n",
    "        y = y[:tgt]\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=N_MELS, n_fft=1024, hop_length=160)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
    "    feat = np.transpose(S_db[..., None], (1, 0, 2)) # (T, F, 1)\n",
    "    \n",
    "    if feat.shape[0] < MAX_FRAMES:\n",
    "        feat = np.pad(feat, ((0, MAX_FRAMES-feat.shape[0]),(0,0),(0,0)))\n",
    "    else:\n",
    "        feat = feat[:MAX_FRAMES]\n",
    "    return feat\n",
    "\n",
    "# =====================\n",
    "# 4) 特征提取 B: eGeMAPS (流2 - 关键新增)\n",
    "# =====================\n",
    "print(\"Initializing OpenSmile for eGeMAPS extraction...\")\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "def extract_egemaps(path):\n",
    "    # OpenSmile 返回的是 DataFrame，我们需要 values\n",
    "    try:\n",
    "        # 提取 88 维特征\n",
    "        df = smile.process_file(path)\n",
    "        return df.values.flatten().astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting eGeMAPS for {path}: {e}\")\n",
    "        return np.zeros(88, dtype=np.float32)\n",
    "\n",
    "# =====================\n",
    "# 5) 执行批量提取\n",
    "# =====================\n",
    "print(\"Extracting ALL features (Log-Mel + eGeMAPS)... This may take a while.\")\n",
    "feat_mel = []\n",
    "feat_ege = []\n",
    "labels = []\n",
    "speakers = []\n",
    "\n",
    "# 为了显示进度\n",
    "from tqdm import tqdm\n",
    "for idx, row in tqdm(meta.iterrows(), total=len(meta)):\n",
    "    # 提取 Mel\n",
    "    feat_mel.append(extract_logmel(row['path']))\n",
    "    # 提取 eGeMAPS\n",
    "    feat_ege.append(extract_egemaps(row['path']))\n",
    "    \n",
    "    labels.append(row['emotion'])\n",
    "    speakers.append(row['speaker'])\n",
    "\n",
    "X_mel = np.stack(feat_mel)\n",
    "X_ege = np.stack(feat_ege) # Shape should be (N, 88)\n",
    "print(f\"Log-Mel shape: {X_mel.shape}\")\n",
    "print(f\"eGeMAPS shape: {X_ege.shape}\")\n",
    "\n",
    "# =====================\n",
    "# 6) 数据划分与归一化\n",
    "# =====================\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels).astype(np.int32)\n",
    "groups = np.array(speakers)\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, test_idx = next(gss.split(X_mel, y, groups=groups))\n",
    "\n",
    "# 划分\n",
    "X_mel_tr, X_mel_te = X_mel[train_idx], X_mel[test_idx]\n",
    "X_ege_tr, X_ege_te = X_ege[train_idx], X_ege[test_idx]\n",
    "y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "# --- 归一化 (关键步骤) ---\n",
    "# 1. Log-Mel: 全局 Z-Score\n",
    "mean_mel = X_mel_tr.mean(axis=(0,1,2), keepdims=True)\n",
    "std_mel = X_mel_tr.std(axis=(0,1,2), keepdims=True) + 1e-6\n",
    "X_mel_tr = (X_mel_tr - mean_mel) / std_mel\n",
    "X_mel_te = (X_mel_te - mean_mel) / std_mel\n",
    "\n",
    "# 2. eGeMAPS: StandardScaler (列级归一化)\n",
    "scaler_ege = StandardScaler()\n",
    "X_ege_tr = scaler_ege.fit_transform(X_ege_tr)\n",
    "X_ege_te = scaler_ege.transform(X_ege_te)\n",
    "\n",
    "print(\"Data normalized.\")\n",
    "\n",
    "# =====================\n",
    "# 7) 双输入 Mixup Generator\n",
    "# =====================\n",
    "class DualStreamGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_mel, x_ege, y, batch_size=64, alpha=0.2, shuffle=True):\n",
    "        self.x_mel = x_mel\n",
    "        self.x_ege = x_ege\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(x_mel))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x_mel) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indexes[idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "        \n",
    "        b_mel = self.x_mel[inds].copy()\n",
    "        b_ege = self.x_ege[inds].copy()\n",
    "        b_y = self.y[inds].copy()\n",
    "        \n",
    "        # Mixup (同时对两个流应用相同的混合系数)\n",
    "        if np.random.random() < 0.5 and self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            # 打乱顺序用于混合\n",
    "            perm = np.random.permutation(len(b_mel))\n",
    "            \n",
    "            b_mel = lam * b_mel + (1 - lam) * b_mel[perm]\n",
    "            b_ege = lam * b_ege + (1 - lam) * b_ege[perm]\n",
    "            b_y   = lam * b_y   + (1 - lam) * b_y[perm]\n",
    "            \n",
    "        # 返回: ([input_A, input_B], target)\n",
    "        return [b_mel, b_ege], b_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# =====================\n",
    "# 8) 模型构建: Conformer V3.1 + MLP Fusion\n",
    "# =====================\n",
    "# --- 复用之前的组件 ---\n",
    "class SpecAugment(layers.Layer):\n",
    "    def __init__(self, **kwargs): super().__init__(**kwargs)\n",
    "    def call(self, x, training=False): return x # 省略具体实现以节省篇幅，沿用V3.1逻辑即可\n",
    "\n",
    "def glu(x): return x[..., :x.shape[-1]//2] * tf.sigmoid(x[..., x.shape[-1]//2:])\n",
    "\n",
    "def conformer_block(x, d_model=128, dropout=0.15):\n",
    "    # 简化版实现，逻辑同 V3.1\n",
    "    r = x\n",
    "    # FFN\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    \n",
    "    r = x\n",
    "    # MHSA\n",
    "    x = layers.MultiHeadAttention(4, d_model//4, dropout=dropout)(x, x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    r = x\n",
    "    # Conv\n",
    "    x = layers.Conv1D(d_model*2, 1)(x)\n",
    "    x = layers.Lambda(glu)(x)\n",
    "    x = layers.DepthwiseConv1D(15, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "    x = layers.Conv1D(d_model, 1)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization()(r + x)\n",
    "    \n",
    "    r = x\n",
    "    # FFN\n",
    "    x = layers.Dense(d_model*4, activation=\"swish\")(x)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = layers.LayerNormalization()(r + 0.5*x)\n",
    "    return x\n",
    "\n",
    "def build_two_stream_model(mel_shape, ege_shape, n_classes):\n",
    "    # --- Stream 1: Conformer (Log-Mel) ---\n",
    "    in_mel = layers.Input(shape=mel_shape, name=\"input_mel\")\n",
    "    x = layers.GaussianNoise(0.02)(in_mel)\n",
    "    \n",
    "    # CNN Frontend (V3.1 配置)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    # Reshape & Conformer\n",
    "    x = layers.Reshape((x.shape[1], -1))(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = conformer_block(x, d_model=128, dropout=0.15)\n",
    "    x = conformer_block(x, d_model=128, dropout=0.15)\n",
    "    \n",
    "    # Pooling\n",
    "    att = layers.Dense(1, activation=\"tanh\")(x)\n",
    "    att = layers.Softmax(axis=1)(att)\n",
    "    vec_mel = tf.reduce_sum(x * att, axis=1) # (Batch, 128)\n",
    "    \n",
    "    # --- Stream 2: MLP (eGeMAPS) ---\n",
    "    in_ege = layers.Input(shape=ege_shape, name=\"input_ege\") # (Batch, 88)\n",
    "    y = layers.GaussianNoise(0.05)(in_ege) # 给统计特征加点噪\n",
    "    \n",
    "    y = layers.Dense(64, activation=\"relu\")(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.3)(y)\n",
    "    \n",
    "    y = layers.Dense(32, activation=\"relu\")(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    vec_ege = layers.Dropout(0.2)(y) # (Batch, 32)\n",
    "    \n",
    "    # --- Feature Fusion ---\n",
    "    combined = layers.Concatenate()([vec_mel, vec_ege]) # 128 + 32 = 160\n",
    "    \n",
    "    # Classifier\n",
    "    z = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    z = layers.Dropout(0.3)(z)\n",
    "    output = layers.Dense(n_classes, activation=\"softmax\", name=\"emotion\")(z)\n",
    "    \n",
    "    model = models.Model(inputs=[in_mel, in_ege], outputs=output)\n",
    "    return model\n",
    "\n",
    "# =====================\n",
    "# 9) 训练与配置 (V3.1 设置)\n",
    "# =====================\n",
    "class LabelSmoothingFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, smoothing=0.05, gamma=2.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        n_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_true = y_true * (1 - self.smoothing) + self.smoothing / n_classes\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        return tf.reduce_sum(-y_true * tf.math.log(y_pred) * tf.pow(1 - y_pred, self.gamma), axis=-1)\n",
    "\n",
    "# 构建模型\n",
    "model = build_two_stream_model(\n",
    "    mel_shape=X_mel_tr.shape[1:],\n",
    "    ege_shape=(88,),\n",
    "    n_classes=n_classes\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# 编译 (V3.1配置)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=8e-4, weight_decay=2e-4),\n",
    "    loss=LabelSmoothingFocalLoss(smoothing=0.05, gamma=2.0),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 生成器\n",
    "train_gen = DualStreamGenerator(X_mel_tr, X_ege_tr, tf.keras.utils.to_categorical(y_tr, n_classes), batch_size=64)\n",
    "val_y_onehot = tf.keras.utils.to_categorical(y_te, n_classes)\n",
    "\n",
    "# 回调\n",
    "class MacroF1Callback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 预测需要两个输入\n",
    "        y_pred = np.argmax(self.model.predict([X_mel_te, X_ege_te], verbose=0), axis=1)\n",
    "        f1 = f1_score(y_te, y_pred, average=\"macro\")\n",
    "        print(f\" — val_macro_f1: {f1:.4f}\")\n",
    "        logs[\"val_macro_f1\"] = f1\n",
    "\n",
    "ckpt = callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, \"best_fusion_model.h5\"), \n",
    "                                 monitor=\"val_macro_f1\", mode=\"max\", save_best_only=True, verbose=1)\n",
    "early = callbacks.EarlyStopping(monitor=\"val_macro_f1\", mode=\"max\", patience=20, restore_best_weights=True)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 5: return 8e-4 * (epoch + 1) / 5\n",
    "    else: return 8e-4 * 0.5 * (1 + np.cos(np.pi * (epoch - 5) / 95))\n",
    "lr_sched = callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# =====================\n",
    "# 10) 开始训练\n",
    "# =====================\n",
    "print(\"\\nStarting Two-Stream Training...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=([X_mel_te, X_ege_te], val_y_onehot),\n",
    "    epochs=100,\n",
    "    callbacks=[MacroF1Callback(), ckpt, early, lr_sched, callbacks.CSVLogger(os.path.join(LOG_DIR, \"log.csv\"))],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 11) 最终评估\n",
    "# =====================\n",
    "print(\"\\nEvaluating Best Fusion Model...\")\n",
    "y_pred_proba = model.predict([X_mel_te, X_ege_te], verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "print(classification_report(y_te, y_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# 绘图\n",
    "cm = confusion_matrix(y_te, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Two-Stream)\")\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"fusion_confusion_matrix.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(f\"Results saved to {EXP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0097e02-99c9-4579-87f6-6fe45b89c595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
